{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPC-DI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:52.142672Z",
     "iopub.status.busy": "2023-12-22T12:10:52.141673Z",
     "iopub.status.idle": "2023-12-22T12:10:53.204899Z",
     "shell.execute_reply": "2023-12-22T12:10:53.202901Z",
     "shell.execute_reply.started": "2023-12-22T12:10:52.142672Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:53.206898Z",
     "iopub.status.busy": "2023-12-22T12:10:53.206898Z",
     "iopub.status.idle": "2023-12-22T12:10:53.328899Z",
     "shell.execute_reply": "2023-12-22T12:10:53.327171Z",
     "shell.execute_reply.started": "2023-12-22T12:10:53.206898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Database connection details\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"password\"\n",
    "database = \"tpcdi_sf5\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}?allow_local_infile=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Historical Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.110698Z",
     "iopub.status.busy": "2023-12-22T12:10:55.110698Z",
     "iopub.status.idle": "2023-12-22T12:10:55.125736Z",
     "shell.execute_reply": "2023-12-22T12:10:55.123726Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.110698Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.242897Z",
     "iopub.status.busy": "2023-12-22T12:10:55.240923Z",
     "iopub.status.idle": "2023-12-22T12:10:55.248902Z",
     "shell.execute_reply": "2023-12-22T12:10:55.247926Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.241919Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_ID = 1\n",
    "DATA_DIR = f\"..\\\\data\\\\sf5\\\\Batch{BATCH_ID}\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.380220Z",
     "iopub.status.busy": "2023-12-22T12:10:55.379219Z",
     "iopub.status.idle": "2023-12-22T12:10:55.404234Z",
     "shell.execute_reply": "2023-12-22T12:10:55.403220Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.380220Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"BatchDate.txt\", \"r\") as f:\n",
    "    BATCH_DATE = f.read().strip()\n",
    "BATCH_DATE = pd.to_datetime(BATCH_DATE, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.666828Z",
     "iopub.status.busy": "2023-12-22T12:10:55.665833Z",
     "iopub.status.idle": "2023-12-22T12:10:55.811828Z",
     "shell.execute_reply": "2023-12-22T12:10:55.810848Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.666828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>DateValue</th>\n",
       "      <th>DateDesc</th>\n",
       "      <th>CalendarYearID</th>\n",
       "      <th>CalendarYearDesc</th>\n",
       "      <th>CalendarQtrID</th>\n",
       "      <th>CalendarQtrDesc</th>\n",
       "      <th>CalendarMonthID</th>\n",
       "      <th>CalendarMonthDesc</th>\n",
       "      <th>CalendarWeekID</th>\n",
       "      <th>CalendarWeekDesc</th>\n",
       "      <th>DayOfWeekNum</th>\n",
       "      <th>DayOfWeekDesc</th>\n",
       "      <th>FiscalYearID</th>\n",
       "      <th>FiscalYearDesc</th>\n",
       "      <th>FiscalQtrID</th>\n",
       "      <th>FiscalQtrDesc</th>\n",
       "      <th>HolidayFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19500101</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>January 1, 1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 Q1</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 January</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950-W1</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19503</td>\n",
       "      <td>1950 Q3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19500102</td>\n",
       "      <td>1950-01-02</td>\n",
       "      <td>January 2, 1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 Q1</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 January</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950-W1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19503</td>\n",
       "      <td>1950 Q3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19500103</td>\n",
       "      <td>1950-01-03</td>\n",
       "      <td>January 3, 1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 Q1</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 January</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950-W1</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19503</td>\n",
       "      <td>1950 Q3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19500104</td>\n",
       "      <td>1950-01-04</td>\n",
       "      <td>January 4, 1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 Q1</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 January</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950-W1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19503</td>\n",
       "      <td>1950 Q3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19500105</td>\n",
       "      <td>1950-01-05</td>\n",
       "      <td>January 5, 1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 Q1</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950 January</td>\n",
       "      <td>19501</td>\n",
       "      <td>1950-W1</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1950</td>\n",
       "      <td>1950</td>\n",
       "      <td>19503</td>\n",
       "      <td>1950 Q3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_DateID  DateValue         DateDesc  CalendarYearID CalendarYearDesc  \\\n",
       "0   19500101 1950-01-01  January 1, 1950            1950             1950   \n",
       "1   19500102 1950-01-02  January 2, 1950            1950             1950   \n",
       "2   19500103 1950-01-03  January 3, 1950            1950             1950   \n",
       "3   19500104 1950-01-04  January 4, 1950            1950             1950   \n",
       "4   19500105 1950-01-05  January 5, 1950            1950             1950   \n",
       "\n",
       "   CalendarQtrID CalendarQtrDesc  CalendarMonthID CalendarMonthDesc  \\\n",
       "0          19501         1950 Q1            19501      1950 January   \n",
       "1          19501         1950 Q1            19501      1950 January   \n",
       "2          19501         1950 Q1            19501      1950 January   \n",
       "3          19501         1950 Q1            19501      1950 January   \n",
       "4          19501         1950 Q1            19501      1950 January   \n",
       "\n",
       "   CalendarWeekID CalendarWeekDesc  DayOfWeekNum DayOfWeekDesc  FiscalYearID  \\\n",
       "0           19501          1950-W1             7        Sunday          1950   \n",
       "1           19501          1950-W1             1        Monday          1950   \n",
       "2           19501          1950-W1             2       Tuesday          1950   \n",
       "3           19501          1950-W1             3     Wednesday          1950   \n",
       "4           19501          1950-W1             4      Thursday          1950   \n",
       "\n",
       "  FiscalYearDesc  FiscalQtrID FiscalQtrDesc  HolidayFlag  \n",
       "0           1950        19503       1950 Q3         True  \n",
       "1           1950        19503       1950 Q3        False  \n",
       "2           1950        19503       1950 Q3        False  \n",
       "3           1950        19503       1950 Q3        False  \n",
       "4           1950        19503       1950 Q3        False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df = pd.read_csv(\n",
    "    DATA_DIR + \"Date.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"SK_DateID\", \"DateValue\", \"DateDesc\", \"CalendarYearID\", \"CalendarYearDesc\", \n",
    "        \"CalendarQtrID\", \"CalendarQtrDesc\", \"CalendarMonthID\", \"CalendarMonthDesc\", \n",
    "        \"CalendarWeekID\", \"CalendarWeekDesc\", \"DayOfWeekNum\", \"DayOfWeekDesc\", \n",
    "        \"FiscalYearID\", \"FiscalYearDesc\", \"FiscalQtrID\", \"FiscalQtrDesc\", \"HolidayFlag\"\n",
    "    ],\n",
    "    parse_dates=[\"DateValue\"],\n",
    "    dtype={\n",
    "        \"SK_DateID\": \"uint32\", \"DateDesc\": \"str\", \"CalendarYearID\": \"uint16\", \"CalendarYearDesc\": \"str\",\n",
    "        \"CalendarQtrID\": \"uint16\", \"CalendarQtrDesc\": \"str\", \"CalendarMonthID\": \"uint32\", \"CalendarMonthDesc\": \"str\",\n",
    "        \"CalendarWeekID\": \"uint32\", \"CalendarWeekDesc\": \"str\", \"DayOfWeekNum\": \"uint8\", \"DayOfWeekDesc\": \"str\",\n",
    "        \"FiscalYearID\": \"uint16\", \"FiscalYearDesc\": \"str\", \"FiscalQtrID\": \"uint16\", \"FiscalQtrDesc\": \"str\",\n",
    "        \"HolidayFlag\": \"bool\"\n",
    "    }\n",
    ")\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.814826Z",
     "iopub.status.busy": "2023-12-22T12:10:55.813827Z",
     "iopub.status.idle": "2023-12-22T12:10:55.826865Z",
     "shell.execute_reply": "2023-12-22T12:10:55.825867Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.814826Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_DateID\": sqlalchemy.types.BigInteger,\n",
    "    \"DateValue\": sqlalchemy.types.Date,\n",
    "    \"DateDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarYearID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarYearDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarQtrID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarQtrDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarMonthID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarMonthDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarWeekID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarWeekDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"DayOfWeekNum\": sqlalchemy.types.SmallInteger,\n",
    "    \"DayOfWeekDesc\": sqlalchemy.types.CHAR(length=10),\n",
    "    \"FiscalYearID\": sqlalchemy.types.Integer,\n",
    "    \"FiscalYearDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"FiscalQtrID\": sqlalchemy.types.Integer,\n",
    "    \"FiscalQtrDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"HolidayFlag\": sqlalchemy.types.Boolean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:55.941827Z",
     "iopub.status.busy": "2023-12-22T12:10:55.940831Z",
     "iopub.status.idle": "2023-12-22T12:10:55.997847Z",
     "shell.execute_reply": "2023-12-22T12:10:55.996867Z",
     "shell.execute_reply.started": "2023-12-22T12:10:55.941827Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimDate (\n",
    "    SK_DateID INT UNSIGNED NOT NULL,\n",
    "    DateValue DATE NOT NULL,\n",
    "    DateDesc CHAR(20) NOT NULL,\n",
    "    CalendarYearID SMALLINT UNSIGNED NOT NULL,\n",
    "    CalendarYearDesc CHAR(20) NOT NULL,\n",
    "    CalendarQtrID SMALLINT UNSIGNED NOT NULL,\n",
    "    CalendarQtrDesc CHAR(20) NOT NULL,\n",
    "    CalendarMonthID MEDIUMINT UNSIGNED NOT NULL,\n",
    "    CalendarMonthDesc CHAR(20) NOT NULL,\n",
    "    CalendarWeekID MEDIUMINT UNSIGNED NOT NULL,\n",
    "    CalendarWeekDesc CHAR(20) NOT NULL,\n",
    "    DayOfWeekNum TINYINT UNSIGNED NOT NULL,\n",
    "    DayOfWeekDesc CHAR(10) NOT NULL,\n",
    "    FiscalYearID SMALLINT UNSIGNED NOT NULL,\n",
    "    FiscalYearDesc CHAR(20) NOT NULL,\n",
    "    FiscalQtrID SMALLINT UNSIGNED NOT NULL,\n",
    "    FiscalQtrDesc CHAR(20) NOT NULL,\n",
    "    HolidayFlag BOOLEAN,\n",
    "    PRIMARY KEY (SK_DateID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:56.095076Z",
     "iopub.status.busy": "2023-12-22T12:10:56.094092Z",
     "iopub.status.idle": "2023-12-22T12:10:57.993106Z",
     "shell.execute_reply": "2023-12-22T12:10:57.992135Z",
     "shell.execute_reply.started": "2023-12-22T12:10:56.095076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25933"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.to_sql(name='dimdate', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:57.996107Z",
     "iopub.status.busy": "2023-12-22T12:10:57.995119Z",
     "iopub.status.idle": "2023-12-22T12:10:58.413153Z",
     "shell.execute_reply": "2023-12-22T12:10:58.412146Z",
     "shell.execute_reply.started": "2023-12-22T12:10:57.996107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_TimeID</th>\n",
       "      <th>TimeValue</th>\n",
       "      <th>HourID</th>\n",
       "      <th>HourDesc</th>\n",
       "      <th>MinuteID</th>\n",
       "      <th>MinuteDesc</th>\n",
       "      <th>SecondID</th>\n",
       "      <th>SecondDesc</th>\n",
       "      <th>MarketHoursFlag</th>\n",
       "      <th>OfficeHoursFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_TimeID TimeValue  HourID HourDesc  MinuteID MinuteDesc  SecondID  \\\n",
       "0          0  00:00:00       0       00         0      00:00         0   \n",
       "1          1  00:00:01       0       00         0      00:00         1   \n",
       "2          2  00:00:02       0       00         0      00:00         2   \n",
       "3          3  00:00:03       0       00         0      00:00         3   \n",
       "4          4  00:00:04       0       00         0      00:00         4   \n",
       "\n",
       "  SecondDesc  MarketHoursFlag  OfficeHoursFlag  \n",
       "0   00:00:00            False            False  \n",
       "1   00:00:01            False            False  \n",
       "2   00:00:02            False            False  \n",
       "3   00:00:03            False            False  \n",
       "4   00:00:04            False            False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file\n",
    "file_path = DATA_DIR + \"Time.txt\"\n",
    "dim_time_df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"SK_TimeID\", \"TimeValue\", \"HourID\", \"HourDesc\", \n",
    "        \"MinuteID\", \"MinuteDesc\", \"SecondID\", \"SecondDesc\",\n",
    "        \"MarketHoursFlag\", \"OfficeHoursFlag\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"SK_TimeID\": \"uint32\", \"HourID\": \"uint8\", \n",
    "        \"HourDesc\": \"str\", \"MinuteID\": \"uint8\", \"MinuteDesc\": \"str\", \n",
    "        \"SecondID\": \"uint8\", \"SecondDesc\": \"str\", \"MarketHoursFlag\": \"bool\", \n",
    "        \"OfficeHoursFlag\": \"bool\"\n",
    "    },\n",
    "    parse_dates=[\"TimeValue\"],\n",
    "    date_format=\"%H:%M:%S\"\n",
    ")\n",
    "dim_time_df['TimeValue'] = dim_time_df['TimeValue'].dt.time\n",
    "\n",
    "dim_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:58.416108Z",
     "iopub.status.busy": "2023-12-22T12:10:58.415107Z",
     "iopub.status.idle": "2023-12-22T12:10:58.428110Z",
     "shell.execute_reply": "2023-12-22T12:10:58.427112Z",
     "shell.execute_reply.started": "2023-12-22T12:10:58.416108Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_TimeID\": sqlalchemy.types.BigInteger,\n",
    "    \"TimeValue\": sqlalchemy.types.Time,\n",
    "    \"HourID\": sqlalchemy.types.SmallInteger,\n",
    "    \"HourDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"MinuteID\": sqlalchemy.types.SmallInteger,\n",
    "    \"MinuteDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"SecondID\": sqlalchemy.types.SmallInteger,\n",
    "    \"SecondDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"MarketHoursFlag\": sqlalchemy.types.Boolean,\n",
    "    \"OfficeHoursFlag\": sqlalchemy.types.Boolean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:10:58.431132Z",
     "iopub.status.busy": "2023-12-22T12:10:58.430108Z",
     "iopub.status.idle": "2023-12-22T12:11:02.155205Z",
     "shell.execute_reply": "2023-12-22T12:11:02.154206Z",
     "shell.execute_reply.started": "2023-12-22T12:10:58.431132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimTime (\n",
    "    SK_TimeID INT UNSIGNED NOT NULL,\n",
    "    TimeValue TIME(3) NOT NULL,\n",
    "    HourID TINYINT UNSIGNED NOT NULL,\n",
    "    HourDesc CHAR(20) NOT NULL,\n",
    "    MinuteID TINYINT UNSIGNED NOT NULL,\n",
    "    MinuteDesc CHAR(20) NOT NULL,\n",
    "    SecondID TINYINT UNSIGNED NOT NULL,\n",
    "    SecondDesc CHAR(20) NOT NULL,\n",
    "    MarketHoursFlag BOOLEAN,\n",
    "    OfficeHoursFlag BOOLEAN,\n",
    "    PRIMARY KEY (SK_TimeID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))\n",
    "dim_time_df.to_sql(name='dimtime', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.157212Z",
     "iopub.status.busy": "2023-12-22T12:11:02.156235Z",
     "iopub.status.idle": "2023-12-22T12:11:02.171220Z",
     "shell.execute_reply": "2023-12-22T12:11:02.169210Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.157212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "file_path = r\"..\\data\\sf5\\Batch1\\Industry.txt\"\n",
    "industry_df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"IN_ID\", \"IN_NAME\", \"IN_SC_ID\"],\n",
    "    dtype={\n",
    "        \"IN_ID\": \"str\",\n",
    "        \"IN_NAME\": \"str\",\n",
    "        \"IN_SC_ID\": \"str\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.173209Z",
     "iopub.status.busy": "2023-12-22T12:11:02.173209Z",
     "iopub.status.idle": "2023-12-22T12:11:02.187215Z",
     "shell.execute_reply": "2023-12-22T12:11:02.185269Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.173209Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"IN_ID\": sqlalchemy.types.CHAR(length=2),\n",
    "    \"IN_NAME\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"IN_SC_ID\": sqlalchemy.types.CHAR(length=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.191208Z",
     "iopub.status.busy": "2023-12-22T12:11:02.189208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.233208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.231209Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.190209Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Industry (\n",
    "    IN_ID CHAR(2) NOT NULL,\n",
    "    IN_NAME CHAR(50) NOT NULL,\n",
    "    IN_SC_ID CHAR(4) NOT NULL,\n",
    "    PRIMARY KEY (IN_ID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.236212Z",
     "iopub.status.busy": "2023-12-22T12:11:02.235208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.264209Z",
     "shell.execute_reply": "2023-12-22T12:11:02.263235Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.236212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_df.to_sql(name=\"industry\", con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### StatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.267207Z",
     "iopub.status.busy": "2023-12-22T12:11:02.266206Z",
     "iopub.status.idle": "2023-12-22T12:11:02.295208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.294205Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.267207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST_ID</th>\n",
       "      <th>ST_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTV</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMPT</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNCL</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PNDG</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBMT</td>\n",
       "      <td>Submitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ST_ID    ST_NAME\n",
       "0  ACTV     Active\n",
       "1  CMPT  Completed\n",
       "2  CNCL   Canceled\n",
       "3  PNDG    Pending\n",
       "4  SBMT  Submitted"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read StatusType data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\StatusType.txt\"\n",
    "status_type_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"ST_ID\", \"ST_NAME\"],\n",
    "    dtype={\"ST_ID\": \"str\", \"ST_NAME\": \"str\"}\n",
    ")\n",
    "status_type_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.300206Z",
     "iopub.status.busy": "2023-12-22T12:11:02.299207Z",
     "iopub.status.idle": "2023-12-22T12:11:02.310208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.309208Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.300206Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"ST_ID\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"ST_NAME\": sqlalchemy.types.CHAR(length=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.312206Z",
     "iopub.status.busy": "2023-12-22T12:11:02.312206Z",
     "iopub.status.idle": "2023-12-22T12:11:02.405208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.403206Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.312206Z"
    }
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE StatusType (\n",
    "    ST_ID CHAR(4) NOT NULL,\n",
    "    ST_NAME CHAR(10) NOT NULL,\n",
    "    PRIMARY KEY (ST_ID)\n",
    ");\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.408214Z",
     "iopub.status.busy": "2023-12-22T12:11:02.407213Z",
     "iopub.status.idle": "2023-12-22T12:11:02.435206Z",
     "shell.execute_reply": "2023-12-22T12:11:02.434206Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.408214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_type_df.to_sql(name=\"statustype\", con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TradeType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.438209Z",
     "iopub.status.busy": "2023-12-22T12:11:02.437209Z",
     "iopub.status.idle": "2023-12-22T12:11:02.450206Z",
     "shell.execute_reply": "2023-12-22T12:11:02.449207Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.438209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read TradeType data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\TradeType.txt\"\n",
    "trade_type_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"TT_ID\", \"TT_NAME\", \"TT_IS_SELL\", \"TT_IS_MRKT\"],\n",
    "    dtype={\"TT_ID\": \"str\", \"TT_NAME\": \"str\", \"TT_IS_SELL\": \"uint8\", \"TT_IS_MRKT\": \"uint8\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.452205Z",
     "iopub.status.busy": "2023-12-22T12:11:02.451206Z",
     "iopub.status.idle": "2023-12-22T12:11:02.528207Z",
     "shell.execute_reply": "2023-12-22T12:11:02.527205Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.452205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {\n",
    "    \"TT_ID\": sqlalchemy.types.CHAR(length=3),\n",
    "    \"TT_NAME\": sqlalchemy.types.CHAR(length=12),\n",
    "    \"TT_IS_SELL\": sqlalchemy.types.SmallInteger,\n",
    "    \"TT_IS_MRKT\": sqlalchemy.types.SmallInteger\n",
    "}\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE TradeType (\n",
    "    TT_ID CHAR(3) NOT NULL,\n",
    "    TT_NAME CHAR(12) NOT NULL,\n",
    "    TT_IS_SELL TINYINT UNSIGNED NOT NULL CHECK (TT_IS_SELL IN (0, 1)),\n",
    "    TT_IS_MRKT TINYINT UNSIGNED NOT NULL CHECK (TT_IS_MRKT IN (0, 1)),\n",
    "    PRIMARY KEY (TT_ID)\n",
    ");\"\"\"))\n",
    "trade_type_df.to_sql(name=\"tradetype\", con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TaxRate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.530206Z",
     "iopub.status.busy": "2023-12-22T12:11:02.529206Z",
     "iopub.status.idle": "2023-12-22T12:11:02.543208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.542207Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.530206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read TaxRate data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\TaxRate.txt\"\n",
    "tax_rate_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"TX_ID\", \"TX_NAME\", \"TX_RATE\"],\n",
    "    dtype={\"TX_ID\": \"str\", \"TX_NAME\": \"str\", \"TX_RATE\": \"float64\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.546208Z",
     "iopub.status.busy": "2023-12-22T12:11:02.545208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.606207Z",
     "shell.execute_reply": "2023-12-22T12:11:02.605208Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.546208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dtypes = {\n",
    "    \"TX_ID\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"TX_NAME\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"TX_RATE\": sqlalchemy.types.Numeric(precision=6, scale=5)\n",
    "}\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE TaxRate (\n",
    "    TX_ID CHAR(4) NOT NULL,\n",
    "    TX_NAME CHAR(50) NOT NULL,\n",
    "    TX_RATE DECIMAL(6, 5) NOT NULL,\n",
    "    PRIMARY KEY (TX_ID)\n",
    ");\"\"\"))\n",
    "\n",
    "tax_rate_df.to_sql(name=\"taxrate\", con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.609207Z",
     "iopub.status.busy": "2023-12-22T12:11:02.608208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.717208Z",
     "shell.execute_reply": "2023-12-22T12:11:02.715213Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.609207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>EmployeeFirstName</th>\n",
       "      <th>EmployeeLastName</th>\n",
       "      <th>EmployeeMI</th>\n",
       "      <th>EmployeeJobCode</th>\n",
       "      <th>EmployeeBranch</th>\n",
       "      <th>EmployeeOffice</th>\n",
       "      <th>EmployeePhone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>Ozkan</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>647</td>\n",
       "      <td>EGZKSobTeknHCbLuHczvWmhTmCSGXD</td>\n",
       "      <td>OFFICE7152</td>\n",
       "      <td>(726) 088-3331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>689</td>\n",
       "      <td>Suer</td>\n",
       "      <td>Candice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>OfOBVvpzNvHCebxyuxXFwsMju  JRU</td>\n",
       "      <td>OFFICE8586</td>\n",
       "      <td>(344) 999-2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>410</td>\n",
       "      <td>Somisetty</td>\n",
       "      <td>Jami</td>\n",
       "      <td>P</td>\n",
       "      <td>534</td>\n",
       "      <td>rAHWYkktOXAyPAYHlncZPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(984) 538-5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>412</td>\n",
       "      <td>Mazurek</td>\n",
       "      <td>Rosalinda</td>\n",
       "      <td>J</td>\n",
       "      <td>364</td>\n",
       "      <td>TJQqsUQQGqWG QleLheUoYlgRNVT</td>\n",
       "      <td>OFFICE8487</td>\n",
       "      <td>(860) 037-6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2173</td>\n",
       "      <td>Aronovich</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>M</td>\n",
       "      <td>314</td>\n",
       "      <td>IEMJHuQgCPDHCwwJkgQQeaqGvzMcVD</td>\n",
       "      <td>OFFICE9420</td>\n",
       "      <td>(604) 387-9350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  ManagerID EmployeeFirstName EmployeeLastName EmployeeMI  \\\n",
       "0           0        351             Ozkan          Douglas        NaN   \n",
       "1           1        689              Suer          Candice        NaN   \n",
       "2           2        410         Somisetty             Jami          P   \n",
       "3           3        412           Mazurek        Rosalinda          J   \n",
       "4           4       2173         Aronovich         Delphine          M   \n",
       "\n",
       "   EmployeeJobCode                  EmployeeBranch EmployeeOffice  \\\n",
       "0              647  EGZKSobTeknHCbLuHczvWmhTmCSGXD     OFFICE7152   \n",
       "1              314  OfOBVvpzNvHCebxyuxXFwsMju  JRU     OFFICE8586   \n",
       "2              534          rAHWYkktOXAyPAYHlncZPG            NaN   \n",
       "3              364    TJQqsUQQGqWG QleLheUoYlgRNVT     OFFICE8487   \n",
       "4              314  IEMJHuQgCPDHCwwJkgQQeaqGvzMcVD     OFFICE9420   \n",
       "\n",
       "    EmployeePhone  \n",
       "0  (726) 088-3331  \n",
       "1  (344) 999-2652  \n",
       "2  (984) 538-5366  \n",
       "3  (860) 037-6897  \n",
       "4  (604) 387-9350  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_df = pd.read_csv(\n",
    "    r\"..\\data\\sf5\\Batch1\\HR.csv\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"EmployeeID\", \"ManagerID\", \"EmployeeFirstName\", \"EmployeeLastName\",\n",
    "        \"EmployeeMI\", \"EmployeeJobCode\", \"EmployeeBranch\",\n",
    "        \"EmployeeOffice\", \"EmployeePhone\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"EmployeeID\": \"uint32\",\n",
    "        \"ManagerID\": \"uint32\",\n",
    "        \"EmployeeFirstName\": \"str\",\n",
    "        \"EmployeeLastName\": \"str\",\n",
    "        \"EmployeeMI\": \"str\",\n",
    "        \"EmployeeJobCode\": \"UInt16\",\n",
    "        \"EmployeeBranch\": \"str\",\n",
    "        \"EmployeeOffice\": \"str\",\n",
    "        \"EmployeePhone\": \"str\"\n",
    "    }\n",
    ")\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.719209Z",
     "iopub.status.busy": "2023-12-22T12:11:02.718208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.763205Z",
     "shell.execute_reply": "2023-12-22T12:11:02.762225Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.719209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\84927967.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df.drop(columns=['EmployeeJobCode'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrokerID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>MiddleInitial</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Office</th>\n",
       "      <th>Phone</th>\n",
       "      <th>SK_BrokerID</th>\n",
       "      <th>IsCurrent</th>\n",
       "      <th>BatchID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>689</td>\n",
       "      <td>Suer</td>\n",
       "      <td>Candice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OfOBVvpzNvHCebxyuxXFwsMju  JRU</td>\n",
       "      <td>OFFICE8586</td>\n",
       "      <td>(344) 999-2652</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2173</td>\n",
       "      <td>Aronovich</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>M</td>\n",
       "      <td>IEMJHuQgCPDHCwwJkgQQeaqGvzMcVD</td>\n",
       "      <td>OFFICE9420</td>\n",
       "      <td>(604) 387-9350</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1073</td>\n",
       "      <td>Hansen</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>T</td>\n",
       "      <td>sGIpORbLsRjTdhqBNBQppRRkp</td>\n",
       "      <td>OFFICE6343</td>\n",
       "      <td>(991) 491-4907</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1130</td>\n",
       "      <td>Charchanko</td>\n",
       "      <td>Sheela</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cw QJMHPgpozCKsFZMmmbokwSRTPD</td>\n",
       "      <td>OFFICE7705</td>\n",
       "      <td>(977) 726-0106</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1832</td>\n",
       "      <td>Knorp</td>\n",
       "      <td>Uday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QmCLAAAJibegHoPZcQJCdDfukiRQo</td>\n",
       "      <td>OFFICE6437</td>\n",
       "      <td>(254) 560-8156</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BrokerID  ManagerID   FirstName  LastName MiddleInitial  \\\n",
       "1          1        689        Suer   Candice           NaN   \n",
       "4          4       2173   Aronovich  Delphine             M   \n",
       "8          8       1073      Hansen  Montreal             T   \n",
       "11        11       1130  Charchanko    Sheela           NaN   \n",
       "14        14       1832       Knorp      Uday           NaN   \n",
       "\n",
       "                            Branch      Office           Phone  SK_BrokerID  \\\n",
       "1   OfOBVvpzNvHCebxyuxXFwsMju  JRU  OFFICE8586  (344) 999-2652            1   \n",
       "4   IEMJHuQgCPDHCwwJkgQQeaqGvzMcVD  OFFICE9420  (604) 387-9350            2   \n",
       "8       sGIpORbLsRjTdhqBNBQppRRkp   OFFICE6343  (991) 491-4907            3   \n",
       "11   Cw QJMHPgpozCKsFZMmmbokwSRTPD  OFFICE7705  (977) 726-0106            4   \n",
       "14   QmCLAAAJibegHoPZcQJCdDfukiRQo  OFFICE6437  (254) 560-8156            5   \n",
       "\n",
       "    IsCurrent  BatchID EffectiveDate    EndDate  \n",
       "1        True        1    1950-01-01 9999-12-31  \n",
       "4        True        1    1950-01-01 9999-12-31  \n",
       "8        True        1    1950-01-01 9999-12-31  \n",
       "11       True        1    1950-01-01 9999-12-31  \n",
       "14       True        1    1950-01-01 9999-12-31  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Filter Records\n",
    "filtered_df = hr_df[hr_df['EmployeeJobCode'] == 314]\n",
    "filtered_df.drop(columns=['EmployeeJobCode'], inplace=True)\n",
    "# 2. Map Columns\n",
    "DimBroker = filtered_df.rename(columns={\n",
    "    'EmployeeID': 'BrokerID',\n",
    "    'ManagerID': 'ManagerID',\n",
    "    'EmployeeFirstName': 'FirstName',\n",
    "    'EmployeeLastName': 'LastName',\n",
    "    'EmployeeMI': 'MiddleInitial',\n",
    "    'EmployeeBranch': 'Branch',\n",
    "    'EmployeeOffice': 'Office',\n",
    "    'EmployeePhone': 'Phone'\n",
    "})\n",
    "# 3. Handle Surrogate Key (SK_BrokerID)\n",
    "# Using cumcount to generate a unique ID for each row\n",
    "DimBroker.loc[:, 'SK_BrokerID'] = range(1, len(DimBroker) + 1)\n",
    "\n",
    "# 4. Set Default Values for New Fields\n",
    "DimBroker.loc[:, 'IsCurrent'] = True\n",
    "DimBroker.loc[:, 'BatchID'] = BATCH_ID\n",
    "# EffectiveDate is set to the earliest date in the DimDate table and EndDate is set to 9999- 12-31\n",
    "DimBroker.loc[:, 'EffectiveDate'] = pd.read_sql_query(\"SELECT MIN(datevalue) FROM dimdate\", engine).iloc[0, 0]\n",
    "DimBroker.loc[:, 'EndDate'] = pd.Timestamp('9999-12-31')\n",
    "\n",
    "# Display the first few rows of the newly created DimBroker DataFrame\n",
    "DimBroker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.766212Z",
     "iopub.status.busy": "2023-12-22T12:11:02.765214Z",
     "iopub.status.idle": "2023-12-22T12:11:02.780206Z",
     "shell.execute_reply": "2023-12-22T12:11:02.778206Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.766212Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_BrokerID\": sqlalchemy.types.BigInteger,\n",
    "    \"BrokerID\": sqlalchemy.types.BigInteger,\n",
    "    \"ManagerID\": sqlalchemy.types.BigInteger,\n",
    "    \"FirstName\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"LastName\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"MiddleInitial\": sqlalchemy.types.CHAR(length=1),\n",
    "    \"Branch\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"Office\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"Phone\": sqlalchemy.types.CHAR(length=14),\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.Integer,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.782209Z",
     "iopub.status.busy": "2023-12-22T12:11:02.781208Z",
     "iopub.status.idle": "2023-12-22T12:11:02.810207Z",
     "shell.execute_reply": "2023-12-22T12:11:02.808209Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.782209Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimBroker (\n",
    "    SK_BrokerID INT UNSIGNED NOT NULL,\n",
    "    BrokerID INT UNSIGNED NOT NULL,\n",
    "    ManagerID INT UNSIGNED,\n",
    "    FirstName CHAR(50) NOT NULL,\n",
    "    LastName CHAR(50) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Branch CHAR(50),\n",
    "    Office CHAR(50),\n",
    "    Phone CHAR(14),\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_BrokerID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:02.813210Z",
     "iopub.status.busy": "2023-12-22T12:11:02.812237Z",
     "iopub.status.idle": "2023-12-22T12:11:03.354269Z",
     "shell.execute_reply": "2023-12-22T12:11:03.353533Z",
     "shell.execute_reply.started": "2023-12-22T12:11:02.812237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7144"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DimBroker.to_sql(name='dimbroker', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimCompany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.356268Z",
     "iopub.status.busy": "2023-12-22T12:11:03.356268Z",
     "iopub.status.idle": "2023-12-22T12:11:03.370266Z",
     "shell.execute_reply": "2023-12-22T12:11:03.369268Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.356268Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_finwire(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 60, 10, 4, 2, 4, 8, 80, 80, 12, 25, 20, 24, 46, 150]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"CompanyName\", \"CIK\", \"Status\", \"IndustryID\",\n",
    "        \"SPrating\", \"FoundingDate\", \"AddrLine1\", \"AddrLine2\", \"PostalCode\",\n",
    "        \"City\", \"StateProvince\", \"Country\", \"CEOname\", \"Description\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_cmp = df[df['RecType'] == 'CMP']\n",
    "    return df_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.373267Z",
     "iopub.status.busy": "2023-12-22T12:11:03.372268Z",
     "iopub.status.idle": "2023-12-22T12:11:03.401267Z",
     "shell.execute_reply": "2023-12-22T12:11:03.400267Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.373267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query StatusType table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    statustype_df = pd.read_sql(\"SELECT * FROM statustype\", conn)\n",
    "status_mapping = dict(statustype_df[[\"ST_ID\", \"ST_NAME\"]].values)\n",
    "\n",
    "# Query Industry table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    industry_df = pd.read_sql(\"SELECT * FROM industry\", conn)\n",
    "industry_mapping = dict(industry_df[[\"IN_ID\", \"IN_NAME\"]].values)\n",
    "\n",
    "# Valid SPrating values\n",
    "valid_spratings = [\n",
    "    \"AAA\",\n",
    "    \"AA+\",\n",
    "    \"AA\",\n",
    "    \"AA-\",\n",
    "    \"A+\",\n",
    "    \"A\",\n",
    "    \"A-\",\n",
    "    \"BBB+\",\n",
    "    \"BBB\",\n",
    "    \"BBB-\",\n",
    "    \"BB+\",\n",
    "    \"BB\",\n",
    "    \"BB-\",\n",
    "    \"B+\",\n",
    "    \"B\",\n",
    "    \"B-\",\n",
    "    \"CCC+\",\n",
    "    \"CCC\",\n",
    "    \"CCC-\",\n",
    "    \"CC\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.404270Z",
     "iopub.status.busy": "2023-12-22T12:11:03.403291Z",
     "iopub.status.idle": "2023-12-22T12:11:03.417267Z",
     "shell.execute_reply": "2023-12-22T12:11:03.416313Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.404270Z"
    }
   },
   "outputs": [],
   "source": [
    "files = os.listdir(DATA_DIR)\n",
    "finwire_files = [file for file in files if file.startswith(\"FINWIRE\") and 'audit' not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.419266Z",
     "iopub.status.busy": "2023-12-22T12:11:03.418266Z",
     "iopub.status.idle": "2023-12-22T12:11:03.433267Z",
     "shell.execute_reply": "2023-12-22T12:11:03.432269Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.419266Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CompanyID\": sqlalchemy.types.BigInteger,\n",
    "    \"CompanyID\": sqlalchemy.types.BigInteger,\n",
    "    \"Status\": sqlalchemy.types.CHAR(length=10),\n",
    "    \"Name\": sqlalchemy.types.CHAR(length=60),\n",
    "    \"Industry\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"SPrating\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"isLowGrade\": sqlalchemy.types.Boolean,\n",
    "    \"CEO\": sqlalchemy.types.CHAR(length=100),\n",
    "    \"AddressLine1\": sqlalchemy.types.CHAR(length=80),\n",
    "    \"AddressLine2\": sqlalchemy.types.CHAR(length=80),\n",
    "    \"PostalCode\": sqlalchemy.types.CHAR(length=12),\n",
    "    \"City\": sqlalchemy.types.CHAR(length=25),\n",
    "    \"StateProv\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"Country\": sqlalchemy.types.CHAR(length=24),\n",
    "    \"Description\": sqlalchemy.types.CHAR(length=150),\n",
    "    \"FoundingDate\": sqlalchemy.types.Date,\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.Integer,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.437270Z",
     "iopub.status.busy": "2023-12-22T12:11:03.436269Z",
     "iopub.status.idle": "2023-12-22T12:11:03.465276Z",
     "shell.execute_reply": "2023-12-22T12:11:03.463269Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.437270Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dimcompany(filename, is_first_batch=False):\n",
    "    file_path = DATA_DIR + filename\n",
    "    df_cmp = read_finwire(file_path)\n",
    "\n",
    "    if len(df_cmp) == 0:\n",
    "        return\n",
    "    \n",
    "    # Define the column names and data types\n",
    "    column_names = [\n",
    "        \"SK_CompanyID\",\n",
    "        \"CompanyID\",\n",
    "        \"Status\",\n",
    "        \"Name\",\n",
    "        \"Industry\",\n",
    "        \"SPrating\",\n",
    "        \"isLowGrade\",\n",
    "        \"CEO\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "        \"City\",\n",
    "        \"StateProv\",\n",
    "        \"Country\",\n",
    "        \"Description\",\n",
    "        \"FoundingDate\",\n",
    "        \"IsCurrent\",\n",
    "        \"BatchID\",\n",
    "        \"EffectiveDate\",\n",
    "        \"EndDate\",\n",
    "    ]\n",
    "    dtypes = {\n",
    "        \"SK_CompanyID\": \"uint32\",\n",
    "        \"CompanyID\": \"uint32\",\n",
    "        \"Status\": \"str\",\n",
    "        \"Name\": \"str\",\n",
    "        \"Industry\": \"str\",\n",
    "        \"SPrating\": \"str\",\n",
    "        \"isLowGrade\": \"boolean\",\n",
    "        \"CEO\": \"str\",\n",
    "        \"AddressLine1\": \"str\",\n",
    "        \"AddressLine2\": \"str\",\n",
    "        \"PostalCode\": \"str\",\n",
    "        \"City\": \"str\",\n",
    "        \"StateProv\": \"str\",\n",
    "        \"Country\": \"str\",\n",
    "        \"Description\": \"str\",\n",
    "        \"FoundingDate\": \"datetime64[ns]\",\n",
    "        \"IsCurrent\": \"bool\",\n",
    "        \"BatchID\": \"uint8\",\n",
    "        \"EffectiveDate\": \"datetime64[ns]\",\n",
    "        \"EndDate\": \"datetime64[ns]\",\n",
    "    }\n",
    "    # Create an empty DataFrame with the specified schema\n",
    "    dimCompany = pd.DataFrame(columns=column_names).astype(dtypes)\n",
    "\n",
    "    # Copy and map relevant columns\n",
    "    df_cmp[\"CIK\"] = pd.to_numeric(df_cmp[\"CIK\"], downcast=\"unsigned\")\n",
    "    dimCompany[\"CompanyID\"] = pd.to_numeric(df_cmp[\"CIK\"], downcast=\"unsigned\")\n",
    "    dimCompany[\"Name\"] = df_cmp[\"CompanyName\"].str.strip()\n",
    "    dimCompany[\"SPrating\"] = df_cmp[\"SPrating\"].str.upper()\n",
    "    dimCompany[\"CEO\"] = df_cmp[\"CEOname\"].str.strip()\n",
    "    dimCompany[\"Description\"] = df_cmp[\"Description\"].str.strip()\n",
    "    dimCompany[\"FoundingDate\"] = pd.to_datetime(\n",
    "        df_cmp[\"FoundingDate\"], format=\"%Y%m%d\", errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # For address fields\n",
    "    dimCompany[\"AddressLine1\"] = df_cmp[\"AddrLine1\"].str.strip()\n",
    "    dimCompany[\"AddressLine2\"] = df_cmp[\"AddrLine2\"].str.strip()\n",
    "    dimCompany[\"PostalCode\"] = df_cmp[\"PostalCode\"].str.strip()\n",
    "    dimCompany[\"City\"] = df_cmp[\"City\"].str.strip()\n",
    "    dimCompany[\"StateProv\"] = df_cmp[\"StateProvince\"].str.strip()\n",
    "    dimCompany[\"Country\"] = df_cmp[\"Country\"].str.strip()\n",
    "\n",
    "    # Replace all-blank strings with None (NULL)\n",
    "    for col in [\n",
    "        \"Name\",\n",
    "        \"SPrating\",\n",
    "        \"CEO\",\n",
    "        \"Description\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "        \"City\",\n",
    "        \"StateProv\",\n",
    "        \"Country\",\n",
    "    ]:\n",
    "        dimCompany[col] = dimCompany[col].replace(r\"^\\s*$\", None, regex=True)\n",
    "\n",
    "    # Update Status in dimCompany\n",
    "    dimCompany[\"Status\"] = df_cmp[\"Status\"].map(status_mapping)\n",
    "    # Update Industry in dimCompany\n",
    "    dimCompany[\"Industry\"] = df_cmp[\"IndustryID\"].map(industry_mapping)\n",
    "    # isLowGrade is set to False if SPrating begins with A or BBB otherwise set to True\n",
    "    dimCompany[\"isLowGrade\"] = ~df_cmp[\"SPrating\"].str.startswith((\"A\", \"BBB\"))\n",
    "\n",
    "    # Identify invalid SPratings\n",
    "    invalid_sprating_mask = ~dimCompany[\"SPrating\"].isin(valid_spratings)\n",
    "    # Filter dimCompany for invalid SPrating\n",
    "    invalid_sprating_data = dimCompany[invalid_sprating_mask]\n",
    "    if len(invalid_sprating_data) > 0:\n",
    "        message_data = (\n",
    "            \"CO_ID = \"\n",
    "            + invalid_sprating_data[\"CompanyID\"].astype(str)\n",
    "            + \", CO_SP_RATE = \"\n",
    "            + invalid_sprating_data[\"SPrating\"]\n",
    "        )\n",
    "        # Create DImessages DataFrame\n",
    "        dimessages = pd.DataFrame(\n",
    "            {\n",
    "                \"MessageDateAndTime\": [datetime.now()] * len(message_data),\n",
    "                \"BatchID\": [1] * len(message_data),\n",
    "                \"MessageSource\": [\"DimCompany\"] * len(message_data),\n",
    "                \"MessageText\": [\"Invalid SPRating\"] * len(message_data),\n",
    "                \"MessageType\": [\"Alert\"] * len(message_data),\n",
    "                \"MessageData\": message_data,\n",
    "            }\n",
    "        )\n",
    "        # Update dimCompany for invalid SPrating\n",
    "        dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
    "        # Insert DImessages into MySQL\n",
    "        dimessages.to_sql(\"dimessages\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    dimCompany.loc[:, \"BatchID\"] = 1\n",
    "    dimCompany[\"EffectiveDate\"] = pd.to_datetime(df_cmp[\"PTS\"], format=\"%Y%m%d-%H%M%S\")\n",
    "    # Identify new and existing records based on CIK\n",
    "    if is_first_batch:\n",
    "        new_records = dimCompany\n",
    "        existing_records = pd.DataFrame(columns=column_names).astype(dtypes)\n",
    "        next_sk_id = 0\n",
    "    else:\n",
    "        existing_cik = pd.read_sql_query(\n",
    "            \"SELECT CompanyID FROM dimCompany WHERE IsCurrent = 1\", engine\n",
    "        )[\"CompanyID\"]\n",
    "        new_records = dimCompany[~df_cmp[\"CIK\"].isin(existing_cik)]\n",
    "        existing_records = dimCompany[df_cmp[\"CIK\"].isin(existing_cik)]\n",
    "        next_sk_id_query = \"SELECT MAX(SK_CompanyID) FROM dimCompany\"\n",
    "        next_sk_id = pd.read_sql_query(next_sk_id_query, engine).iloc[0, 0] or 0\n",
    "\n",
    "    new_records.loc[:, \"SK_CompanyID\"] = range(\n",
    "        next_sk_id + 1, next_sk_id + 1 + len(new_records)\n",
    "    )\n",
    "    new_records.loc[:, \"IsCurrent\"] = True\n",
    "    new_records.loc[:, \"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "    new_records.to_sql(\n",
    "        \"dimcompany\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "    )\n",
    "    next_sk_id = new_records[\"SK_CompanyID\"].max()\n",
    "\n",
    "    # Process existing records\n",
    "    for _, row in existing_records.iterrows():\n",
    "        effective_date = row[\"EffectiveDate\"]\n",
    "        company_id = row[\"CompanyID\"]\n",
    "        # get the current record\n",
    "        select_query = f\"\"\"SELECT * FROM dimCompany\n",
    "        WHERE CompanyID = '{company_id}' AND IsCurrent = 1\"\"\"\n",
    "        existing_record = pd.read_sql(select_query, engine).iloc[0]\n",
    "        compare_cols = [\n",
    "            \"Status\",\n",
    "            \"Name\",\n",
    "            \"Industry\",\n",
    "            \"SPrating\",\n",
    "            \"isLowGrade\",\n",
    "            \"CEO\",\n",
    "            \"AddressLine1\",\n",
    "            \"AddressLine2\",\n",
    "            \"PostalCode\",\n",
    "            \"City\",\n",
    "            \"StateProv\",\n",
    "            \"Country\",\n",
    "            \"Description\",\n",
    "            \"FoundingDate\",\n",
    "        ]\n",
    "        is_same = True\n",
    "        for col in compare_cols:\n",
    "            if row[col] != existing_record[col]:\n",
    "                is_same = False\n",
    "                break\n",
    "        if not is_same:\n",
    "            # Expire the current record in MySQL\n",
    "            update_query = f\"\"\"UPDATE dimcompany \n",
    "            SET IsCurrent = 0, EndDate = '{effective_date}' \n",
    "            WHERE CompanyID = '{company_id}' AND IsCurrent = 1\n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(update_query))\n",
    "                conn.commit()\n",
    "            # Insert updated record\n",
    "            row[\"SK_CompanyID\"] = next_sk_id + 1\n",
    "            row[\"IsCurrent\"] = True\n",
    "            row[\"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "            row_df = pd.DataFrame(row).T\n",
    "            # insert records with existing SK_CompanyID\n",
    "            row_df.to_sql(\n",
    "                \"dimcompany\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "            )        \n",
    "            next_sk_id += 1\n",
    "\n",
    "    return df_cmp, new_records, existing_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.468268Z",
     "iopub.status.busy": "2023-12-22T12:11:03.467269Z",
     "iopub.status.idle": "2023-12-22T12:11:03.496267Z",
     "shell.execute_reply": "2023-12-22T12:11:03.495268Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.468268Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimCompany (\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    CompanyID INT UNSIGNED NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Name CHAR(60) NOT NULL,\n",
    "    Industry CHAR(50) NOT NULL,\n",
    "    SPrating CHAR(4),\n",
    "    isLowGrade BOOLEAN,\n",
    "    CEO CHAR(100) NOT NULL,\n",
    "    AddressLine1 CHAR(80),\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12) NOT NULL,\n",
    "    City CHAR(25) NOT NULL,\n",
    "    StateProv CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Description CHAR(150) NOT NULL,\n",
    "    FoundingDate DATE,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_CompanyID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:03.507265Z",
     "iopub.status.busy": "2023-12-22T12:11:03.507265Z",
     "iopub.status.idle": "2023-12-22T12:11:25.619159Z",
     "shell.execute_reply": "2023-12-22T12:11:25.618158Z",
     "shell.execute_reply.started": "2023-12-22T12:11:03.507265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0aa9850d6486c8dfe49f1e4c4eca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\221389655.py:120: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(tqdm(finwire_files)):\n",
    "    load_dimcompany(file, i == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:25.621131Z",
     "iopub.status.busy": "2023-12-22T12:11:25.620126Z",
     "iopub.status.idle": "2023-12-22T12:11:25.635128Z",
     "shell.execute_reply": "2023-12-22T12:11:25.633169Z",
     "shell.execute_reply.started": "2023-12-22T12:11:25.621131Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_finwire_fin(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 4, 1, 8, 8, 17, 17, 12, 12, 12, 17, 17, 17, 13, 13, 60]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"Year\", \"Quarter\", \"QtrStartDate\", \"PostingDate\",\n",
    "        \"Revenue\", \"Earnings\", \"EPS\", \"DilutedEPS\", \"Margin\", \"Inventory\",\n",
    "        \"Assets\", \"Liabilities\", \"ShOut\", \"DilutedShOut\", \"CoNameOrCIK\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df_fin = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_fin = df_fin[df_fin['RecType'] == 'FIN']\n",
    "    # Convert PTS to datetime\n",
    "    df_fin['PTS'] = pd.to_datetime(df_fin['PTS'], format='%Y%m%d-%H%M%S')\n",
    "\n",
    "    return df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:25.638127Z",
     "iopub.status.busy": "2023-12-22T12:11:25.637159Z",
     "iopub.status.idle": "2023-12-22T12:11:25.666134Z",
     "shell.execute_reply": "2023-12-22T12:11:25.664172Z",
     "shell.execute_reply.started": "2023-12-22T12:11:25.638127Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_financial():\n",
    "    files = os.listdir(DATA_DIR)\n",
    "    finwire_files = [file for file in files if file.startswith(\"FINWIRE\") and 'audit' not in file]\n",
    "    \n",
    "\n",
    "    for filename in tqdm(finwire_files):\n",
    "        file_path = DATA_DIR + filename\n",
    "        df_fin = read_finwire_fin(file_path)\n",
    "        if len(df_fin) == 0:\n",
    "            continue\n",
    "        # datatypes for the mysql table\n",
    "        sql_dtypes = {\n",
    "            \"SK_CompanyID\": sqlalchemy.types.BigInteger,\n",
    "            \"FI_YEAR\": sqlalchemy.types.Integer,\n",
    "            \"FI_QTR\": sqlalchemy.types.SmallInteger,\n",
    "            \"FI_QTR_START_DATE\": sqlalchemy.types.Date,\n",
    "            \"FI_REVENUE\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "            \"FI_NET_EARN\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "            \"FI_BASIC_EPS\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "            \"FI_DILUT_EPS\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "            \"FI_MARGIN\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "            \"FI_INVENTORY\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "            \"FI_ASSETS\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "            \"FI_LIABILITY\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "            \"FI_OUT_BASIC\": sqlalchemy.types.BigInteger,\n",
    "            \"FI_OUT_DILUT\": sqlalchemy.types.BigInteger\n",
    "        }\n",
    "\n",
    "        # data types for the DataFrame\n",
    "        dtypes = {\n",
    "            'SK_CompanyID': 'uint32',\n",
    "            'FI_YEAR': 'uint16',\n",
    "            'FI_QTR': 'uint8',\n",
    "            'FI_QTR_START_DATE': 'datetime64[ns]',\n",
    "            'FI_REVENUE': 'float64',\n",
    "            'FI_NET_EARN': 'float64',\n",
    "            'FI_BASIC_EPS': 'float64',\n",
    "            'FI_DILUT_EPS': 'float64',\n",
    "            'FI_MARGIN': 'float64',\n",
    "            'FI_INVENTORY': 'float64',\n",
    "            'FI_ASSETS': 'float64',\n",
    "            'FI_LIABILITY': 'float64',\n",
    "            'FI_OUT_BASIC': 'uint64',\n",
    "            'FI_OUT_DILUT': 'uint64'\n",
    "        }\n",
    "\n",
    "        # Create empty DataFrame\n",
    "        financial_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in dtypes.items()})\n",
    "\n",
    "        # copy directly\n",
    "        financial_df['FI_YEAR'] = pd.to_numeric(df_fin['Year'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_QTR'] = pd.to_numeric(df_fin['Quarter'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_QTR_START_DATE'] = pd.to_datetime(df_fin['QtrStartDate'], format='%Y%m%d')\n",
    "        financial_df['FI_REVENUE'] = pd.to_numeric(df_fin['Revenue'].str.strip(), downcast='float')\n",
    "        financial_df['FI_NET_EARN'] = pd.to_numeric(df_fin['Earnings'].str.strip(), downcast='float')\n",
    "        financial_df['FI_BASIC_EPS'] = pd.to_numeric(df_fin['EPS'].str.strip(), downcast='float')\n",
    "        financial_df['FI_DILUT_EPS'] = pd.to_numeric(df_fin['DilutedEPS'].str.strip(), downcast='float')\n",
    "        financial_df['FI_MARGIN'] = pd.to_numeric(df_fin['Margin'].str.strip(), downcast='float')\n",
    "        financial_df['FI_INVENTORY'] = pd.to_numeric(df_fin['Inventory'].str.strip(), downcast='float')\n",
    "        financial_df['FI_ASSETS'] = pd.to_numeric(df_fin['Assets'].str.strip(), downcast='float')\n",
    "        financial_df['FI_LIABILITY'] = pd.to_numeric(df_fin['Liabilities'].str.strip(), downcast='float')\n",
    "        financial_df['FI_OUT_BASIC'] = pd.to_numeric(df_fin['ShOut'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_OUT_DILUT'] = pd.to_numeric(df_fin['DilutedShOut'].str.strip(), downcast='unsigned')\n",
    "\n",
    "        # Split df_fin based on the length of CoNameOrCIK\n",
    "        df_fin_id = df_fin[df_fin['CoNameOrCIK'].str.len() == 10][['PTS', 'CoNameOrCIK']]\n",
    "        df_fin_id['PTS'] = df_fin_id['PTS'].dt.strftime('%Y-%m-%d')\n",
    "        df_fin_id['CoNameOrCIK'] = pd.to_numeric(df_fin_id['CoNameOrCIK'], downcast='unsigned')\n",
    "        df_fin_name = df_fin[df_fin['CoNameOrCIK'].str.len() != 10][['PTS', 'CoNameOrCIK']]\n",
    "        df_fin_name['PTS'] = df_fin_name['PTS'].dt.strftime('%Y-%m-%d')\n",
    "        df_fin_name['CoNameOrCIK'] = df_fin_name['CoNameOrCIK'].str.strip()\n",
    "\n",
    "        def build_query(df, id_or_name_col):\n",
    "            '''Function to build SQL query for date range checks'''\n",
    "            query_parts = []\n",
    "            for _, row in df.iterrows():\n",
    "                pts = row['PTS']\n",
    "                if id_or_name_col == 'CompanyID':\n",
    "                    company_id = row['CoNameOrCIK']\n",
    "                    query_part = f\"(CompanyID = {company_id} AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "                else:  # Name\n",
    "                    company_name = row['CoNameOrCIK']\n",
    "                    query_part = f\"(Name = '{company_name}' AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "                query_parts.append(query_part)\n",
    "            return ' OR '.join(query_parts)\n",
    "\n",
    "        # Execute query and map results for ID-based records\n",
    "        if not df_fin_id.empty:\n",
    "            query_id = f\"SELECT CompanyID, SK_CompanyID FROM dimcompany WHERE \" + build_query(df_fin_id, 'CompanyID')\n",
    "            sk_id_map = pd.read_sql_query(query_id, engine).set_index('CompanyID')['SK_CompanyID']            \n",
    "            financial_df.loc[df_fin_id.index, 'SK_CompanyID'] = df_fin_id['CoNameOrCIK'].astype(int).map(sk_id_map)\n",
    "\n",
    "        # Execute query and map results for Name-based records\n",
    "        if not df_fin_name.empty:\n",
    "            query_name = f\"SELECT Name, SK_CompanyID FROM dimcompany WHERE \" + build_query(df_fin_name, 'Name')\n",
    "            sk_name_map = pd.read_sql_query(query_name, engine).set_index('Name')['SK_CompanyID']\n",
    "            financial_df.loc[df_fin_name.index, 'SK_CompanyID'] = df_fin_name['CoNameOrCIK'].map(sk_name_map)\n",
    "\n",
    "        financial_df['SK_CompanyID'] = financial_df['SK_CompanyID'].astype('uint32')\n",
    "\n",
    "        # perform migration\n",
    "        financial_df.to_sql('financial', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:25.668132Z",
     "iopub.status.busy": "2023-12-22T12:11:25.667128Z",
     "iopub.status.idle": "2023-12-22T12:11:25.696129Z",
     "shell.execute_reply": "2023-12-22T12:11:25.695128Z",
     "shell.execute_reply.started": "2023-12-22T12:11:25.668132Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Financial (\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    FI_YEAR YEAR NOT NULL,\n",
    "    FI_QTR TINYINT UNSIGNED NOT NULL CHECK (FI_QTR IN (1, 2, 3, 4)),\n",
    "    FI_QTR_START_DATE DATE NOT NULL,\n",
    "    FI_REVENUE DECIMAL(15, 2) NOT NULL,\n",
    "    FI_NET_EARN DECIMAL(15, 2) NOT NULL,\n",
    "    FI_BASIC_EPS DECIMAL(10, 2) NOT NULL,\n",
    "    FI_DILUT_EPS DECIMAL(10, 2) NOT NULL,\n",
    "    FI_MARGIN DECIMAL(10, 2) NOT NULL,\n",
    "    FI_INVENTORY DECIMAL(15, 2) NOT NULL,\n",
    "    FI_ASSETS DECIMAL(15, 2) NOT NULL,\n",
    "    FI_LIABILITY DECIMAL(15, 2) NOT NULL,\n",
    "    FI_OUT_BASIC BIGINT NOT NULL,\n",
    "    FI_OUT_DILUT BIGINT NOT NULL,\n",
    "    PRIMARY KEY (SK_CompanyID, FI_YEAR, FI_QTR)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:11:25.699126Z",
     "iopub.status.busy": "2023-12-22T12:11:25.698128Z",
     "iopub.status.idle": "2023-12-22T12:12:42.898754Z",
     "shell.execute_reply": "2023-12-22T12:12:42.897977Z",
     "shell.execute_reply.started": "2023-12-22T12:11:25.699126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3eaa1355424d64be4b031a31573cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_financial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimSecurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:42.900723Z",
     "iopub.status.busy": "2023-12-22T12:12:42.900723Z",
     "iopub.status.idle": "2023-12-22T12:12:42.914717Z",
     "shell.execute_reply": "2023-12-22T12:12:42.913708Z",
     "shell.execute_reply.started": "2023-12-22T12:12:42.900723Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_finwire_sec(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 15, 6, 4, 70, 6, 13, 8, 8, 12, 60]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"Symbol\", \"IssueType\", \"Status\", \"Name\", \"ExID\",\n",
    "        \"ShOut\", \"FirstTradeDate\", \"FirstTradeExchg\", \"Dividend\", \"CoNameOrCIK\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df_sec = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_sec = df_sec[df_sec['RecType'] == 'SEC']\n",
    "    # Convert date cols to datetime\n",
    "    df_sec['PTS'] = pd.to_datetime(df_sec['PTS'], format='%Y%m%d-%H%M%S')\n",
    "    df_sec['FirstTradeDate'] = pd.to_datetime(df_sec['FirstTradeDate'], format='%Y%m%d')\n",
    "    df_sec['FirstTradeExchg'] = pd.to_datetime(df_sec['FirstTradeExchg'], format='%Y%m%d')\n",
    "\n",
    "    return df_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:42.917708Z",
     "iopub.status.busy": "2023-12-22T12:12:42.916708Z",
     "iopub.status.idle": "2023-12-22T12:12:42.930714Z",
     "shell.execute_reply": "2023-12-22T12:12:42.928711Z",
     "shell.execute_reply.started": "2023-12-22T12:12:42.917708Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"Symbol\": sqlalchemy.types.String(15),\n",
    "    \"Issue\": sqlalchemy.types.String(6),\n",
    "    \"Status\": sqlalchemy.types.String(10),\n",
    "    \"Name\": sqlalchemy.types.String(70),\n",
    "    \"ExchangeID\": sqlalchemy.types.String(6),\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SharesOutstanding\": sqlalchemy.types.Integer,\n",
    "    \"FirstTrade\": sqlalchemy.types.Date,\n",
    "    \"FirstTradeOnExchange\": sqlalchemy.types.Date,\n",
    "    \"Dividend\": sqlalchemy.types.Numeric(10, 2),\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date,\n",
    "}\n",
    "\n",
    "dtypes = {\n",
    "    \"SK_SecurityID\": \"uint32\",\n",
    "    \"Symbol\": \"str\",\n",
    "    \"Issue\": \"str\",\n",
    "    \"Status\": \"str\",\n",
    "    \"Name\": \"str\",\n",
    "    \"ExchangeID\": \"str\",\n",
    "    \"SK_CompanyID\": \"uint32\",\n",
    "    \"SharesOutstanding\": \"uint32\",\n",
    "    \"FirstTrade\": \"datetime64[ns]\",\n",
    "    \"FirstTradeOnExchange\": \"datetime64[ns]\",\n",
    "    \"Dividend\": \"float64\",\n",
    "    \"IsCurrent\": \"bool\",\n",
    "    \"BatchID\": \"uint8\",\n",
    "    \"EffectiveDate\": \"datetime64[ns]\",\n",
    "    \"EndDate\": \"datetime64[ns]\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:42.932711Z",
     "iopub.status.busy": "2023-12-22T12:12:42.932711Z",
     "iopub.status.idle": "2023-12-22T12:12:42.945709Z",
     "shell.execute_reply": "2023-12-22T12:12:42.944711Z",
     "shell.execute_reply.started": "2023-12-22T12:12:42.932711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query StatusType table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    statustype_df = pd.read_sql(\"SELECT * FROM statustype\", conn)\n",
    "status_mapping = dict(statustype_df[['ST_ID', 'ST_NAME']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:42.947710Z",
     "iopub.status.busy": "2023-12-22T12:12:42.946710Z",
     "iopub.status.idle": "2023-12-22T12:12:42.961711Z",
     "shell.execute_reply": "2023-12-22T12:12:42.960745Z",
     "shell.execute_reply.started": "2023-12-22T12:12:42.947710Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_query(df, id_or_name_col):\n",
    "    '''Function to build SQL query for date range checks'''\n",
    "    query_parts = []\n",
    "    for _, row in df.iterrows():\n",
    "        pts = row['PTS']\n",
    "        if id_or_name_col == 'CompanyID':\n",
    "            company_id = row['CoNameOrCIK']\n",
    "            query_part = f\"(CompanyID = {company_id} AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "        else:  # Name\n",
    "            company_name = row['CoNameOrCIK']\n",
    "            query_part = f\"(Name = '{company_name}' AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "        query_parts.append(query_part)\n",
    "    return ' OR '.join(query_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:42.964711Z",
     "iopub.status.busy": "2023-12-22T12:12:42.963711Z",
     "iopub.status.idle": "2023-12-22T12:12:43.008718Z",
     "shell.execute_reply": "2023-12-22T12:12:43.006730Z",
     "shell.execute_reply.started": "2023-12-22T12:12:42.964711Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dimsecurity():\n",
    "    finwire_files = os.listdir(DATA_DIR)\n",
    "    finwire_files = [\n",
    "        DATA_DIR + file\n",
    "        for file in finwire_files\n",
    "        if file.startswith(\"FINWIRE\") and \"audit\" not in file\n",
    "    ]\n",
    "    for i, file in enumerate(tqdm(finwire_files)):\n",
    "        # raw data from file\n",
    "        df_sec = read_finwire_sec(file)\n",
    "        # dimension table in data warehouse\n",
    "        security_df = pd.DataFrame(\n",
    "            {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    "        )\n",
    "        # copy directly\n",
    "        security_df[\"Symbol\"] = df_sec[\"Symbol\"]\n",
    "        security_df[\"Issue\"] = df_sec[\"IssueType\"]\n",
    "        security_df[\"Name\"] = df_sec[\"Name\"]\n",
    "        security_df[\"ExchangeID\"] = df_sec[\"ExID\"]\n",
    "        security_df[\"SharesOutstanding\"] = pd.to_numeric(\n",
    "            df_sec[\"ShOut\"], downcast=\"unsigned\"\n",
    "        )\n",
    "        security_df[\"FirstTrade\"] = df_sec[\"FirstTradeDate\"]\n",
    "        security_df[\"FirstTradeOnExchange\"] = df_sec[\"FirstTradeExchg\"]\n",
    "        security_df[\"Dividend\"] = pd.to_numeric(df_sec[\"Dividend\"], downcast=\"float\")\n",
    "        # Update Status in security_df\n",
    "        security_df[\"Status\"] = df_sec[\"Status\"].map(status_mapping)\n",
    "        # BatchID is set to 1\n",
    "        security_df[\"BatchID\"] = BATCH_ID\n",
    "        # Split df_sec based on the length of CoNameOrCIK\n",
    "        df_sec_id = df_sec[df_sec[\"CoNameOrCIK\"].str.len() == 10][\n",
    "            [\"PTS\", \"CoNameOrCIK\"]\n",
    "        ]\n",
    "        df_sec_id[\"PTS\"] = df_sec_id[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        df_sec_id[\"CoNameOrCIK\"] = pd.to_numeric(\n",
    "            df_sec_id[\"CoNameOrCIK\"], downcast=\"unsigned\"\n",
    "        )\n",
    "        df_sec_name = df_sec[df_sec[\"CoNameOrCIK\"].str.len() != 10][\n",
    "            [\"PTS\", \"CoNameOrCIK\"]\n",
    "        ]\n",
    "        df_sec_name[\"PTS\"] = df_sec_name[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        df_sec_name[\"CoNameOrCIK\"] = df_sec_name[\"CoNameOrCIK\"].str.strip()\n",
    "        # Map results for ID-based records\n",
    "        if not df_sec_id.empty:\n",
    "            query_id = (\n",
    "                f\"SELECT CompanyID, SK_CompanyID FROM dimcompany WHERE \"\n",
    "                + build_query(df_sec_id, \"CompanyID\")\n",
    "            )\n",
    "            sk_id_map = pd.read_sql_query(query_id, engine).set_index(\"CompanyID\")[\n",
    "                \"SK_CompanyID\"\n",
    "            ]\n",
    "            # drop duplicates from the index\n",
    "            sk_id_map = sk_id_map[~sk_id_map.index.duplicated(keep=\"last\")]\n",
    "            security_df.loc[df_sec_id.index, \"SK_CompanyID\"] = (\n",
    "                df_sec_id[\"CoNameOrCIK\"].astype(int).map(sk_id_map)\n",
    "            )\n",
    "        # Map results for Name-based records\n",
    "        if not df_sec_name.empty:\n",
    "            query_name = (\n",
    "                f\"SELECT Name, SK_CompanyID FROM dimcompany WHERE \"\n",
    "                + build_query(df_sec_name, \"Name\")\n",
    "            )\n",
    "            sk_name_map = pd.read_sql_query(query_name, engine).set_index(\"Name\")[\n",
    "                \"SK_CompanyID\"\n",
    "            ]\n",
    "            # drop duplicates from the index\n",
    "            sk_name_map = sk_name_map[~sk_name_map.index.duplicated(keep=\"last\")]\n",
    "            security_df.loc[df_sec_name.index, \"SK_CompanyID\"] = df_sec_name[\n",
    "                \"CoNameOrCIK\"\n",
    "            ].map(sk_name_map)\n",
    "        # change the type back to uint32\n",
    "        security_df[\"SK_CompanyID\"] = security_df[\"SK_CompanyID\"].astype(\"uint32\")\n",
    "        # get effective date from posting date\n",
    "        security_df[\"EffectiveDate\"] = df_sec[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        # Identify new and existing records based on Symbol\n",
    "        is_first_batch = i == 0\n",
    "        if is_first_batch:\n",
    "            new_records = security_df\n",
    "            existing_records = pd.DataFrame(\n",
    "                {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    "            )\n",
    "            next_sk_id = 0\n",
    "        else:\n",
    "            existing_symbol = pd.read_sql_query(\n",
    "                \"SELECT Symbol FROM dimsecurity WHERE IsCurrent = 1\", engine\n",
    "            )[\"Symbol\"]\n",
    "            new_records = security_df[~security_df[\"Symbol\"].isin(existing_symbol)]\n",
    "            existing_records = security_df[security_df[\"Symbol\"].isin(existing_symbol)]\n",
    "            next_sk_id_query = \"SELECT MAX(SK_SecurityID) FROM dimsecurity\"\n",
    "            next_sk_id = pd.read_sql_query(next_sk_id_query, engine).iloc[0, 0] or 0\n",
    "        # update SK_SecurityID, IsCurrent, EndDate\n",
    "        new_records.loc[:, \"SK_SecurityID\"] = range(\n",
    "            next_sk_id + 1, next_sk_id + 1 + len(new_records)\n",
    "        )\n",
    "        new_records.loc[:, \"IsCurrent\"] = True\n",
    "        new_records.loc[:, \"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "        # Insert records with new SK_CompanyID\n",
    "        new_records.to_sql(\n",
    "            \"dimsecurity\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "        )\n",
    "        next_sk_id = new_records[\"SK_SecurityID\"].max()\n",
    "\n",
    "        # Process existing records\n",
    "        for _, row in existing_records.iterrows():\n",
    "            effective_date = row[\"EffectiveDate\"]\n",
    "            symbol = row[\"Symbol\"]\n",
    "            # Expire the current record in MySQL\n",
    "            update_query = f\"\"\"UPDATE dimsecurity \n",
    "            SET IsCurrent = 0, EndDate = '{effective_date}' \n",
    "            WHERE Symbol = '{symbol}' AND IsCurrent = 1\n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(update_query))\n",
    "                conn.commit()\n",
    "            row[\"SK_SecurityID\"] = next_sk_id + 1\n",
    "            row[\"IsCurrent\"] = True\n",
    "            row[\"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "            row_df = pd.DataFrame(row).T\n",
    "            # insert records with existing SK_CompanyID\n",
    "            row_df.to_sql(\n",
    "                \"dimsecurity\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "            )\n",
    "            next_sk_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:43.009745Z",
     "iopub.status.busy": "2023-12-22T12:12:43.009745Z",
     "iopub.status.idle": "2023-12-22T12:12:43.039711Z",
     "shell.execute_reply": "2023-12-22T12:12:43.038739Z",
     "shell.execute_reply.started": "2023-12-22T12:12:43.009745Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimSecurity (\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    Symbol CHAR(15) NOT NULL,\n",
    "    Issue CHAR(6) NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Name CHAR(70) NOT NULL,\n",
    "    ExchangeID CHAR(6) NOT NULL,\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    SharesOutstanding BIGINT UNSIGNED NOT NULL,\n",
    "    FirstTrade DATE NOT NULL,\n",
    "    FirstTradeOnExchange DATE NOT NULL,\n",
    "    Dividend DECIMAL(10, 2) NOT NULL,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_SecurityID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:12:43.041709Z",
     "iopub.status.busy": "2023-12-22T12:12:43.041709Z",
     "iopub.status.idle": "2023-12-22T12:13:02.471999Z",
     "shell.execute_reply": "2023-12-22T12:13:02.470966Z",
     "shell.execute_reply.started": "2023-12-22T12:12:43.041709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e77c2d03b5b403799636acb077735ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dimsecurity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prospect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:02.477968Z",
     "iopub.status.busy": "2023-12-22T12:13:02.476939Z",
     "iopub.status.idle": "2023-12-22T12:13:02.502938Z",
     "shell.execute_reply": "2023-12-22T12:13:02.501944Z",
     "shell.execute_reply.started": "2023-12-22T12:13:02.477968Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_prospect_file(filepath):\n",
    "    # Define the column names and their data types\n",
    "    columns = [\n",
    "        'AgencyID', 'LastName', 'FirstName', 'MiddleInitial', 'Gender', \n",
    "        'AddressLine1', 'AddressLine2', 'PostalCode', 'City', 'State', \n",
    "        'Country', 'Phone', 'Income', 'NumberCars', 'NumberChildren', \n",
    "        'MaritalStatus', 'Age', 'CreditRating', 'OwnOrRentFlag', \n",
    "        'Employer', 'NumberCreditCards', 'NetWorth'\n",
    "    ]\n",
    "\n",
    "    # Define the data types for reading the file\n",
    "    dtypes = {\n",
    "        'AgencyID': 'str', 'LastName': 'str', 'FirstName': 'str', \n",
    "        'MiddleInitial': 'str', 'Gender': 'str', 'AddressLine1': 'str', \n",
    "        'AddressLine2': 'str', 'PostalCode': 'str', 'City': 'str', \n",
    "        'State': 'str', 'Country': 'str', 'Phone': 'str', \n",
    "        'Income': 'Int64', 'NumberCars': 'Int8', 'NumberChildren': 'Int8', \n",
    "        'MaritalStatus': 'str', 'Age': 'Int8', 'CreditRating': 'Int16', \n",
    "        'OwnOrRentFlag': 'str', 'Employer': 'str', \n",
    "        'NumberCreditCards': 'Int8', 'NetWorth': 'Int64'\n",
    "    }\n",
    "\n",
    "    # Read the CSV file\n",
    "    raw_prospect_df = pd.read_csv(\n",
    "        filepath, \n",
    "        header=None, \n",
    "        names=columns, \n",
    "        dtype=dtypes\n",
    "    )\n",
    "\n",
    "    return raw_prospect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:02.504938Z",
     "iopub.status.busy": "2023-12-22T12:13:02.504938Z",
     "iopub.status.idle": "2023-12-22T12:13:02.954679Z",
     "shell.execute_reply": "2023-12-22T12:13:02.953720Z",
     "shell.execute_reply.started": "2023-12-22T12:13:02.504938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24970 entries, 0 to 24969\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   AgencyID           24970 non-null  object\n",
      " 1   LastName           24970 non-null  object\n",
      " 2   FirstName          24969 non-null  object\n",
      " 3   MiddleInitial      10982 non-null  object\n",
      " 4   Gender             11880 non-null  object\n",
      " 5   AddressLine1       24097 non-null  object\n",
      " 6   AddressLine2       17160 non-null  object\n",
      " 7   PostalCode         24098 non-null  object\n",
      " 8   City               24970 non-null  object\n",
      " 9   State              24970 non-null  object\n",
      " 10  Country            23929 non-null  object\n",
      " 11  Phone              23674 non-null  object\n",
      " 12  Income             23760 non-null  Int64 \n",
      " 13  NumberCars         23708 non-null  Int8  \n",
      " 14  NumberChildren     23741 non-null  Int8  \n",
      " 15  MaritalStatus      23721 non-null  object\n",
      " 16  Age                23685 non-null  Int8  \n",
      " 17  CreditRating       23726 non-null  Int16 \n",
      " 18  OwnOrRentFlag      23790 non-null  object\n",
      " 19  Employer           23710 non-null  object\n",
      " 20  NumberCreditCards  23693 non-null  Int8  \n",
      " 21  NetWorth           23678 non-null  Int64 \n",
      "dtypes: Int16(1), Int64(2), Int8(4), object(15)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleInitial</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Income</th>\n",
       "      <th>NumberCars</th>\n",
       "      <th>NumberChildren</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>OwnOrRentFlag</th>\n",
       "      <th>Employer</th>\n",
       "      <th>NumberCreditCards</th>\n",
       "      <th>NetWorth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLY0</td>\n",
       "      <td>CLYSDALE</td>\n",
       "      <td>Leif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>11538 kimberley boulevard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97217</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>368776</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>W</td>\n",
       "      <td>20</td>\n",
       "      <td>760</td>\n",
       "      <td>O</td>\n",
       "      <td>Brink's</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1058868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NAN1</td>\n",
       "      <td>NANAMIYA</td>\n",
       "      <td>CHARANGIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>13347 norwalk road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89506</td>\n",
       "      <td>Miami</td>\n",
       "      <td>NH</td>\n",
       "      <td>...</td>\n",
       "      <td>177967</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>U</td>\n",
       "      <td>3</td>\n",
       "      <td>555</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1988185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pea2</td>\n",
       "      <td>pearson</td>\n",
       "      <td>pier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2134 neff south</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35207</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>321772</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>566</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3673128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIL3</td>\n",
       "      <td>PILOTE</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23923 potomac road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t6d 1h9</td>\n",
       "      <td>Fayetteville</td>\n",
       "      <td>MO</td>\n",
       "      <td>...</td>\n",
       "      <td>25449</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>77</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>Air Products &amp; Chemicals</td>\n",
       "      <td>3</td>\n",
       "      <td>2005895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEN4</td>\n",
       "      <td>DENETTE</td>\n",
       "      <td>kattie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>21376 kirby lower</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63172</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>NC</td>\n",
       "      <td>...</td>\n",
       "      <td>166567</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>815</td>\n",
       "      <td>O</td>\n",
       "      <td>Oshkosh</td>\n",
       "      <td>4</td>\n",
       "      <td>624736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AgencyID  LastName  FirstName MiddleInitial Gender  \\\n",
       "0     CLY0  CLYSDALE       Leif           NaN      m   \n",
       "1     NAN1  NANAMIYA  CHARANGIT           NaN      f   \n",
       "2     pea2   pearson       pier           NaN      F   \n",
       "3     PIL3    PILOTE      Hazel           NaN    NaN   \n",
       "4     DEN4   DENETTE     kattie           NaN      F   \n",
       "\n",
       "                AddressLine1 AddressLine2 PostalCode          City State  ...  \\\n",
       "0  11538 kimberley boulevard          NaN      97217       Chicago    FL  ...   \n",
       "1         13347 norwalk road          NaN      89506         Miami    NH  ...   \n",
       "2            2134 neff south          NaN      35207    Des Moines    NY  ...   \n",
       "3         23923 potomac road          NaN    t6d 1h9  Fayetteville    MO  ...   \n",
       "4          21376 kirby lower          NaN      63172    Greensboro    NC  ...   \n",
       "\n",
       "   Income NumberCars  NumberChildren  MaritalStatus   Age CreditRating  \\\n",
       "0  368776       <NA>               3              W    20          760   \n",
       "1  177967          5               1              U     3          555   \n",
       "2  321772          2               1              S  <NA>          566   \n",
       "3   25449          2               1              W    77         <NA>   \n",
       "4  166567          0               3              M    21          815   \n",
       "\n",
       "   OwnOrRentFlag                  Employer NumberCreditCards NetWorth  \n",
       "0              O                   Brink's              <NA>  1058868  \n",
       "1              U                       NaN                 6  1988185  \n",
       "2              O                       NaN                 6  3673128  \n",
       "3              O  Air Products & Chemicals                 3  2005895  \n",
       "4              O                   Oshkosh                 4   624736  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_prospect_df = read_prospect_file(DATA_DIR + \"Prospect.csv\")\n",
    "raw_prospect_df.info()\n",
    "raw_prospect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:02.957680Z",
     "iopub.status.busy": "2023-12-22T12:13:02.956680Z",
     "iopub.status.idle": "2023-12-22T12:13:03.001681Z",
     "shell.execute_reply": "2023-12-22T12:13:03.000684Z",
     "shell.execute_reply.started": "2023-12-22T12:13:02.957680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24970 entries, 0 to 24969\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   AgencyID           24970 non-null  object\n",
      " 1   LastName           24970 non-null  object\n",
      " 2   FirstName          24970 non-null  object\n",
      " 3   MiddleInitial      10982 non-null  object\n",
      " 4   Gender             11880 non-null  object\n",
      " 5   AddressLine1       24097 non-null  object\n",
      " 6   AddressLine2       17160 non-null  object\n",
      " 7   PostalCode         24098 non-null  object\n",
      " 8   City               24970 non-null  object\n",
      " 9   State              24970 non-null  object\n",
      " 10  Country            23929 non-null  object\n",
      " 11  Phone              23674 non-null  object\n",
      " 12  Income             23760 non-null  Int64 \n",
      " 13  NumberCars         23708 non-null  Int8  \n",
      " 14  NumberChildren     23741 non-null  Int8  \n",
      " 15  MaritalStatus      23721 non-null  object\n",
      " 16  Age                23685 non-null  Int8  \n",
      " 17  CreditRating       23726 non-null  Int16 \n",
      " 18  OwnOrRentFlag      23790 non-null  object\n",
      " 19  Employer           23710 non-null  object\n",
      " 20  NumberCreditCards  23693 non-null  Int8  \n",
      " 21  NetWorth           23678 non-null  Int64 \n",
      "dtypes: Int16(1), Int64(2), Int8(4), object(15)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "not_null_cols = ['LastName', 'FirstName', 'City', 'State']\n",
    "for col in not_null_cols:\n",
    "    raw_prospect_df.loc[raw_prospect_df[col].isna(), col] = ''\n",
    "raw_prospect_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.004685Z",
     "iopub.status.busy": "2023-12-22T12:13:03.003681Z",
     "iopub.status.idle": "2023-12-22T12:13:03.033684Z",
     "shell.execute_reply": "2023-12-22T12:13:03.031681Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.004685Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'AgencyID': 'str',\n",
    "    'SK_RecordDateID': 'uint32',\n",
    "    'SK_UpdateDateID': 'uint32',\n",
    "    'BatchID': 'uint16',\n",
    "    'IsCustomer': 'boolean',\n",
    "    'LastName': 'str',\n",
    "    'FirstName': 'str',\n",
    "    'MiddleInitial': 'str',\n",
    "    'Gender': 'str',\n",
    "    'AddressLine1': 'str',\n",
    "    'AddressLine2': 'str',\n",
    "    'PostalCode': 'str',\n",
    "    'City': 'str',\n",
    "    'State': 'str',\n",
    "    'Country': 'str',\n",
    "    'Phone': 'str',\n",
    "    'Income': 'uint32',\n",
    "    'NumberCars': 'uint8',\n",
    "    'NumberChildren': 'uint8',\n",
    "    'MaritalStatus': 'str',\n",
    "    'Age': 'uint8',\n",
    "    'CreditRating': 'uint16',\n",
    "    'OwnOrRentFlag': 'str',\n",
    "    'Employer': 'str',\n",
    "    'NumberCreditCards': 'uint8',\n",
    "    'NetWorth': 'int64',\n",
    "    'MarketingNameplate': 'str'\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame with the specified schema\n",
    "prospect_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in dtypes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.035686Z",
     "iopub.status.busy": "2023-12-22T12:13:03.034695Z",
     "iopub.status.idle": "2023-12-22T12:13:03.111679Z",
     "shell.execute_reply": "2023-12-22T12:13:03.110681Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.035686Z"
    }
   },
   "outputs": [],
   "source": [
    "prospect_df[\"AgencyID\"] = raw_prospect_df[\"AgencyID\"]\n",
    "prospect_df[\"LastName\"] = raw_prospect_df[\"LastName\"]\n",
    "prospect_df[\"FirstName\"] = raw_prospect_df[\"FirstName\"]\n",
    "prospect_df[\"MiddleInitial\"] = raw_prospect_df[\"MiddleInitial\"]\n",
    "prospect_df[\"Gender\"] = raw_prospect_df[\"Gender\"]\n",
    "# fix data quality issues\n",
    "prospect_df['Gender'] = prospect_df['Gender'].str.upper()\n",
    "mask = ~prospect_df['Gender'].isin([\"M\", \"F\"])\n",
    "prospect_df.loc[mask, \"Gender\"] = \"U\"\n",
    "prospect_df[\"AddressLine1\"] = raw_prospect_df[\"AddressLine1\"]\n",
    "prospect_df[\"AddressLine2\"] = raw_prospect_df[\"AddressLine2\"]\n",
    "prospect_df[\"PostalCode\"] = raw_prospect_df[\"PostalCode\"]\n",
    "prospect_df[\"City\"] = raw_prospect_df[\"City\"]\n",
    "prospect_df[\"State\"] = raw_prospect_df[\"State\"]\n",
    "prospect_df[\"Country\"] = raw_prospect_df[\"Country\"]\n",
    "prospect_df[\"Phone\"] = raw_prospect_df[\"Phone\"]\n",
    "prospect_df[\"Income\"] = raw_prospect_df[\"Income\"]\n",
    "prospect_df[\"NumberCars\"] = raw_prospect_df[\"NumberCars\"]\n",
    "prospect_df[\"NumberChildren\"] = raw_prospect_df[\"NumberChildren\"]\n",
    "prospect_df[\"MaritalStatus\"] = raw_prospect_df[\"MaritalStatus\"]\n",
    "prospect_df[\"MaritalStatus\"] = prospect_df[\"MaritalStatus\"].str.upper()\n",
    "mask = ~prospect_df[\"MaritalStatus\"].isin([\"S\", \"M\", \"D\", \"W\"])\n",
    "prospect_df.loc[mask, \"MaritalStatus\"] = \"U\"\n",
    "prospect_df[\"Age\"] = raw_prospect_df[\"Age\"]\n",
    "prospect_df[\"CreditRating\"] = raw_prospect_df[\"CreditRating\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = raw_prospect_df[\"OwnOrRentFlag\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = prospect_df[\"OwnOrRentFlag\"].str.upper()\n",
    "mask = ~prospect_df[\"OwnOrRentFlag\"].isin([\"O\", \"R\"])\n",
    "prospect_df.loc[mask, \"OwnOrRentFlag\"] = \"U\"\n",
    "prospect_df[\"Employer\"] = raw_prospect_df[\"Employer\"]\n",
    "prospect_df[\"NumberCreditCards\"] = raw_prospect_df[\"NumberCreditCards\"]\n",
    "prospect_df[\"NetWorth\"] = raw_prospect_df[\"NetWorth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.113681Z",
     "iopub.status.busy": "2023-12-22T12:13:03.113681Z",
     "iopub.status.idle": "2023-12-22T12:13:03.142682Z",
     "shell.execute_reply": "2023-12-22T12:13:03.141682Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.113681Z"
    }
   },
   "outputs": [],
   "source": [
    "sk_dateid = pd.read_sql_query(f\"select SK_DateID from dimdate where DateValue = '{BATCH_DATE}'\", engine).iloc[0, 0]\n",
    "# SK_RecordDateID is set to the DimDate SK_DateID field that corresponds to the Batch Date.\n",
    "prospect_df['SK_RecordDateID'] = sk_dateid\n",
    "# SK_UpdateDateID is set to the DimDate SK_DateID field that corresponds to the Batch Date\n",
    "prospect_df['SK_UpdateDateID'] = sk_dateid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.146682Z",
     "iopub.status.busy": "2023-12-22T12:13:03.144680Z",
     "iopub.status.idle": "2023-12-22T12:13:03.235681Z",
     "shell.execute_reply": "2023-12-22T12:13:03.234680Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.146682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define conditions for each tag with null checks\n",
    "conditions = {\n",
    "    \"HighValue\": (prospect_df[\"NetWorth\"].notnull() & prospect_df[\"Income\"].notnull())\n",
    "    & ((prospect_df[\"NetWorth\"] > 1_000_000) | (prospect_df[\"Income\"] > 200_000)),\n",
    "    \"Expenses\": (\n",
    "        prospect_df[\"NumberChildren\"].notnull()\n",
    "        & prospect_df[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df[\"NumberChildren\"] > 3) | (prospect_df[\"NumberCreditCards\"] > 5)),\n",
    "    \"Boomer\": prospect_df[\"Age\"].notnull() & (prospect_df[\"Age\"] > 45),\n",
    "    \"MoneyAlert\": (\n",
    "        prospect_df[\"Income\"].notnull()\n",
    "        & prospect_df[\"CreditRating\"].notnull()\n",
    "        & prospect_df[\"NetWorth\"].notnull()\n",
    "    )\n",
    "    & (\n",
    "        (prospect_df[\"Income\"] < 50_000)\n",
    "        | (prospect_df[\"CreditRating\"] < 600)\n",
    "        | (prospect_df[\"NetWorth\"] < 100_000)\n",
    "    ),\n",
    "    \"Spender\": (\n",
    "        prospect_df[\"NumberCars\"].notnull() & prospect_df[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df[\"NumberCars\"] > 3) | (prospect_df[\"NumberCreditCards\"] > 7)),\n",
    "    \"Inherited\": (prospect_df[\"Age\"].notnull() & prospect_df[\"NetWorth\"].notnull())\n",
    "    & ((prospect_df[\"Age\"] < 25) & (prospect_df[\"NetWorth\"] > 1_000_000)),\n",
    "}\n",
    "\n",
    "# Apply conditions to assign tags\n",
    "prospect_df[\"MarketingNameplate\"] = \"\"\n",
    "for tag, condition in conditions.items():\n",
    "    prospect_df[\"MarketingNameplate\"] += np.where(condition, tag + \"+\", \"\")\n",
    "\n",
    "# Remove trailing '+' and replace empty strings with None\n",
    "prospect_df[\"MarketingNameplate\"] = (\n",
    "    prospect_df[\"MarketingNameplate\"].str.rstrip(\"+\").replace(\"\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.238697Z",
     "iopub.status.busy": "2023-12-22T12:13:03.237685Z",
     "iopub.status.idle": "2023-12-22T12:13:03.281680Z",
     "shell.execute_reply": "2023-12-22T12:13:03.280679Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.238697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24970 entries, 0 to 24969\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   AgencyID            24970 non-null  object \n",
      " 1   SK_RecordDateID     24970 non-null  int64  \n",
      " 2   SK_UpdateDateID     24970 non-null  int64  \n",
      " 3   BatchID             0 non-null      float64\n",
      " 4   IsCustomer          0 non-null      boolean\n",
      " 5   LastName            24970 non-null  object \n",
      " 6   FirstName           24970 non-null  object \n",
      " 7   MiddleInitial       10982 non-null  object \n",
      " 8   Gender              24970 non-null  object \n",
      " 9   AddressLine1        24097 non-null  object \n",
      " 10  AddressLine2        17160 non-null  object \n",
      " 11  PostalCode          24098 non-null  object \n",
      " 12  City                24970 non-null  object \n",
      " 13  State               24970 non-null  object \n",
      " 14  Country             23929 non-null  object \n",
      " 15  Phone               23674 non-null  object \n",
      " 16  Income              23760 non-null  Int64  \n",
      " 17  NumberCars          23708 non-null  Int8   \n",
      " 18  NumberChildren      23741 non-null  Int8   \n",
      " 19  MaritalStatus       24970 non-null  object \n",
      " 20  Age                 23685 non-null  Int8   \n",
      " 21  CreditRating        23726 non-null  Int16  \n",
      " 22  OwnOrRentFlag       24970 non-null  object \n",
      " 23  Employer            23710 non-null  object \n",
      " 24  NumberCreditCards   23693 non-null  Int8   \n",
      " 25  NetWorth            23678 non-null  Int64  \n",
      " 26  MarketingNameplate  24580 non-null  object \n",
      "dtypes: Int16(1), Int64(2), Int8(4), boolean(1), float64(1), int64(2), object(16)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "prospect_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IsCurrent and BatchID are set after processing dimCustomer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.283679Z",
     "iopub.status.busy": "2023-12-22T12:13:03.282679Z",
     "iopub.status.idle": "2023-12-22T12:13:03.580680Z",
     "shell.execute_reply": "2023-12-22T12:13:03.579679Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.283679Z"
    }
   },
   "outputs": [],
   "source": [
    "data_file = DATA_DIR + \"CustomerMgmt.xml\"\n",
    "tree = etree.parse(data_file)\n",
    "namespace = {'tpcdi': 'http://www.tpc.org/tpc-di'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.582680Z",
     "iopub.status.busy": "2023-12-22T12:13:03.582680Z",
     "iopub.status.idle": "2023-12-22T12:13:03.595682Z",
     "shell.execute_reply": "2023-12-22T12:13:03.594695Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.582680Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'SK_CustomerID': 'int32',\n",
    "    'CustomerID': 'int32',\n",
    "    'TaxID': 'str',\n",
    "    'Status': 'str',\n",
    "    'LastName': 'str',\n",
    "    'FirstName': 'str',\n",
    "    'MiddleInitial': 'str',\n",
    "    'Gender': 'str',\n",
    "    'Tier': 'UInt8',\n",
    "    'DOB': 'datetime64[ns]',\n",
    "    'AddressLine1': 'str',\n",
    "    'AddressLine2': 'str',\n",
    "    'PostalCode': 'str',\n",
    "    'City': 'str',\n",
    "    'StateProv': 'str',\n",
    "    'Country': 'str',\n",
    "    'Phone1': 'str',\n",
    "    'Phone2': 'str',\n",
    "    'Phone3': 'str',\n",
    "    'Email1': 'str',\n",
    "    'Email2': 'str',\n",
    "    'NationalTaxRateDesc': 'str',\n",
    "    'NationalTaxRate': 'Float64',\n",
    "    'LocalTaxRateDesc': 'str',\n",
    "    'LocalTaxRate': 'Float64',\n",
    "    'AgencyID': 'str',\n",
    "    'CreditRating': 'UInt16',\n",
    "    'NetWorth': 'Float64',\n",
    "    'MarketingNameplate': 'str',\n",
    "    'IsCurrent': 'boolean',\n",
    "    'BatchID': 'uint8',\n",
    "    'EffectiveDate': 'datetime64[ns]',\n",
    "    'EndDate': 'datetime64[ns]'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.598683Z",
     "iopub.status.busy": "2023-12-22T12:13:03.597698Z",
     "iopub.status.idle": "2023-12-22T12:13:03.611680Z",
     "shell.execute_reply": "2023-12-22T12:13:03.610719Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.598683Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_phone_number(phone_element):\n",
    "    # Extract components of the phone number\n",
    "    ctry_code = phone_element.findtext('C_CTRY_CODE', default=None, namespaces=namespace)\n",
    "    area_code = phone_element.findtext('C_AREA_CODE', default=None, namespaces=namespace)\n",
    "    local = phone_element.findtext('C_LOCAL', default=None, namespaces=namespace)\n",
    "    ext = phone_element.findtext('C_EXT', default=None, namespaces=namespace)\n",
    "\n",
    "    # Apply transformation rules\n",
    "    if ctry_code and area_code and local:\n",
    "        phone = f\"+{ctry_code} ({area_code}) {local}\"\n",
    "    elif area_code and local:\n",
    "        phone = f\"({area_code}) {local}\"\n",
    "    elif local:\n",
    "        phone = local\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Add extension if present\n",
    "    if ext:\n",
    "        phone += ext\n",
    "\n",
    "    return phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.613680Z",
     "iopub.status.busy": "2023-12-22T12:13:03.612680Z",
     "iopub.status.idle": "2023-12-22T12:13:03.628689Z",
     "shell.execute_reply": "2023-12-22T12:13:03.626685Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.613680Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_tax_info(tax_ids):\n",
    "    tax_ids_str = \"','\".join(tax_ids)\n",
    "    query = f\"SELECT TX_ID, TX_NAME, TX_RATE FROM taxrate WHERE TX_ID IN ('{tax_ids_str}')\"\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    return result.set_index('TX_ID').to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.630686Z",
     "iopub.status.busy": "2023-12-22T12:13:03.629685Z",
     "iopub.status.idle": "2023-12-22T12:13:03.797679Z",
     "shell.execute_reply": "2023-12-22T12:13:03.796681Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.630686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the latest index of 'UPDCUST' or 'INACT' for each CustomerID\n",
    "latest_updates = {}\n",
    "\n",
    "# Get all actions\n",
    "all_actions = tree.xpath(\".//tpcdi:Action\", namespaces=namespace)\n",
    "# NEW actions\n",
    "new_actions = [action for action in all_actions if action.get('ActionType') == 'NEW']\n",
    "# UPD actions\n",
    "upd_actions = [action for action in all_actions if action.get('ActionType') == 'UPDCUST']\n",
    "# INACT actions\n",
    "inact_actions = [action for action in all_actions if action.get('ActionType') == 'INACT']\n",
    "\n",
    "# Preprocess to fill the dictionary\n",
    "for i, action in enumerate(all_actions):\n",
    "    if action.get('ActionType') in ['UPDCUST', 'INACT']:\n",
    "        customer = action.find('Customer', namespaces=namespace)\n",
    "        customer_id = customer.get('C_ID', None)\n",
    "        if customer_id:\n",
    "            latest_updates[int(customer_id)] = i\n",
    "\n",
    "# Modified has_later_update function\n",
    "def has_later_update(customer_id, current_index):\n",
    "    \"\"\"Check for subsequent 'UPDCUST' or 'INACT' actions for a given CustomerID at current_index\"\"\"\n",
    "    return latest_updates.get(customer_id, -1) > current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.799679Z",
     "iopub.status.busy": "2023-12-22T12:13:03.798680Z",
     "iopub.status.idle": "2023-12-22T12:13:03.892679Z",
     "shell.execute_reply": "2023-12-22T12:13:03.891738Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.799679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified schema\n",
    "dimCustomer_df = pd.DataFrame(\n",
    "    {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    ")\n",
    "\n",
    "# Initialize lists to store tax IDs for each record\n",
    "national_tax_ids = []\n",
    "local_tax_ids = []\n",
    "\n",
    "# temporary prospect_df for matching\n",
    "prospect_df_temp = prospect_df[\n",
    "    [\n",
    "        \"AgencyID\",\n",
    "        \"CreditRating\",\n",
    "        \"NetWorth\",\n",
    "        \"MarketingNameplate\",\n",
    "        \"LastName\",\n",
    "        \"FirstName\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "    ]\n",
    "].copy()\n",
    "prospect_df_temp[\"LastName\"] = prospect_df_temp[\"LastName\"].str.upper()\n",
    "prospect_df_temp[\"FirstName\"] = prospect_df_temp[\"FirstName\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine1\"] = prospect_df_temp[\"AddressLine1\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine2\"] = prospect_df_temp[\"AddressLine2\"].str.upper()\n",
    "prospect_df_temp[\"PostalCode\"] = prospect_df_temp[\"PostalCode\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:03.894680Z",
     "iopub.status.busy": "2023-12-22T12:13:03.894680Z",
     "iopub.status.idle": "2023-12-22T12:13:56.208559Z",
     "shell.execute_reply": "2023-12-22T12:13:56.207954Z",
     "shell.execute_reply.started": "2023-12-22T12:13:03.894680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bc4342fafa497a9c5a2543313239d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strai\\AppData\\Local\\Temp\\ipykernel_15716\\4200087088.py:199: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dimCustomer_df = pd.concat([dimCustomer_df, pd.DataFrame(data)])\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store data for NEW actions\n",
    "data = {\n",
    "    \"CustomerID\": [],\n",
    "    \"TaxID\": [],\n",
    "    \"LastName\": [],\n",
    "    \"FirstName\": [],\n",
    "    \"MiddleInitial\": [],\n",
    "    \"Tier\": [],\n",
    "    \"DOB\": [],\n",
    "    \"Gender\": [],\n",
    "    \"Email1\": [],\n",
    "    \"Email2\": [],\n",
    "    \"AddressLine1\": [],\n",
    "    \"AddressLine2\": [],\n",
    "    \"PostalCode\": [],\n",
    "    \"City\": [],\n",
    "    \"StateProv\": [],\n",
    "    \"Country\": [],\n",
    "    \"Phone1\": [],\n",
    "    \"Phone2\": [],\n",
    "    \"Phone3\": [],\n",
    "    \"NationalTaxRateDesc\": [],\n",
    "    \"NationalTaxRate\": [],\n",
    "    \"LocalTaxRateDesc\": [],\n",
    "    \"LocalTaxRate\": [],\n",
    "    \"AgencyID\": [],\n",
    "    \"CreditRating\": [],\n",
    "    \"NetWorth\": [],\n",
    "    \"MarketingNameplate\": [],\n",
    "    \"EffectiveDate\": [],\n",
    "}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"NEW\"\n",
    "for index, action in enumerate(tqdm(new_actions)):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    name = customer.find(\"Name\", namespaces=namespace)\n",
    "    contact_info = customer.find(\"ContactInfo\", namespaces=namespace)\n",
    "    address = customer.find(\"Address\", namespaces=namespace)\n",
    "    tax_info = customer.find(\"TaxInfo\", namespaces=namespace)\n",
    "\n",
    "    customer_id = customer.get(\"C_ID\", None)\n",
    "    customer_id = int(customer_id) if customer_id else None\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "    data[\"TaxID\"].append(customer.get(\"C_TAX_ID\", None))\n",
    "    tier = customer.get(\"C_TIER\", None)\n",
    "    tier = int(tier) if tier else None\n",
    "    if tier is not None and tier not in (1,2,3):\n",
    "        \"\"\"\n",
    "        A record will be inserted in the DImessages table if a customer's Tier is not one of the valid\n",
    "        values (1,2,3). The MessageSource is DimCustomer, the MessageType is Alert and the\n",
    "        MessageText is Invalid customer tier. The MessageData field is C_ID =  followed by the\n",
    "        natural key value of the record, then , C_TIER =  and the C_TIER value.\n",
    "        \"\"\"\n",
    "        MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "        sk_customer_id = len(data[\"CustomerID\"])\n",
    "        message = f\"C_ID = {sk_customer_id}, C_TIER = {tier}\"\n",
    "        message_source = \"DimCustomer\"\n",
    "        message_type = \"Alert\"\n",
    "        message_text = \"Invalid customer tier\"\n",
    "        query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "        VALUES ('{MessageDateAndTime}', {BATCH_ID}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "\n",
    "    data[\"Tier\"].append(tier)\n",
    "    dob = customer.get(\"C_DOB\", None)\n",
    "    dob = pd.to_datetime(dob, format=\"%Y-%m-%d\") if dob else None\n",
    "    \"\"\"A record will be reported in the DImessages table if a customer's DOB is invalid. A customer's\n",
    "    DOB is invalid if DOB < Batch Date - 100 years or DOB > Batch Date (customer is over 100\n",
    "    years old or born in the future). The MessageSource is DimCustomer, the MessageType is\n",
    "    Alert and the MessageText is DOB out of range. The MessageData field is C_ID = \n",
    "    followed by the natural key value of the record, then , C_DOB =  and the C_DOB value.\"\"\"\n",
    "    if dob and (dob < BATCH_DATE - pd.Timedelta(days=100*365) or dob > BATCH_DATE):\n",
    "        MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "        batch_id = 1\n",
    "        sk_customer_id = len(data[\"CustomerID\"])\n",
    "        message = f\"C_ID = {sk_customer_id}, C_DOB = {dob}\"\n",
    "        message_source = \"DimCustomer\"\n",
    "        message_type = \"Alert\"\n",
    "        message_text = \"DOB out of range\"\n",
    "        query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "        VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "    data[\"DOB\"].append(dob)\n",
    "    gender = customer.get(\"C_GNDR\", \"U\")\n",
    "    if gender is not None:\n",
    "        gender = gender.upper()\n",
    "    gender = \"U\" if gender not in (\"M\", \"F\") else gender\n",
    "    data[\"Gender\"].append(gender)\n",
    "    \n",
    "    first_name = name.findtext(\"C_F_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"FirstName\"].append(first_name if first_name else None)\n",
    "    middle_initial = name.findtext(\"C_M_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"MiddleInitial\"].append(middle_initial if middle_initial else None)\n",
    "    last_name = name.findtext(\"C_L_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"LastName\"].append(last_name if last_name else None)\n",
    "\n",
    "    \n",
    "    prim_email = contact_info.findtext(\n",
    "        \"C_PRIM_EMAIL\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"Email1\"].append(prim_email if prim_email else None)\n",
    "    alt_email = contact_info.findtext(\n",
    "        \"C_ALT_EMAIL\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"Email2\"].append(alt_email if alt_email else None)\n",
    "    data[\"Phone1\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_1\", namespaces=namespace))\n",
    "    )\n",
    "    data[\"Phone2\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_2\", namespaces=namespace))\n",
    "    )\n",
    "    data[\"Phone3\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_3\", namespaces=namespace))\n",
    "    )\n",
    "\n",
    "    # Extracting address information\n",
    "    address_line1 = address.findtext(\n",
    "        \"C_ADLINE1\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"AddressLine1\"].append(address_line1 if address_line1 else None)\n",
    "    address_line2 = address.findtext(\n",
    "        \"C_ADLINE2\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"AddressLine2\"].append(address_line2 if address_line2 else None)\n",
    "    postalcode = address.findtext(\"C_ZIPCODE\", default=None, namespaces=namespace)\n",
    "    data[\"PostalCode\"].append(postalcode if postalcode else None)\n",
    "    city = address.findtext(\"C_CITY\", default=None, namespaces=namespace)\n",
    "    data[\"City\"].append(city if city else None)\n",
    "    state_prov = address.findtext(\n",
    "        \"C_STATE_PROV\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"StateProv\"].append(state_prov if state_prov else None)\n",
    "    country = address.findtext(\"C_CTRY\", default=None, namespaces=namespace)\n",
    "    data[\"Country\"].append(country if country else None)\n",
    "    \n",
    "    # Store TX_ID as placeholders\n",
    "    national_tax_id = tax_info.findtext(\n",
    "        \"C_NAT_TX_ID\", default=None, namespaces=namespace\n",
    "    )\n",
    "    national_tax_id = national_tax_id if national_tax_id else None\n",
    "    national_tax_ids.append(national_tax_id)\n",
    "    local_tax_id = tax_info.findtext(\n",
    "        \"C_LCL_TX_ID\", default=None, namespaces=namespace\n",
    "    )\n",
    "    local_tax_id = local_tax_id if local_tax_id else None\n",
    "    local_tax_ids.append(local_tax_id)\n",
    "\n",
    "    if not has_later_update(customer_id, index):\n",
    "        # Find matching prospect record\n",
    "        match = prospect_df_temp[\n",
    "            (prospect_df_temp[\"LastName\"] == last_name.upper())\n",
    "            & (prospect_df_temp[\"FirstName\"] == first_name.upper())\n",
    "            & (prospect_df_temp[\"AddressLine1\"] == address_line1.upper())\n",
    "            & (prospect_df_temp[\"AddressLine2\"] == address_line2.upper())\n",
    "            & (prospect_df_temp[\"PostalCode\"] == postalcode.upper())\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            # Set values from the matching prospect record\n",
    "            data[\"AgencyID\"].append(match[\"AgencyID\"].iloc[-1])\n",
    "            data[\"CreditRating\"].append(match[\"CreditRating\"].iloc[-1])\n",
    "            data[\"NetWorth\"].append(match[\"NetWorth\"].iloc[-1])\n",
    "            data[\"MarketingNameplate\"].append(match[\"MarketingNameplate\"].iloc[-1])\n",
    "        else:\n",
    "            # Set values to NULL\n",
    "            data[\"AgencyID\"].append(None)\n",
    "            data[\"CreditRating\"].append(None)\n",
    "            data[\"NetWorth\"].append(None)\n",
    "            data[\"MarketingNameplate\"].append(None)\n",
    "    else:\n",
    "        # Set values to NULL due to later 'UPDCUST' or 'INACT'\n",
    "        data[\"AgencyID\"].append(None)\n",
    "        data[\"CreditRating\"].append(None)\n",
    "        data[\"NetWorth\"].append(None)\n",
    "        data[\"MarketingNameplate\"].append(None)\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Get unique TX_IDs and remove None values \n",
    "unique_tax_ids = set(national_tax_ids + local_tax_ids) - {None}\n",
    "all_tax_info = get_all_tax_info(unique_tax_ids)\n",
    "\n",
    "# map each tax ID to its description and rate\n",
    "for i in range(len(national_tax_ids)):\n",
    "    national_info = all_tax_info.get(\n",
    "        national_tax_ids[i], {\"TX_NAME\": None, \"TX_RATE\": None}\n",
    "    )\n",
    "    data[\"NationalTaxRateDesc\"].append(national_info[\"TX_NAME\"])\n",
    "    data[\"NationalTaxRate\"].append(national_info[\"TX_RATE\"])\n",
    "\n",
    "    local_info = all_tax_info.get(local_tax_ids[i], {\"TX_NAME\": None, \"TX_RATE\": None})\n",
    "    data[\"LocalTaxRateDesc\"].append(local_info[\"TX_NAME\"])\n",
    "    data[\"LocalTaxRate\"].append(local_info[\"TX_RATE\"])\n",
    "\n",
    "# Creating DataFrame\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, pd.DataFrame(data)])\n",
    "dimCustomer_df[\"Status\"] = \"ACTIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:56.211574Z",
     "iopub.status.busy": "2023-12-22T12:13:56.210558Z",
     "iopub.status.idle": "2023-12-22T12:13:56.224557Z",
     "shell.execute_reply": "2023-12-22T12:13:56.223557Z",
     "shell.execute_reply.started": "2023-12-22T12:13:56.211574Z"
    }
   },
   "outputs": [],
   "source": [
    "def df2dict(df, exclude_columns):\n",
    "    # Remove the specified columns from the DataFrame\n",
    "    df_filtered = df.drop(columns=exclude_columns)\n",
    "    # Convert the filtered DataFrame to a dictionary\n",
    "    df_dict = df_filtered.to_dict(orient='index')\n",
    "    # Create a new dictionary that maps CustomerID to a dictionary of column values\n",
    "    customer_dict = {row['CustomerID']: {col: val for col, val in row.items() if col != 'CustomerID'} for _, row in df_dict.items()}\n",
    "    return customer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:56.227558Z",
     "iopub.status.busy": "2023-12-22T12:13:56.226573Z",
     "iopub.status.idle": "2023-12-22T12:13:56.632557Z",
     "shell.execute_reply": "2023-12-22T12:13:56.630820Z",
     "shell.execute_reply.started": "2023-12-22T12:13:56.227558Z"
    }
   },
   "outputs": [],
   "source": [
    "exclude_columns = ['SK_CustomerID', 'IsCurrent', 'BatchID', 'EffectiveDate', 'EndDate', 'Status']\n",
    "# dictionary to track latest values for each customer\n",
    "customer_data = df2dict(dimCustomer_df, exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:56.634555Z",
     "iopub.status.busy": "2023-12-22T12:13:56.634555Z",
     "iopub.status.idle": "2023-12-22T12:13:57.270225Z",
     "shell.execute_reply": "2023-12-22T12:13:57.269285Z",
     "shell.execute_reply.started": "2023-12-22T12:13:56.634555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store data for NEW actions\n",
    "data = {col: [] for col in data.keys()}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"UPDCUST\"\n",
    "for index, action in enumerate(upd_actions):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    name = customer.find(\"Name\", namespaces=namespace)\n",
    "    contact_info = customer.find(\"ContactInfo\", namespaces=namespace)\n",
    "    address = customer.find(\"Address\", namespaces=namespace)\n",
    "    tax_info = customer.find(\"TaxInfo\", namespaces=namespace)\n",
    "\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "\n",
    "    # Update tax_id\n",
    "    tax_id = customer.get(\"C_TAX_ID\", None)\n",
    "    if tax_id is None:\n",
    "        tax_id = customer_data[customer_id][\"TaxID\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"TaxID\"] = tax_id\n",
    "    data[\"TaxID\"].append(tax_id)\n",
    "    # Update tier\n",
    "    tier = customer.get(\"C_TIER\", None)\n",
    "    tier = int(tier) if tier else None\n",
    "    if tier is None:\n",
    "        tier = customer_data[customer_id][\"Tier\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"Tier\"] = tier\n",
    "        if tier is not None and tier not in (1,2,3):\n",
    "            \"\"\"\n",
    "            A record will be inserted in the DImessages table if a customer's Tier is not one of the valid\n",
    "            values (1,2,3). The MessageSource is DimCustomer, the MessageType is Alert and the\n",
    "            MessageText is Invalid customer tier. The MessageData field is C_ID =  followed by the\n",
    "            natural key value of the record, then , C_TIER =  and the C_TIER value.\n",
    "            \"\"\"\n",
    "            MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "            batch_id = 1\n",
    "            sk_customer_id = len(data[\"CustomerID\"]) + dimCustomer_df.shape[0]\n",
    "            message = f\"C_ID = {sk_customer_id}, C_TIER = {tier}\"\n",
    "            message_source = \"DimCustomer\"\n",
    "            message_type = \"Alert\"\n",
    "            message_text = \"Invalid customer tier\"\n",
    "            query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(query))\n",
    "                conn.commit()\n",
    "    data[\"Tier\"].append(tier)\n",
    "    # Update DOB\n",
    "    dob = customer.get(\"C_DOB\", None)\n",
    "    dob = pd.to_datetime(dob, format=\"%Y-%m-%d\") if dob else None\n",
    "    if dob is None:\n",
    "        dob = customer_data[customer_id][\"DOB\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"DOB\"] = dob\n",
    "        \"\"\"A record will be reported in the DImessages table if a customer's DOB is invalid. A customer's\n",
    "        DOB is invalid if DOB < Batch Date - 100 years or DOB > Batch Date (customer is over 100\n",
    "        years old or born in the future). The MessageSource is DimCustomer, the MessageType is\n",
    "        Alert and the MessageText is DOB out of range. The MessageData field is C_ID = \n",
    "        followed by the natural key value of the record, then , C_DOB =  and the C_DOB value.\"\"\"\n",
    "        if dob and (dob < BATCH_DATE - pd.Timedelta(days=100*365) or dob > BATCH_DATE):\n",
    "            MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "            batch_id = 1\n",
    "            sk_customer_id = len(data[\"CustomerID\"])\n",
    "            message = f\"C_ID = {sk_customer_id}, C_DOB = {dob}\"\n",
    "            message_source = \"DimCustomer\"\n",
    "            message_type = \"Alert\"\n",
    "            message_text = \"DOB out of range\"\n",
    "            query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(query))\n",
    "                conn.commit()\n",
    "    data[\"DOB\"].append(dob)\n",
    "    # Update gender\n",
    "    gender = customer.get(\"C_GNDR\", None)\n",
    "    if gender is None:\n",
    "        gender = customer_data[customer_id][\"Gender\"]\n",
    "    else:\n",
    "        gender = gender.upper()\n",
    "        gender = \"U\" if gender not in (\"M\", \"F\") else gender\n",
    "        customer_data[customer_id][\"Gender\"] = gender\n",
    "    data[\"Gender\"].append(gender)\n",
    "\n",
    "    # Update first name\n",
    "    if name is None:\n",
    "        first_name = customer_data[customer_id][\"FirstName\"]\n",
    "        data[\"FirstName\"].append(first_name)\n",
    "        middle_initial = customer_data[customer_id][\"MiddleInitial\"]\n",
    "        data[\"MiddleInitial\"].append(middle_initial)\n",
    "        last_name = customer_data[customer_id][\"LastName\"]\n",
    "        data[\"LastName\"].append(last_name)\n",
    "    else:\n",
    "        first_name = name.findtext(\"C_F_NAME\", default=None, namespaces=namespace)\n",
    "        if first_name is None:\n",
    "            first_name = customer_data[customer_id][\"FirstName\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"FirstName\"] = first_name\n",
    "        data[\"FirstName\"].append(first_name)\n",
    "        # Update middle initial\n",
    "        middle_initial = name.findtext(\"C_M_NAME\", default=None, namespaces=namespace)\n",
    "        if middle_initial is None:\n",
    "            middle_initial = customer_data[customer_id][\"MiddleInitial\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"MiddleInitial\"] = middle_initial\n",
    "        data[\"MiddleInitial\"].append(middle_initial)\n",
    "        # Update last name\n",
    "        last_name = name.findtext(\"C_L_NAME\", default=None, namespaces=namespace)\n",
    "        if last_name is None:\n",
    "            last_name = customer_data[customer_id][\"LastName\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"LastName\"] = last_name\n",
    "        data[\"LastName\"].append(last_name if last_name else None)\n",
    "\n",
    "    if contact_info is None:\n",
    "        prim_email = customer_data[customer_id][\"Email1\"]\n",
    "        data[\"Email1\"].append(prim_email)\n",
    "        alt_email = customer_data[customer_id][\"Email2\"]\n",
    "        data[\"Email2\"].append(alt_email)\n",
    "        phone1 = customer_data[customer_id][\"Phone1\"]\n",
    "        data[\"Phone1\"].append(phone1)\n",
    "        phone2 = customer_data[customer_id][\"Phone2\"]\n",
    "        data[\"Phone2\"].append(phone2)\n",
    "        phone3 = customer_data[customer_id][\"Phone3\"]\n",
    "        data[\"Phone3\"].append(phone3)\n",
    "    else:\n",
    "        # update primary email\n",
    "        prim_email = contact_info.findtext(\n",
    "            \"C_PRIM_EMAIL\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if prim_email is None:\n",
    "            prim_email = customer_data[customer_id][\"Email1\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Email1\"] = prim_email\n",
    "        data[\"Email1\"].append(prim_email if prim_email else None)\n",
    "        # update alternate email\n",
    "        alt_email = contact_info.findtext(\n",
    "            \"C_ALT_EMAIL\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if alt_email is None:\n",
    "            alt_email = customer_data[customer_id][\"Email2\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Email2\"] = alt_email\n",
    "        data[\"Email2\"].append(alt_email if alt_email else None)\n",
    "        # update phone numbers\n",
    "        phone1 = contact_info.find(\"C_PHONE_1\", namespaces=namespace)\n",
    "        if phone1 is None:\n",
    "            phone1 = customer_data[customer_id][\"Phone1\"]\n",
    "        else:\n",
    "            phone1 = format_phone_number(phone1)\n",
    "            customer_data[customer_id][\"Phone1\"] = phone1\n",
    "        data[\"Phone1\"].append(phone1)\n",
    "        phone2 = contact_info.find(\"C_PHONE_2\", namespaces=namespace)\n",
    "        if phone2 is None:\n",
    "            phone2 = customer_data[customer_id][\"Phone2\"]\n",
    "        else:\n",
    "            phone2 = format_phone_number(phone2)\n",
    "            customer_data[customer_id][\"Phone2\"] = phone2\n",
    "        data[\"Phone2\"].append(phone2)\n",
    "        phone3 = contact_info.find(\"C_PHONE_3\", namespaces=namespace)\n",
    "        if phone3 is None:\n",
    "            phone3 = customer_data[customer_id][\"Phone3\"]\n",
    "        else:\n",
    "            phone3 = format_phone_number(phone3)\n",
    "            customer_data[customer_id][\"Phone3\"] = phone3\n",
    "        data[\"Phone3\"].append(phone3)\n",
    "\n",
    "    if address is None:\n",
    "        address_line1 = customer_data[customer_id][\"AddressLine1\"]\n",
    "        data[\"AddressLine1\"].append(address_line1)\n",
    "        address_line2 = customer_data[customer_id][\"AddressLine2\"]\n",
    "        data[\"AddressLine2\"].append(address_line2)\n",
    "        postalcode = customer_data[customer_id][\"PostalCode\"]\n",
    "        data[\"PostalCode\"].append(postalcode)\n",
    "        city = customer_data[customer_id][\"City\"]\n",
    "        data[\"City\"].append(city)\n",
    "        state_prov = customer_data[customer_id][\"StateProv\"]\n",
    "        data[\"StateProv\"].append(state_prov)\n",
    "        country = customer_data[customer_id][\"Country\"]\n",
    "        data[\"Country\"].append(country)\n",
    "    else:\n",
    "        # Extracting address information\n",
    "        address_line1 = address.findtext(\n",
    "            \"C_ADLINE1\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if address_line1 is None:\n",
    "            address_line1 = customer_data[customer_id][\"AddressLine1\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"AddressLine1\"] = address_line1\n",
    "        data[\"AddressLine1\"].append(address_line1 if address_line1 else None)\n",
    "        address_line2 = address.findtext(\n",
    "            \"C_ADLINE2\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if address_line2 is None:\n",
    "            address_line2 = customer_data[customer_id][\"AddressLine2\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"AddressLine2\"] = address_line2\n",
    "        data[\"AddressLine2\"].append(address_line2 if address_line2 else None)\n",
    "        postalcode = address.findtext(\"C_ZIPCODE\", default=None, namespaces=namespace)\n",
    "        if postalcode is None:\n",
    "            postalcode = customer_data[customer_id][\"PostalCode\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"PostalCode\"] = postalcode\n",
    "        data[\"PostalCode\"].append(postalcode if postalcode else None)\n",
    "        city = address.findtext(\"C_CITY\", default=None, namespaces=namespace)\n",
    "        if city is None:\n",
    "            city = customer_data[customer_id][\"City\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"City\"] = city\n",
    "        data[\"City\"].append(city if city else None)\n",
    "        state_prov = address.findtext(\n",
    "            \"C_STATE_PROV\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if state_prov is None:\n",
    "            state_prov = customer_data[customer_id][\"StateProv\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"StateProv\"] = state_prov\n",
    "        data[\"StateProv\"].append(state_prov if state_prov else None)\n",
    "        country = address.findtext(\"C_CTRY\", default=None, namespaces=namespace)\n",
    "        if country is None:\n",
    "            country = customer_data[customer_id][\"Country\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Country\"] = country\n",
    "        data[\"Country\"].append(country if country else None)\n",
    "    \n",
    "    # Store TX_ID as placeholders\n",
    "    if tax_info is None:\n",
    "        national_tax_rate_desc = customer_data[customer_id][\"NationalTaxRateDesc\"]\n",
    "        data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "        national_tax_rate = customer_data[customer_id][\"NationalTaxRate\"]\n",
    "        data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "        local_tax_rate_desc = customer_data[customer_id][\"LocalTaxRateDesc\"]\n",
    "        data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "        local_tax_rate = customer_data[customer_id][\"LocalTaxRate\"]\n",
    "        data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "        national_tax_ids.append(None)\n",
    "        local_tax_ids.append(None)        \n",
    "    else:\n",
    "        national_tax_id = tax_info.findtext(\n",
    "            \"C_NAT_TX_ID\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if national_tax_id is None:\n",
    "            national_tax_rate_desc = customer_data[customer_id][\"NationalTaxRateDesc\"]\n",
    "            data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "            national_tax_rate = customer_data[customer_id][\"NationalTaxRate\"]\n",
    "            data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "            national_tax_ids.append(None)\n",
    "        else:\n",
    "            result = pd.read_sql(f\"SELECT TX_NAME, TX_RATE FROM taxrate WHERE TX_ID = '{national_tax_id}'\", engine)\n",
    "            national_tax_rate_desc = result.iloc[0, 0]\n",
    "            national_tax_rate = result.iloc[0, 1]\n",
    "            customer_data[customer_id][\"NationalTaxRateDesc\"] = national_tax_rate_desc\n",
    "            customer_data[customer_id][\"NationalTaxRate\"] = national_tax_rate\n",
    "            data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "            data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "        local_tax_id = tax_info.findtext(\n",
    "            \"C_LCL_TX_ID\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if local_tax_id is None:\n",
    "            local_tax_rate_desc = customer_data[customer_id][\"LocalTaxRateDesc\"]\n",
    "            data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "            local_tax_rate = customer_data[customer_id][\"LocalTaxRate\"]\n",
    "            data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "        else:\n",
    "            result = pd.read_sql(f\"SELECT TX_NAME, TX_RATE FROM taxrate WHERE TX_ID = '{local_tax_id}'\", engine)\n",
    "            local_tax_rate_desc = result.iloc[0, 0]\n",
    "            local_tax_rate = result.iloc[0, 1]\n",
    "            customer_data[customer_id][\"LocalTaxRateDesc\"] = local_tax_rate_desc\n",
    "            customer_data[customer_id][\"LocalTaxRate\"] = local_tax_rate\n",
    "            data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "            data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "\n",
    "\n",
    "    if not has_later_update(customer_id, index):\n",
    "        # Find matching prospect record\n",
    "        match = prospect_df[\n",
    "            (prospect_df_temp[\"LastName\"] == last_name.upper())\n",
    "            & (prospect_df_temp[\"FirstName\"] == first_name.upper())\n",
    "            & (prospect_df_temp[\"AddressLine1\"] == address_line1.upper())\n",
    "            & (prospect_df_temp[\"AddressLine2\"] == address_line2.upper())\n",
    "            & (prospect_df_temp[\"PostalCode\"] == postalcode.upper())\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            # Set values from the matching prospect record\n",
    "            data[\"AgencyID\"].append(match[\"AgencyID\"].iloc[-1])\n",
    "            data[\"CreditRating\"].append(match[\"CreditRating\"].iloc[-1])\n",
    "            data[\"NetWorth\"].append(match[\"NetWorth\"].iloc[-1])\n",
    "            data[\"MarketingNameplate\"].append(match[\"MarketingNameplate\"].iloc[-1])\n",
    "        else:\n",
    "            # Set values to those in customer_data\n",
    "            data[\"AgencyID\"].append(customer_data[customer_id][\"AgencyID\"])\n",
    "            data[\"CreditRating\"].append(customer_data[customer_id][\"CreditRating\"])\n",
    "            data[\"NetWorth\"].append(customer_data[customer_id][\"NetWorth\"])\n",
    "            data[\"MarketingNameplate\"].append(customer_data[customer_id][\"MarketingNameplate\"])\n",
    "    else:\n",
    "        # Set values to those in customer_data due to later 'UPDCUST' or 'INACT'\n",
    "        data[\"AgencyID\"].append(customer_data[customer_id][\"AgencyID\"])\n",
    "        data[\"CreditRating\"].append(customer_data[customer_id][\"CreditRating\"])\n",
    "        data[\"NetWorth\"].append(customer_data[customer_id][\"NetWorth\"])\n",
    "        data[\"MarketingNameplate\"].append(customer_data[customer_id][\"MarketingNameplate\"])\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Creating DataFrame\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, pd.DataFrame(data)])\n",
    "dimCustomer_df[\"Status\"] = \"ACTIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.273232Z",
     "iopub.status.busy": "2023-12-22T12:13:57.272230Z",
     "iopub.status.idle": "2023-12-22T12:13:57.473229Z",
     "shell.execute_reply": "2023-12-22T12:13:57.472233Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.273232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store data for NEW actions\n",
    "data = {col: [] for col in data.keys()}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"INACT\"\n",
    "for index, action in enumerate(inact_actions):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "    # Copy all fields from customer_data\n",
    "    for col in data.keys():\n",
    "        if col in (\"CustomerID\", \"EffectiveDate\"):\n",
    "            continue\n",
    "        else:\n",
    "            data[col].append(customer_data[customer_id][col])\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Creating DataFrame\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df[\"Status\"] = \"INACTIVE\"\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, data_df])\n",
    "dimCustomer_df[\"BatchID\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.476230Z",
     "iopub.status.busy": "2023-12-22T12:13:57.476230Z",
     "iopub.status.idle": "2023-12-22T12:13:57.520227Z",
     "shell.execute_reply": "2023-12-22T12:13:57.518490Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.476230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10810 entries, 0 to 859\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   SK_CustomerID        10810 non-null  int64         \n",
      " 1   CustomerID           10810 non-null  int64         \n",
      " 2   TaxID                10810 non-null  object        \n",
      " 3   Status               10810 non-null  object        \n",
      " 4   LastName             10810 non-null  object        \n",
      " 5   FirstName            10810 non-null  object        \n",
      " 6   MiddleInitial        4036 non-null   object        \n",
      " 7   Gender               10810 non-null  object        \n",
      " 8   Tier                 10382 non-null  float64       \n",
      " 9   DOB                  10810 non-null  datetime64[ns]\n",
      " 10  AddressLine1         10810 non-null  object        \n",
      " 11  AddressLine2         1230 non-null   object        \n",
      " 12  PostalCode           10810 non-null  object        \n",
      " 13  City                 10810 non-null  object        \n",
      " 14  StateProv            10810 non-null  object        \n",
      " 15  Country              10732 non-null  object        \n",
      " 16  Phone1               10590 non-null  object        \n",
      " 17  Phone2               8132 non-null   object        \n",
      " 18  Phone3               3245 non-null   object        \n",
      " 19  Email1               10810 non-null  object        \n",
      " 20  Email2               5525 non-null   object        \n",
      " 21  NationalTaxRateDesc  10810 non-null  object        \n",
      " 22  NationalTaxRate      10810 non-null  float64       \n",
      " 23  LocalTaxRateDesc     10810 non-null  object        \n",
      " 24  LocalTaxRate         10810 non-null  float64       \n",
      " 25  AgencyID             547 non-null    object        \n",
      " 26  CreditRating         512 non-null    object        \n",
      " 27  NetWorth             524 non-null    object        \n",
      " 28  MarketingNameplate   540 non-null    object        \n",
      " 29  IsCurrent            0 non-null      boolean       \n",
      " 30  BatchID              10810 non-null  int64         \n",
      " 31  EffectiveDate        10810 non-null  datetime64[ns]\n",
      " 32  EndDate              0 non-null      datetime64[ns]\n",
      "dtypes: boolean(1), datetime64[ns](3), float64(3), int64(3), object(23)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dimCustomer_df['SK_CustomerID'] = range(1, len(dimCustomer_df) + 1)\n",
    "dimCustomer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.522228Z",
     "iopub.status.busy": "2023-12-22T12:13:57.522228Z",
     "iopub.status.idle": "2023-12-22T12:13:57.581226Z",
     "shell.execute_reply": "2023-12-22T12:13:57.580492Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.522228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by CustomerID and EffectiveDate\n",
    "dimCustomer_df.sort_values(by=['CustomerID', 'EffectiveDate'], inplace=True)\n",
    "# Create a shifted DataFrame\n",
    "shifted_df = dimCustomer_df.shift(-1)\n",
    "# Update EndDate: If next row has same CustomerID, use its EffectiveDate; otherwise, use default date\n",
    "dimCustomer_df['EndDate'] = pd.Timestamp('9999-12-31')\n",
    "mask = dimCustomer_df['CustomerID'] == shifted_df['CustomerID']\n",
    "dimCustomer_df.loc[mask, 'EndDate'] = shifted_df.loc[mask, 'EffectiveDate']\n",
    "\n",
    "# Update IsCurrent: True if next row has different CustomerID or is the last row\n",
    "dimCustomer_df['IsCurrent'] = ~mask\n",
    "dimCustomer_df.sort_values(by=['SK_CustomerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.583226Z",
     "iopub.status.busy": "2023-12-22T12:13:57.583226Z",
     "iopub.status.idle": "2023-12-22T12:13:57.598229Z",
     "shell.execute_reply": "2023-12-22T12:13:57.596247Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.583226Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'CustomerID': sqlalchemy.types.Integer,\n",
    "    'TaxID': sqlalchemy.types.String(20),\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'LastName': sqlalchemy.types.String(30),\n",
    "    'FirstName': sqlalchemy.types.String(30),\n",
    "    'MiddleInitial': sqlalchemy.types.String(1),\n",
    "    'Gender': sqlalchemy.types.String(1),\n",
    "    'Tier': sqlalchemy.types.SmallInteger,\n",
    "    'DOB': sqlalchemy.types.Date,\n",
    "    'AddressLine1': sqlalchemy.types.String(80),\n",
    "    'AddressLine2': sqlalchemy.types.String(80),\n",
    "    'PostalCode': sqlalchemy.types.String(12),\n",
    "    'City': sqlalchemy.types.String(25),\n",
    "    'StateProv': sqlalchemy.types.String(20),\n",
    "    'Country': sqlalchemy.types.String(24),\n",
    "    'Phone1': sqlalchemy.types.String(30),\n",
    "    'Phone2': sqlalchemy.types.String(30),\n",
    "    'Phone3': sqlalchemy.types.String(30),\n",
    "    'Email1': sqlalchemy.types.String(50),\n",
    "    'Email2': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'LocalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'LocalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'AgencyID': sqlalchemy.types.String(30),\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.Numeric(10),\n",
    "    'MarketingNameplate': sqlalchemy.types.String(100),\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.601229Z",
     "iopub.status.busy": "2023-12-22T12:13:57.600228Z",
     "iopub.status.idle": "2023-12-22T12:13:57.629231Z",
     "shell.execute_reply": "2023-12-22T12:13:57.627230Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.601229Z"
    }
   },
   "outputs": [],
   "source": [
    "# cast to int 32\n",
    "cols = ['SK_CustomerID', 'CustomerID', 'BatchID']\n",
    "for col in cols:\n",
    "    dimCustomer_df[col] = dimCustomer_df[col].astype('int')\n",
    "dimCustomer_df['Tier'] = dimCustomer_df['Tier'].astype('UInt8')\n",
    "dimCustomer_df['NationalTaxRate'] = dimCustomer_df['NationalTaxRate'].astype('float32')\n",
    "dimCustomer_df['LocalTaxRate'] = dimCustomer_df['LocalTaxRate'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.632227Z",
     "iopub.status.busy": "2023-12-22T12:13:57.631226Z",
     "iopub.status.idle": "2023-12-22T12:13:57.706227Z",
     "shell.execute_reply": "2023-12-22T12:13:57.704228Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.632227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to the appropriate types\n",
    "dimCustomer_df['SK_CustomerID'] = dimCustomer_df['SK_CustomerID'].astype(np.int32)\n",
    "dimCustomer_df['CustomerID'] = dimCustomer_df['CustomerID'].astype(np.int32)\n",
    "dimCustomer_df['Tier'] = dimCustomer_df['Tier'].astype(pd.Int8Dtype())\n",
    "dimCustomer_df['NationalTaxRate'] = dimCustomer_df['NationalTaxRate'].astype(np.float64)\n",
    "dimCustomer_df['LocalTaxRate'] = dimCustomer_df['LocalTaxRate'].astype(np.float64)\n",
    "dimCustomer_df['CreditRating'] = dimCustomer_df['CreditRating'].astype(pd.Int16Dtype())\n",
    "dimCustomer_df['NetWorth'] = dimCustomer_df['NetWorth'].astype(pd.Float64Dtype())\n",
    "dimCustomer_df['BatchID'] = dimCustomer_df['BatchID'].astype(np.int16)\n",
    "\n",
    "# Convert date columns to datetime.date\n",
    "dimCustomer_df['DOB'] = pd.to_datetime(dimCustomer_df['DOB']).dt.date\n",
    "dimCustomer_df['EffectiveDate'] = pd.to_datetime(dimCustomer_df['EffectiveDate']).dt.date\n",
    "dimCustomer_df['EndDate'] = pd.to_datetime(dimCustomer_df['EndDate']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.709236Z",
     "iopub.status.busy": "2023-12-22T12:13:57.707232Z",
     "iopub.status.idle": "2023-12-22T12:13:57.724226Z",
     "shell.execute_reply": "2023-12-22T12:13:57.720239Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.708239Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimCustomer (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    CustomerID INT UNSIGNED NOT NULL,\n",
    "    TaxID CHAR(20) NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    LastName CHAR(30) NOT NULL,\n",
    "    FirstName CHAR(30) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Gender CHAR(1),\n",
    "    Tier TINYINT UNSIGNED,\n",
    "    DOB DATE NOT NULL,\n",
    "    AddressLine1 CHAR(80) NOT NULL,\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12) NOT NULL,\n",
    "    City CHAR(25) NOT NULL,\n",
    "    StateProv CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Phone1 CHAR(30),\n",
    "    Phone2 CHAR(30),\n",
    "    Phone3 CHAR(30),\n",
    "    Email1 CHAR(50),\n",
    "    Email2 CHAR(50),\n",
    "    NationalTaxRateDesc CHAR(50),\n",
    "    NationalTaxRate DECIMAL(6, 5),\n",
    "    LocalTaxRateDesc CHAR(50),\n",
    "    LocalTaxRate DECIMAL(6, 5),\n",
    "    AgencyID CHAR(30),\n",
    "    CreditRating SMALLINT UNSIGNED,\n",
    "    NetWorth DECIMAL(10),\n",
    "    MarketingNameplate CHAR(100),\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_CustomerID)\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.727225Z",
     "iopub.status.busy": "2023-12-22T12:13:57.726226Z",
     "iopub.status.idle": "2023-12-22T12:13:57.767225Z",
     "shell.execute_reply": "2023-12-22T12:13:57.766296Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.727225Z"
    }
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:57.769235Z",
     "iopub.status.busy": "2023-12-22T12:13:57.768228Z",
     "iopub.status.idle": "2023-12-22T12:13:59.402838Z",
     "shell.execute_reply": "2023-12-22T12:13:59.401098Z",
     "shell.execute_reply.started": "2023-12-22T12:13:57.769235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10810"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimCustomer_df.to_sql('dimcustomer', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.404838Z",
     "iopub.status.busy": "2023-12-22T12:13:59.403837Z",
     "iopub.status.idle": "2023-12-22T12:13:59.667073Z",
     "shell.execute_reply": "2023-12-22T12:13:59.666416Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.404838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create temporary uppercase columns for merging in both DataFrames\n",
    "merge_fields = [\"FirstName\", \"LastName\", \"AddressLine1\", \"AddressLine2\", \"PostalCode\"]\n",
    "for field in merge_fields:\n",
    "    prospect_df[f\"temp_{field}\"] = prospect_df[field].str.upper()\n",
    "    dimCustomer_df[f\"temp_{field}\"] = dimCustomer_df[field].str.upper()\n",
    "\n",
    "# Filter dimCustomer_df for active and current customers\n",
    "active_customers = dimCustomer_df[(dimCustomer_df['IsCurrent'] == True) & (dimCustomer_df['Status'] == 'ACTIVE')]\n",
    "\n",
    "# Perform an outer merge on the temporary uppercase fields\n",
    "temp_merge_fields = [f\"temp_{field}\" for field in merge_fields]\n",
    "merged_df = prospect_df.merge(active_customers, how='left', \n",
    "                              left_on=temp_merge_fields, right_on=temp_merge_fields,\n",
    "                              indicator=True)\n",
    "\n",
    "# Update IsCustomer based on whether a match was found\n",
    "prospect_df['IsCustomer'] = merged_df['_merge'] == 'both'\n",
    "\n",
    "# Clean up by dropping the temporary columns\n",
    "prospect_df.drop(columns=temp_merge_fields, inplace=True)\n",
    "dimCustomer_df.drop(columns=temp_merge_fields, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.670076Z",
     "iopub.status.busy": "2023-12-22T12:13:59.669053Z",
     "iopub.status.idle": "2023-12-22T12:13:59.683055Z",
     "shell.execute_reply": "2023-12-22T12:13:59.682053Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.670076Z"
    }
   },
   "outputs": [],
   "source": [
    "prospect_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.688053Z",
     "iopub.status.busy": "2023-12-22T12:13:59.687056Z",
     "iopub.status.idle": "2023-12-22T12:13:59.715049Z",
     "shell.execute_reply": "2023-12-22T12:13:59.713052Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.688053Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'AgencyID': sqlalchemy.types.CHAR(30),\n",
    "    'SK_RecordDateID': sqlalchemy.types.Integer,\n",
    "    'SK_UpdateDateID': sqlalchemy.types.Integer,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'IsCustomer': sqlalchemy.types.Boolean,\n",
    "    'LastName': sqlalchemy.types.CHAR(30),\n",
    "    'FirstName': sqlalchemy.types.CHAR(30),\n",
    "    'MiddleInitial': sqlalchemy.types.CHAR(1),\n",
    "    'Gender': sqlalchemy.types.CHAR(1),\n",
    "    'AddressLine1': sqlalchemy.types.CHAR(80),\n",
    "    'AddressLine2': sqlalchemy.types.CHAR(80),\n",
    "    'PostalCode': sqlalchemy.types.CHAR(12),\n",
    "    'City': sqlalchemy.types.CHAR(25),\n",
    "    'State': sqlalchemy.types.CHAR(20),\n",
    "    'Country': sqlalchemy.types.CHAR(24),\n",
    "    'Phone': sqlalchemy.types.CHAR(30),\n",
    "    'Income': sqlalchemy.types.Integer,\n",
    "    'NumberCars': sqlalchemy.types.SmallInteger,\n",
    "    'NumberChildren': sqlalchemy.types.SmallInteger,\n",
    "    'MaritalStatus': sqlalchemy.types.CHAR(1),\n",
    "    'Age': sqlalchemy.types.SmallInteger,\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'OwnOrRentFlag': sqlalchemy.types.CHAR(1),\n",
    "    'Employer': sqlalchemy.types.CHAR(30),\n",
    "    'NumberCreditCards': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.BigInteger,\n",
    "    'MarketingNameplate': sqlalchemy.types.CHAR(100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.717051Z",
     "iopub.status.busy": "2023-12-22T12:13:59.716054Z",
     "iopub.status.idle": "2023-12-22T12:13:59.761050Z",
     "shell.execute_reply": "2023-12-22T12:13:59.760115Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.717051Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Prospect (\n",
    "    AgencyID CHAR(30) NOT NULL,\n",
    "    SK_RecordDateID INT UNSIGNED NOT NULL,\n",
    "    SK_UpdateDateID INT UNSIGNED NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    IsCustomer BOOLEAN NOT NULL,\n",
    "    LastName CHAR(30) NOT NULL,\n",
    "    FirstName CHAR(30) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Gender CHAR(1) CHECK (Gender IN ('M', 'F', 'U')),\n",
    "    AddressLine1 CHAR(80),\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12),\n",
    "    City CHAR(25) NOT NULL,\n",
    "    State CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Phone CHAR(30),\n",
    "    Income INT UNSIGNED,\n",
    "    NumberCars TINYINT UNSIGNED,\n",
    "    NumberChildren TINYINT UNSIGNED,\n",
    "    MaritalStatus CHAR(1) CHECK (MaritalStatus IN ('S', 'M', 'D', 'W', 'U')),\n",
    "    Age TINYINT UNSIGNED,\n",
    "    CreditRating SMALLINT UNSIGNED,\n",
    "    OwnOrRentFlag CHAR(1) CHECK (OwnOrRentFlag IN ('O', 'R', 'U')),\n",
    "    Employer CHAR(30),\n",
    "    NumberCreditCards TINYINT UNSIGNED,\n",
    "    NetWorth BIGINT,\n",
    "    MarketingNameplate CHAR(100),\n",
    "    PRIMARY KEY (AgencyID, SK_RecordDateID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.763049Z",
     "iopub.status.busy": "2023-12-22T12:13:59.762050Z",
     "iopub.status.idle": "2023-12-22T12:13:59.808050Z",
     "shell.execute_reply": "2023-12-22T12:13:59.807105Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.763049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24970 entries, 0 to 24969\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   AgencyID            24970 non-null  object\n",
      " 1   SK_RecordDateID     24970 non-null  int64 \n",
      " 2   SK_UpdateDateID     24970 non-null  int64 \n",
      " 3   BatchID             24970 non-null  int64 \n",
      " 4   IsCustomer          24970 non-null  bool  \n",
      " 5   LastName            24970 non-null  object\n",
      " 6   FirstName           24970 non-null  object\n",
      " 7   MiddleInitial       10982 non-null  object\n",
      " 8   Gender              24970 non-null  object\n",
      " 9   AddressLine1        24097 non-null  object\n",
      " 10  AddressLine2        17160 non-null  object\n",
      " 11  PostalCode          24098 non-null  object\n",
      " 12  City                24970 non-null  object\n",
      " 13  State               24970 non-null  object\n",
      " 14  Country             23929 non-null  object\n",
      " 15  Phone               23674 non-null  object\n",
      " 16  Income              23760 non-null  Int64 \n",
      " 17  NumberCars          23708 non-null  Int8  \n",
      " 18  NumberChildren      23741 non-null  Int8  \n",
      " 19  MaritalStatus       24970 non-null  object\n",
      " 20  Age                 23685 non-null  Int8  \n",
      " 21  CreditRating        23726 non-null  Int16 \n",
      " 22  OwnOrRentFlag       24970 non-null  object\n",
      " 23  Employer            23710 non-null  object\n",
      " 24  NumberCreditCards   23693 non-null  Int8  \n",
      " 25  NetWorth            23678 non-null  Int64 \n",
      " 26  MarketingNameplate  24580 non-null  object\n",
      "dtypes: Int16(1), Int64(2), Int8(4), bool(1), int64(3), object(16)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "prospect_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:13:59.810570Z",
     "iopub.status.busy": "2023-12-22T12:13:59.809572Z",
     "iopub.status.idle": "2023-12-22T12:14:03.076637Z",
     "shell.execute_reply": "2023-12-22T12:14:03.075692Z",
     "shell.execute_reply.started": "2023-12-22T12:13:59.810570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24970"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prospect_df.to_sql('prospect', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_end_time = datetime.now()\n",
    "print(f\"Prospect took {(prospect_end_time - prospect_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Prospect file is processed, the number of source rows is counted. After the last\n",
    "row, a Status message is written to the DImessages table, with the MessageSource\n",
    "Prospect, MessageText Source rows and the MessageData field containing the\n",
    "number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:14:03.078316Z",
     "iopub.status.busy": "2023-12-22T12:14:03.078316Z",
     "iopub.status.idle": "2023-12-22T12:14:03.093314Z",
     "shell.execute_reply": "2023-12-22T12:14:03.091317Z",
     "shell.execute_reply.started": "2023-12-22T12:14:03.078316Z"
    }
   },
   "outputs": [],
   "source": [
    "num_rows = prospect_df.shape[0]\n",
    "message_type = \"Status\"\n",
    "message_source = \"Prospect\"\n",
    "message_text = f\"Inserted rows\"\n",
    "MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "batch_id = 1\n",
    "\n",
    "query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{num_rows}')\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:14:03.096314Z",
     "iopub.status.busy": "2023-12-22T12:14:03.095315Z",
     "iopub.status.idle": "2023-12-22T12:14:03.109312Z",
     "shell.execute_reply": "2023-12-22T12:14:03.107323Z",
     "shell.execute_reply.started": "2023-12-22T12:14:03.096314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the schema as a dictionary\n",
    "schema = {\n",
    "    'SK_AccountID': 'uint32',\n",
    "    'AccountID': 'uint32',\n",
    "    'SK_BrokerID': 'uint32',\n",
    "    'SK_CustomerID': 'uint32',\n",
    "    'Status': 'str',\n",
    "    'AccountDesc': 'str',\n",
    "    'TaxStatus': 'UInt8',\n",
    "    'IsCurrent': 'bool',\n",
    "    'BatchID': 'uint8',\n",
    "    'EffectiveDate': 'datetime64[ns]',\n",
    "    'EndDate': 'datetime64[ns]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:14:03.126314Z",
     "iopub.status.busy": "2023-12-22T12:14:03.125312Z",
     "iopub.status.idle": "2023-12-22T12:14:03.480312Z",
     "shell.execute_reply": "2023-12-22T12:14:03.478567Z",
     "shell.execute_reply.started": "2023-12-22T12:14:03.126314Z"
    }
   },
   "outputs": [],
   "source": [
    "data_file = DATA_DIR + \"CustomerMgmt.xml\"\n",
    "tree = etree.parse(data_file)\n",
    "namespace = {'tpcdi': 'http://www.tpc.org/tpc-di'}\n",
    "\n",
    "# Get all actions\n",
    "all_actions = tree.xpath(\".//tpcdi:Action\", namespaces=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:14:03.482315Z",
     "iopub.status.busy": "2023-12-22T12:14:03.481314Z",
     "iopub.status.idle": "2023-12-22T12:14:07.054532Z",
     "shell.execute_reply": "2023-12-22T12:14:07.053530Z",
     "shell.execute_reply.started": "2023-12-22T12:14:03.482315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d416a62d7584ae98a5f2d4761f14d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty DataFrame with the specified schema\n",
    "dimAccount_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in schema.items()})\n",
    "\n",
    "# initialize lists to store data\n",
    "relevant_cols = ['AccountID', 'SK_BrokerID', 'SK_CustomerID', 'Status', 'AccountDesc', 'TaxStatus', 'EffectiveDate']\n",
    "data = {col: [] for col in relevant_cols}\n",
    "\n",
    "# initialize dict to store most recent values for each account of a customer\n",
    "customer_accounts = dict()\n",
    "\n",
    "for index, action in enumerate(tqdm(all_actions)):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    if customer_id not in customer_accounts:\n",
    "        customer_accounts[customer_id] = dict()\n",
    "    if action.get(\"ActionType\") in (\"NEW\", \"ADDACCT\"):\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # Customer/Account/CA_NAME\n",
    "            account_desc = account.findtext(\"CA_NAME\", default=None, namespaces=namespace)\n",
    "            data[\"AccountDesc\"].append(account_desc)\n",
    "            # Customer/Account/@CA_TAX_ST\n",
    "            tax_status = account.get(\"CA_TAX_ST\", None)\n",
    "            tax_status = int(tax_status) if tax_status else None\n",
    "            data[\"TaxStatus\"].append(tax_status)\n",
    "            #  Customer/Account/CA_B_ID\n",
    "            broker_id = account.findtext(\"CA_B_ID\", default=None, namespaces=namespace)\n",
    "            broker_id = int(broker_id) if broker_id else None\n",
    "            data[\"SK_BrokerID\"].append((broker_id, action_ts))\n",
    "            data[\"SK_CustomerID\"].append((customer_id, action_ts))\n",
    "            status = \"ACTIVE\"\n",
    "            data[\"Status\"].append(status)\n",
    "            # update customer_accounts\n",
    "            customer_accounts[customer_id][account_id] = {\n",
    "                \"AccountDesc\": account_desc,\n",
    "                \"TaxStatus\": tax_status,\n",
    "                \"SK_BrokerID\": (broker_id, action_ts),\n",
    "                \"SK_CustomerID\": (customer_id, action_ts),\n",
    "                \"Status\": status,\n",
    "            }\n",
    "    elif action.get(\"ActionType\") == \"UPDACCT\":\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # Customer/Account/CA_NAME\n",
    "            account_desc = account.findtext(\"CA_NAME\", default=None, namespaces=namespace)\n",
    "            if account_desc is None:\n",
    "                account_desc = customer_accounts[customer_id][account_id][\"AccountDesc\"]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"AccountDesc\"] = account_desc\n",
    "            data[\"AccountDesc\"].append(account_desc)\n",
    "            # Customer/Account/@CA_TAX_ST\n",
    "            tax_status = account.get(\"CA_TAX_ST\", None)\n",
    "            tax_status = int(tax_status) if tax_status else None\n",
    "            if tax_status is None:\n",
    "                tax_status = customer_accounts[customer_id][account_id][\"TaxStatus\"]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"TaxStatus\"] = tax_status\n",
    "            data[\"TaxStatus\"].append(tax_status)\n",
    "            #  Customer/Account/CA_B_ID\n",
    "            broker_id = account.findtext(\"CA_B_ID\", default=None, namespaces=namespace)\n",
    "            broker_id = int(broker_id) if broker_id else None\n",
    "            if broker_id is None:\n",
    "                broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)\n",
    "            status = \"ACTIVE\"\n",
    "            data[\"Status\"].append(status)\n",
    "    elif action.get(\"ActionType\") == \"UPDCUST\":\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # set all other fields as is\n",
    "            for col in customer_accounts[customer_id][account_id]:\n",
    "                if not col.startswith(\"SK_\"):\n",
    "                    data[col].append(customer_accounts[customer_id][account_id][col])\n",
    "            broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)\n",
    "    elif action.get(\"ActionType\") in (\"INACT\", \"CLOSEACCT\"):\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # set all other fields as is\n",
    "            for col in customer_accounts[customer_id][account_id]:\n",
    "                if col.startswith(\"SK_\"):\n",
    "                    continue\n",
    "                elif col != \"Status\":\n",
    "                    data[col].append(customer_accounts[customer_id][account_id][col])\n",
    "                else:\n",
    "                    data[col].append(\"INACTIVE\")\n",
    "                    customer_accounts[customer_id][account_id][col] = \"INACTIVE\"\n",
    "            broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:14:07.057547Z",
     "iopub.status.busy": "2023-12-22T12:14:07.056532Z",
     "iopub.status.idle": "2023-12-22T12:15:29.863958Z",
     "shell.execute_reply": "2023-12-22T12:15:29.862988Z",
     "shell.execute_reply.started": "2023-12-22T12:14:07.057547Z"
    }
   },
   "outputs": [],
   "source": [
    "# query the database to get all SK_BrokerID\n",
    "query_parts = [\n",
    "    f\"(BrokerID = {broker_id} AND EffectiveDate <= '{action_ts}' <= EndDate)\"\n",
    "    for broker_id, action_ts in data[\"SK_BrokerID\"]\n",
    "]\n",
    "# Joining all conditions with 'OR'\n",
    "conditions = \" OR \".join(query_parts)\n",
    "query = f\"\"\"SELECT BrokerID, EffectiveDate, EndDate, SK_BrokerID \n",
    "FROM dimbroker \n",
    "WHERE {conditions}\"\"\"\n",
    "result = pd.read_sql_query(query, engine)\n",
    "for index, pair in enumerate(data[\"SK_BrokerID\"]):\n",
    "    broker_id, action_ts = pair    \n",
    "    sk_brokerid = result[\n",
    "        (result[\"BrokerID\"] == broker_id)\n",
    "        & (result[\"EffectiveDate\"] <= action_ts.date())\n",
    "        & (action_ts.date() <= result[\"EndDate\"])\n",
    "    ].iloc[0, 3]\n",
    "    data[\"SK_BrokerID\"][index] = sk_brokerid\n",
    "\n",
    "# query the database to get all SK_CustomerID\n",
    "query_parts = [\n",
    "    f\"(CustomerID = {customer_id} AND EffectiveDate <= '{action_ts}' <= EndDate)\"\n",
    "    for customer_id, action_ts in data[\"SK_CustomerID\"]\n",
    "]\n",
    "# Joining all conditions with 'OR'\n",
    "conditions = \" OR \".join(query_parts)\n",
    "query = f\"\"\"SELECT CustomerID, EffectiveDate, EndDate, SK_CustomerID \n",
    "FROM dimcustomer \n",
    "WHERE {conditions}\"\"\"\n",
    "result = pd.read_sql_query(query, engine)\n",
    "for index, pair in enumerate(data[\"SK_CustomerID\"]):\n",
    "    customer_id, action_ts = pair\n",
    "    sk_brokerid = result[\n",
    "        (result[\"CustomerID\"] == customer_id)\n",
    "        & (result[\"EffectiveDate\"] <= action_ts.date())\n",
    "        & (action_ts.date() <= result[\"EndDate\"])\n",
    "    ].iloc[0, 3]\n",
    "    data[\"SK_CustomerID\"][index] = sk_brokerid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:29.866970Z",
     "iopub.status.busy": "2023-12-22T12:15:29.865957Z",
     "iopub.status.idle": "2023-12-22T12:15:30.162966Z",
     "shell.execute_reply": "2023-12-22T12:15:30.161261Z",
     "shell.execute_reply.started": "2023-12-22T12:15:29.866970Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    dimAccount_df[col] = data[col]\n",
    "dimAccount_df['SK_AccountID'] = range(1, len(dimAccount_df) + 1)\n",
    "dimAccount_df['BatchID'] = 1\n",
    "\n",
    "# Sort the DataFrame by CustomerID and EffectiveDate\n",
    "dimAccount_df.sort_values(by=['AccountID', 'EffectiveDate'], inplace=True)\n",
    "# Create a shifted DataFrame\n",
    "shifted_df = dimAccount_df.shift(-1)\n",
    "# Update EndDate: If next row has same CustomerID, use its EffectiveDate; otherwise, use default date\n",
    "dimAccount_df['EndDate'] = pd.Timestamp('9999-12-31')\n",
    "mask = dimAccount_df['AccountID'] == shifted_df['AccountID']\n",
    "dimAccount_df.loc[mask, 'EndDate'] = shifted_df.loc[mask, 'EffectiveDate']\n",
    "\n",
    "# Update IsCurrent: True if next row has different CustomerID or is the last row\n",
    "dimAccount_df['IsCurrent'] = ~mask\n",
    "dimAccount_df.sort_values(by=['SK_AccountID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:30.165967Z",
     "iopub.status.busy": "2023-12-22T12:15:30.164968Z",
     "iopub.status.idle": "2023-12-22T12:15:30.177969Z",
     "shell.execute_reply": "2023-12-22T12:15:30.176969Z",
     "shell.execute_reply.started": "2023-12-22T12:15:30.165967Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'AccountID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'AccountDesc': sqlalchemy.types.String(50),\n",
    "    'TaxStatus': sqlalchemy.types.SmallInteger,\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:30.181968Z",
     "iopub.status.busy": "2023-12-22T12:15:30.180966Z",
     "iopub.status.idle": "2023-12-22T12:15:30.223966Z",
     "shell.execute_reply": "2023-12-22T12:15:30.223217Z",
     "shell.execute_reply.started": "2023-12-22T12:15:30.181968Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimAccount (\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    AccountID INT UNSIGNED NOT NULL,\n",
    "    SK_BrokerID INT UNSIGNED NOT NULL,\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    AccountDesc CHAR(50),\n",
    "    TaxStatus TINYINT UNSIGNED,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_AccountID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:30.225992Z",
     "iopub.status.busy": "2023-12-22T12:15:30.224967Z",
     "iopub.status.idle": "2023-12-22T12:15:30.254972Z",
     "shell.execute_reply": "2023-12-22T12:15:30.254215Z",
     "shell.execute_reply.started": "2023-12-22T12:15:30.225992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21560 entries, 0 to 21559\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   SK_AccountID   21560 non-null  int64         \n",
      " 1   AccountID      21560 non-null  int64         \n",
      " 2   SK_BrokerID    21560 non-null  int64         \n",
      " 3   SK_CustomerID  21560 non-null  int64         \n",
      " 4   Status         21560 non-null  object        \n",
      " 5   AccountDesc    21560 non-null  object        \n",
      " 6   TaxStatus      21560 non-null  int64         \n",
      " 7   IsCurrent      21560 non-null  bool          \n",
      " 8   BatchID        21560 non-null  int64         \n",
      " 9   EffectiveDate  21560 non-null  datetime64[ns]\n",
      " 10  EndDate        21560 non-null  datetime64[s] \n",
      "dtypes: bool(1), datetime64[ns](1), datetime64[s](1), int64(6), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dimAccount_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:30.257998Z",
     "iopub.status.busy": "2023-12-22T12:15:30.256969Z",
     "iopub.status.idle": "2023-12-22T12:15:31.568835Z",
     "shell.execute_reply": "2023-12-22T12:15:31.567875Z",
     "shell.execute_reply.started": "2023-12-22T12:15:30.257998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21560"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimAccount_df.to_sql('dimaccount', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:31.571839Z",
     "iopub.status.busy": "2023-12-22T12:15:31.570838Z",
     "iopub.status.idle": "2023-12-22T12:15:33.259998Z",
     "shell.execute_reply": "2023-12-22T12:15:33.258001Z",
     "shell.execute_reply.started": "2023-12-22T12:15:31.571839Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'T_ID', 'T_DTS', 'T_ST_ID', 'T_TT_ID', 'T_IS_CASH', \n",
    "    'T_S_SYMB', 'T_QTY', 'T_BID_PRICE', 'T_CA_ID', 'T_EXEC_NAME', \n",
    "    'T_TRADE_PRICE', 'T_CHRG', 'T_COMM', 'T_TAX'\n",
    "]\n",
    "dtypes = {\n",
    "    'T_ID': 'uint64',\n",
    "    'T_DTS': 'str',\n",
    "    'T_ST_ID': 'str',\n",
    "    'T_TT_ID': 'str',\n",
    "    'T_IS_CASH': 'bool',\n",
    "    'T_S_SYMB': 'str',\n",
    "    'T_QTY': 'uint32',\n",
    "    'T_BID_PRICE': 'float64',\n",
    "    'T_CA_ID': 'uint32',\n",
    "    'T_EXEC_NAME': 'str',\n",
    "    'T_TRADE_PRICE': 'float64',\n",
    "    'T_CHRG': 'float64',\n",
    "    'T_COMM': 'float64',\n",
    "    'T_TAX': 'float64'\n",
    "}\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "trade_df = pd.read_csv(\n",
    "    DATA_DIR + \"Trade.txt\", \n",
    "    sep='|', \n",
    "    header=None, \n",
    "    names=columns, \n",
    "    dtype=dtypes,\n",
    "    parse_dates=['T_DTS']\n",
    ")\n",
    "trade_df['T_DTS'] = pd.to_datetime(trade_df['T_DTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:33.263000Z",
     "iopub.status.busy": "2023-12-22T12:15:33.262001Z",
     "iopub.status.idle": "2023-12-22T12:15:35.869830Z",
     "shell.execute_reply": "2023-12-22T12:15:35.868831Z",
     "shell.execute_reply.started": "2023-12-22T12:15:33.262001Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"TH_T_ID\", \"TH_DTS\", \"TH_ST_ID\"]\n",
    "dtypes = {\n",
    "    \"TH_T_ID\": \"uint64\",\n",
    "    \"TH_DTS\": \"str\",\n",
    "    \"TH_ST_ID\": \"str\"\n",
    "}\n",
    "tradehistory_df = pd.read_csv(DATA_DIR + \"TradeHistory.txt\", sep=\"|\", header=None, \n",
    "                              names=columns, dtype=dtypes, parse_dates=['TH_DTS'])\n",
    "tradehistory_df['TH_DTS'] = pd.to_datetime(tradehistory_df['TH_DTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:35.871831Z",
     "iopub.status.busy": "2023-12-22T12:15:35.870830Z",
     "iopub.status.idle": "2023-12-22T12:15:36.319295Z",
     "shell.execute_reply": "2023-12-22T12:15:36.318317Z",
     "shell.execute_reply.started": "2023-12-22T12:15:35.871831Z"
    }
   },
   "outputs": [],
   "source": [
    "trade_merged = tradehistory_df.merge(trade_df, left_on='TH_T_ID', right_on='T_ID')\n",
    "del tradehistory_df\n",
    "del trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:36.321289Z",
     "iopub.status.busy": "2023-12-22T12:15:36.320287Z",
     "iopub.status.idle": "2023-12-22T12:15:37.475964Z",
     "shell.execute_reply": "2023-12-22T12:15:37.474271Z",
     "shell.execute_reply.started": "2023-12-22T12:15:36.321289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-fetch data from related tables\n",
    "date_mapping = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine).set_index(\"DateValue\")[\"SK_DateID\"].to_dict()\n",
    "time_mapping = pd.read_sql(\"SELECT TimeValue, SK_TimeID FROM dimtime\", engine).set_index(\"TimeValue\")[\"SK_TimeID\"].to_dict()\n",
    "status_mapping = pd.read_sql(\"SELECT ST_ID, ST_NAME FROM statustype\", engine).set_index(\"ST_ID\")[\"ST_NAME\"].to_dict()\n",
    "trade_type_mapping = pd.read_sql(\"SELECT TT_ID, TT_NAME FROM tradetype\", engine).set_index(\"TT_ID\")[\"TT_NAME\"].to_dict()\n",
    "\n",
    "# Fetching security and account info in one go\n",
    "security_info = pd.read_sql(\"SELECT Symbol, SK_SecurityID, SK_CompanyID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "account_info = pd.read_sql(\"SELECT AccountID, SK_AccountID, SK_CustomerID, SK_BrokerID, EffectiveDate, EndDate FROM dimaccount\", engine)\n",
    "account_info['EffectiveDate'] = pd.to_datetime(account_info['EffectiveDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:37.477962Z",
     "iopub.status.busy": "2023-12-22T12:15:37.476963Z",
     "iopub.status.idle": "2023-12-22T12:15:37.740709Z",
     "shell.execute_reply": "2023-12-22T12:15:37.739712Z",
     "shell.execute_reply.started": "2023-12-22T12:15:37.477962Z"
    }
   },
   "outputs": [],
   "source": [
    "# direct copy\n",
    "trade_merged[\"TradeID\"] = trade_merged[\"T_ID\"]\n",
    "trade_merged[\"CashFlag\"] = trade_merged[\"T_IS_CASH\"]\n",
    "trade_merged[\"Quantity\"] = trade_merged[\"T_QTY\"]\n",
    "trade_merged[\"BidPrice\"] = trade_merged[\"T_BID_PRICE\"]\n",
    "trade_merged[\"ExecutedBy\"] = trade_merged[\"T_EXEC_NAME\"]\n",
    "trade_merged[\"TradePrice\"] = trade_merged[\"T_TRADE_PRICE\"]\n",
    "trade_merged[\"Fee\"] = trade_merged[\"T_CHRG\"]\n",
    "trade_merged[\"Commission\"] = trade_merged[\"T_COMM\"]\n",
    "trade_merged[\"Tax\"] = trade_merged[\"T_TAX\"]\n",
    "trade_merged[\"Status\"] = trade_merged[\"T_ST_ID\"].map(status_mapping)\n",
    "trade_merged[\"Type\"] = trade_merged[\"T_TT_ID\"].map(trade_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:37.742711Z",
     "iopub.status.busy": "2023-12-22T12:15:37.741718Z",
     "iopub.status.idle": "2023-12-22T12:15:43.534040Z",
     "shell.execute_reply": "2023-12-22T12:15:43.532447Z",
     "shell.execute_reply.started": "2023-12-22T12:15:37.742711Z"
    }
   },
   "outputs": [],
   "source": [
    "# initially set null\n",
    "trade_merged[\"SK_CreateDateID\"] = None\n",
    "trade_merged[\"SK_CreateTimeID\"] = None\n",
    "trade_merged[\"SK_CloseDateID\"] = None\n",
    "trade_merged[\"SK_CloseTimeID\"] = None\n",
    "\n",
    "# now populate\n",
    "create_mask = (trade_merged[\"TH_ST_ID\"] == \"PNDG\") | (trade_merged[\"TH_ST_ID\"] == \"SBMT\")\n",
    "trade_merged.loc[create_mask, \"SK_CreateDateID\"] = trade_merged.loc[create_mask, \"TH_DTS\"].dt.date.map(date_mapping)\n",
    "trade_merged.loc[create_mask, \"SK_CreateTimeID\"] = pd.to_timedelta(trade_merged.loc[create_mask, \"TH_DTS\"].dt.time.astype(str)).map(time_mapping)\n",
    "close_mask = (trade_merged[\"TH_ST_ID\"] == \"CMPT\") | (trade_merged[\"TH_ST_ID\"] == \"CNCL\")\n",
    "trade_merged.loc[close_mask, \"SK_CloseDateID\"] = trade_merged.loc[close_mask, \"TH_DTS\"].dt.date.map(date_mapping)\n",
    "trade_merged.loc[close_mask, \"SK_CloseTimeID\"] = pd.to_timedelta(trade_merged.loc[close_mask, \"TH_DTS\"].dt.time.astype(str)).map(time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:43.536048Z",
     "iopub.status.busy": "2023-12-22T12:15:43.535041Z",
     "iopub.status.idle": "2023-12-22T12:15:43.550039Z",
     "shell.execute_reply": "2023-12-22T12:15:43.548040Z",
     "shell.execute_reply.started": "2023-12-22T12:15:43.536048Z"
    }
   },
   "outputs": [],
   "source": [
    "trade_merged.rename({\"T_S_SYMB\": \"Symbol\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:43.552045Z",
     "iopub.status.busy": "2023-12-22T12:15:43.551040Z",
     "iopub.status.idle": "2023-12-22T12:15:45.143315Z",
     "shell.execute_reply": "2023-12-22T12:15:45.142342Z",
     "shell.execute_reply.started": "2023-12-22T12:15:43.552045Z"
    }
   },
   "outputs": [],
   "source": [
    "trade_merged = pd.merge(\n",
    "    trade_merged,\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    on=\"Symbol\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:45.145344Z",
     "iopub.status.busy": "2023-12-22T12:15:45.145344Z",
     "iopub.status.idle": "2023-12-22T12:15:46.158654Z",
     "shell.execute_reply": "2023-12-22T12:15:46.157907Z",
     "shell.execute_reply.started": "2023-12-22T12:15:45.145344Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the rows where TH_DTS < EffectiveDate  or TH_DTS > EndDate\n",
    "trade_merged = trade_merged[\n",
    "    (trade_merged[\"TH_DTS\"] >= trade_merged[\"EffectiveDate\"])\n",
    "    & (trade_merged[\"TH_DTS\"].dt.date < trade_merged[\"EndDate\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:46.161640Z",
     "iopub.status.busy": "2023-12-22T12:15:46.160655Z",
     "iopub.status.idle": "2023-12-22T12:15:49.733768Z",
     "shell.execute_reply": "2023-12-22T12:15:49.732771Z",
     "shell.execute_reply.started": "2023-12-22T12:15:46.161640Z"
    }
   },
   "outputs": [],
   "source": [
    "trade_merged = pd.merge(\n",
    "    trade_merged,\n",
    "    account_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"T_CA_ID\",\n",
    "    right_on=\"AccountID\",\n",
    ")\n",
    "trade_merged = trade_merged[\n",
    "    (trade_merged[\"TH_DTS\"] >= trade_merged[\"EffectiveDate_y\"])\n",
    "    & (trade_merged[\"TH_DTS\"].dt.date < trade_merged[\"EndDate_y\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:49.736767Z",
     "iopub.status.busy": "2023-12-22T12:15:49.735784Z",
     "iopub.status.idle": "2023-12-22T12:15:49.953842Z",
     "shell.execute_reply": "2023-12-22T12:15:49.952417Z",
     "shell.execute_reply.started": "2023-12-22T12:15:49.736767Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    \"TradeID\",\n",
    "    \"SK_BrokerID\",\n",
    "    \"SK_CreateDateID\",\n",
    "    \"SK_CreateTimeID\",\n",
    "    \"SK_CloseDateID\",\n",
    "    \"SK_CloseTimeID\",\n",
    "    \"Status\",\n",
    "    \"Type\",\n",
    "    \"CashFlag\",\n",
    "    \"SK_SecurityID\",\n",
    "    \"SK_CompanyID\",\n",
    "    \"Quantity\",\n",
    "    \"BidPrice\",\n",
    "    \"SK_CustomerID\",\n",
    "    \"SK_AccountID\",\n",
    "    \"ExecutedBy\",\n",
    "    \"TradePrice\",\n",
    "    \"Fee\",\n",
    "    \"Commission\",\n",
    "    \"Tax\",\n",
    "]\n",
    "trade_merged = trade_merged[use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:49.955837Z",
     "iopub.status.busy": "2023-12-22T12:15:49.955837Z",
     "iopub.status.idle": "2023-12-22T12:15:50.749838Z",
     "shell.execute_reply": "2023-12-22T12:15:50.749090Z",
     "shell.execute_reply.started": "2023-12-22T12:15:49.955837Z"
    }
   },
   "outputs": [],
   "source": [
    "trade_merged = trade_merged.groupby(\"TradeID\").last().reset_index()\n",
    "trade_merged['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:50.752842Z",
     "iopub.status.busy": "2023-12-22T12:15:50.751854Z",
     "iopub.status.idle": "2023-12-22T12:15:50.937376Z",
     "shell.execute_reply": "2023-12-22T12:15:50.936375Z",
     "shell.execute_reply.started": "2023-12-22T12:15:50.752842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 650412 entries, 0 to 650411\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   TradeID          650412 non-null  uint64 \n",
      " 1   SK_BrokerID      650412 non-null  int64  \n",
      " 2   SK_CreateDateID  650412 non-null  object \n",
      " 3   SK_CreateTimeID  650412 non-null  object \n",
      " 4   SK_CloseDateID   640835 non-null  object \n",
      " 5   SK_CloseTimeID   640835 non-null  object \n",
      " 6   Status           650412 non-null  object \n",
      " 7   Type             650412 non-null  object \n",
      " 8   CashFlag         650412 non-null  bool   \n",
      " 9   SK_SecurityID    650412 non-null  int64  \n",
      " 10  SK_CompanyID     650412 non-null  int64  \n",
      " 11  Quantity         650412 non-null  uint32 \n",
      " 12  BidPrice         650412 non-null  float64\n",
      " 13  SK_CustomerID    650412 non-null  int64  \n",
      " 14  SK_AccountID     650412 non-null  int64  \n",
      " 15  ExecutedBy       650412 non-null  object \n",
      " 16  TradePrice       602956 non-null  float64\n",
      " 17  Fee              602956 non-null  float64\n",
      " 18  Commission       602956 non-null  float64\n",
      " 19  Tax              602956 non-null  float64\n",
      " 20  BatchID          650412 non-null  int64  \n",
      "dtypes: bool(1), float64(5), int64(6), object(7), uint32(1), uint64(1)\n",
      "memory usage: 97.4+ MB\n"
     ]
    }
   ],
   "source": [
    "trade_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:50.939389Z",
     "iopub.status.busy": "2023-12-22T12:15:50.939389Z",
     "iopub.status.idle": "2023-12-22T12:15:51.233072Z",
     "shell.execute_reply": "2023-12-22T12:15:51.232336Z",
     "shell.execute_reply.started": "2023-12-22T12:15:50.939389Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'TradeID': 'uint32',\n",
    "    'SK_BrokerID': 'UInt32',\n",
    "    'SK_CreateDateID': 'uint32',\n",
    "    'SK_CreateTimeID': 'uint32',\n",
    "    'SK_CloseDateID': 'UInt32',\n",
    "    'SK_CloseTimeID': 'UInt32',\n",
    "    'Status': 'str',\n",
    "    'Type': 'str',\n",
    "    'CashFlag': 'bool',\n",
    "    'SK_SecurityID': 'uint32',\n",
    "    'SK_CompanyID': 'uint32',\n",
    "    'Quantity': 'uint32',\n",
    "    'BidPrice': 'float64',\n",
    "    'SK_CustomerID': 'uint32',\n",
    "    'SK_AccountID': 'uint32',\n",
    "    'ExecutedBy': 'str',\n",
    "    'TradePrice': 'float64',\n",
    "    'Fee': 'float64',\n",
    "    'Commission': 'float64',\n",
    "    'Tax': 'float64',\n",
    "    'BatchID': 'uint8'\n",
    "}\n",
    "trade_merged = trade_merged.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:51.235071Z",
     "iopub.status.busy": "2023-12-22T12:15:51.235071Z",
     "iopub.status.idle": "2023-12-22T12:15:51.250075Z",
     "shell.execute_reply": "2023-12-22T12:15:51.248072Z",
     "shell.execute_reply.started": "2023-12-22T12:15:51.235071Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'TradeID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateTimeID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseTimeID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.CHAR(10),\n",
    "    'Type': sqlalchemy.types.CHAR(12),\n",
    "    'CashFlag': sqlalchemy.types.Boolean,\n",
    "    'SK_SecurityID': sqlalchemy.types.Integer,\n",
    "    'SK_CompanyID': sqlalchemy.types.Integer,\n",
    "    'Quantity': sqlalchemy.types.Integer,\n",
    "    'BidPrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'ExecutedBy': sqlalchemy.types.CHAR(64),\n",
    "    'TradePrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'Fee': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Commission': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Tax': sqlalchemy.types.Numeric(10, 2),\n",
    "    'BatchID': sqlalchemy.types.SmallInteger\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:51.253075Z",
     "iopub.status.busy": "2023-12-22T12:15:51.253075Z",
     "iopub.status.idle": "2023-12-22T12:15:51.294500Z",
     "shell.execute_reply": "2023-12-22T12:15:51.293749Z",
     "shell.execute_reply.started": "2023-12-22T12:15:51.253075Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimTrade (\n",
    "    TradeID INT UNSIGNED NOT NULL,\n",
    "    SK_BrokerID INT UNSIGNED,\n",
    "    SK_CreateDateID INT UNSIGNED NOT NULL,\n",
    "    SK_CreateTimeID INT UNSIGNED NOT NULL,\n",
    "    SK_CloseDateID INT UNSIGNED,\n",
    "    SK_CloseTimeID INT UNSIGNED,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Type CHAR(12) NOT NULL,\n",
    "    CashFlag BOOLEAN NOT NULL,\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    Quantity MEDIUMINT UNSIGNED NOT NULL,\n",
    "    BidPrice DECIMAL(8, 2) NOT NULL,\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    ExecutedBy CHAR(64) NOT NULL,\n",
    "    TradePrice DECIMAL(8, 2),\n",
    "    Fee DECIMAL(10, 2),\n",
    "    Commission DECIMAL(10, 2),\n",
    "    Tax DECIMAL(10, 2),\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    PRIMARY KEY (TradeID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:15:51.296520Z",
     "iopub.status.busy": "2023-12-22T12:15:51.296520Z",
     "iopub.status.idle": "2023-12-22T12:16:38.683148Z",
     "shell.execute_reply": "2023-12-22T12:16:38.682171Z",
     "shell.execute_reply.started": "2023-12-22T12:15:51.296520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7105ac0b93a4180aa076efbcab72411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try:\n",
    "    for i in trange(0, trade_merged.shape[0], 100000):\n",
    "        trade_merged.iloc[i:i+100000].to_sql('dimtrade', engine, if_exists='append', index=False, dtype=sql_dtypes)\n",
    "    session.commit()\n",
    "except:\n",
    "    session.rollback()\n",
    "    raise\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:38.685140Z",
     "iopub.status.busy": "2023-12-22T12:16:38.684133Z",
     "iopub.status.idle": "2023-12-22T12:16:38.714132Z",
     "shell.execute_reply": "2023-12-22T12:16:38.713190Z",
     "shell.execute_reply.started": "2023-12-22T12:16:38.685140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 21)\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame\n",
    "invalid_trades = trade_merged[\n",
    "    (trade_merged[\"Commission\"].notnull())\n",
    "    & (trade_merged[\"Commission\"] > (trade_merged[\"TradePrice\"] * trade_merged[\"Quantity\"]))\n",
    "]\n",
    "print(invalid_trades.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:38.716132Z",
     "iopub.status.busy": "2023-12-22T12:16:38.716132Z",
     "iopub.status.idle": "2023-12-22T12:16:38.731135Z",
     "shell.execute_reply": "2023-12-22T12:16:38.729132Z",
     "shell.execute_reply.started": "2023-12-22T12:16:38.716132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# Create lists without using iterrows\n",
    "MessageSource = [\"DimTrade\"] * len(invalid_trades)\n",
    "MessageType = [\"Alert\"] * len(invalid_trades)\n",
    "MessageText = [\"Invalid trade commission\"] * len(invalid_trades)\n",
    "MessageData = [\n",
    "    \"T_ID = \"\n",
    "    + invalid_trades[\"TradeID\"].astype(str)\n",
    "    + \", T_COMM = \"\n",
    "    + invalid_trades[\"Commission\"].astype(str)\n",
    "]\n",
    "# Convert MessageData from a list of Series to a list of strings\n",
    "MessageData = MessageData[0].tolist()\n",
    "\n",
    "print(len(MessageSource))\n",
    "print(len(MessageData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:38.733660Z",
     "iopub.status.busy": "2023-12-22T12:16:38.733132Z",
     "iopub.status.idle": "2023-12-22T12:16:38.761668Z",
     "shell.execute_reply": "2023-12-22T12:16:38.760655Z",
     "shell.execute_reply.started": "2023-12-22T12:16:38.733660Z"
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "VALUES \"\"\"\n",
    "for i in range(len(MessageSource)):\n",
    "    query += f\"\"\"('{pd.Timestamp(\"now\")}', 1, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query[:-1]))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:38.764653Z",
     "iopub.status.busy": "2023-12-22T12:16:38.763652Z",
     "iopub.status.idle": "2023-12-22T12:16:38.791652Z",
     "shell.execute_reply": "2023-12-22T12:16:38.790654Z",
     "shell.execute_reply.started": "2023-12-22T12:16:38.764653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for invalid trade fees\n",
    "invalid_fee_trades = trade_merged[\n",
    "    (trade_merged[\"Fee\"].notnull())\n",
    "    & (trade_merged[\"Fee\"] > (trade_merged[\"TradePrice\"] * trade_merged[\"Quantity\"]))\n",
    "]\n",
    "\n",
    "# Create the required lists\n",
    "MessageSource = [\"DimTrade\"] * len(invalid_fee_trades)\n",
    "MessageType = [\"Alert\"] * len(invalid_fee_trades)\n",
    "MessageText = [\"Invalid trade fee\"] * len(invalid_fee_trades)\n",
    "\n",
    "# Vectorized operation for MessageData\n",
    "MessageData = (\n",
    "    \"T_ID = \"\n",
    "    + invalid_fee_trades[\"TradeID\"].astype(str)\n",
    "    + \", T_CHRG = \"\n",
    "    + invalid_fee_trades[\"Fee\"].astype(str)\n",
    ")\n",
    "MessageData = MessageData.tolist()\n",
    "\n",
    "query = \"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData) VALUES \"\"\"\n",
    "for i in range(len(MessageSource)):\n",
    "    query += f\"\"\"('{pd.Timestamp(\"now\")}', 1, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query[:-1]))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactCashBalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcb_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:38.793652Z",
     "iopub.status.busy": "2023-12-22T12:16:38.793652Z",
     "iopub.status.idle": "2023-12-22T12:16:42.302599Z",
     "shell.execute_reply": "2023-12-22T12:16:42.301586Z",
     "shell.execute_reply.started": "2023-12-22T12:16:38.793652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 602115 entries, 0 to 602114\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   CT_CA_ID  602115 non-null  uint32        \n",
      " 1   CT_DTS    602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT    602115 non-null  float64       \n",
      " 3   CT_NAME   602115 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1), uint32(1)\n",
      "memory usage: 16.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0         2 2012-07-11 08:10:15 -37215.14   \n",
       "1        34 2012-07-07 17:11:38  -3178.67   \n",
       "2        36 2012-07-12 17:37:44  -3172.19   \n",
       "3        40 2012-09-20 03:12:34 -16621.00   \n",
       "4        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                             CT_NAME  \n",
       "0  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...  \n",
       "1  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...  \n",
       "2  uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...  \n",
       "3  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...  \n",
       "4  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = pd.read_csv(\n",
    "    DATA_DIR + \"CashTransaction.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"CT_CA_ID\",\n",
    "        \"CT_DTS\",\n",
    "        \"CT_AMT\",\n",
    "        \"CT_NAME\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"CT_CA_ID\": \"uint32\",\n",
    "        \"CT_DTS\": \"str\",\n",
    "        \"CT_AMT\": \"float64\",\n",
    "        \"CT_NAME\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"CT_DTS\"],\n",
    ")\n",
    "cash_txn_df[\"CT_DTS\"] = pd.to_datetime(cash_txn_df[\"CT_DTS\"])\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK_CustomerID and SK_AccountID are obtained from DimAccount by matching CT_CA_ID\n",
    "with AccountID, where CT_DTS is in the range given by EffectiveDate and EndDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:42.304591Z",
     "iopub.status.busy": "2023-12-22T12:16:42.304591Z",
     "iopub.status.idle": "2023-12-22T12:16:42.474588Z",
     "shell.execute_reply": "2023-12-22T12:16:42.473621Z",
     "shell.execute_reply.started": "2023-12-22T12:16:42.304591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountID  SK_AccountID  SK_CustomerID EffectiveDate     EndDate\n",
       "0          0             1              1    2007-07-07  2007-10-15\n",
       "1          1             2              2    2007-07-07  2007-07-21\n",
       "2          2             3              3    2007-07-07  2007-07-23\n",
       "3          3             4              4    2007-07-07  2007-09-16\n",
       "4          4             5              5    2007-07-07  2007-07-27"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_info = pd.read_sql(\n",
    "    \"SELECT AccountID, SK_AccountID, SK_CustomerID, EffectiveDate, EndDate FROM dimaccount\",\n",
    "    engine,\n",
    ")\n",
    "account_info[\"EffectiveDate\"] = pd.to_datetime(account_info[\"EffectiveDate\"])\n",
    "account_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:42.476587Z",
     "iopub.status.busy": "2023-12-22T12:16:42.476587Z",
     "iopub.status.idle": "2023-12-22T12:16:42.850594Z",
     "shell.execute_reply": "2023-12-22T12:16:42.848620Z",
     "shell.execute_reply.started": "2023-12-22T12:16:42.476587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197606 entries, 0 to 1197605\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   CT_CA_ID       1197606 non-null  uint32        \n",
      " 1   CT_DTS         1197606 non-null  datetime64[ns]\n",
      " 2   CT_AMT         1197606 non-null  float64       \n",
      " 3   CT_NAME        1197606 non-null  object        \n",
      " 4   AccountID      1197606 non-null  int64         \n",
      " 5   SK_AccountID   1197606 non-null  int64         \n",
      " 6   SK_CustomerID  1197606 non-null  int64         \n",
      " 7   EffectiveDate  1197606 non-null  datetime64[ns]\n",
      " 8   EndDate        1197606 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(3), object(2), uint32(1)\n",
      "memory usage: 77.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-23</td>\n",
       "      <td>2007-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-07-11</td>\n",
       "      <td>2007-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0         2 2012-07-11 08:10:15 -37215.14   \n",
       "1         2 2012-07-11 08:10:15 -37215.14   \n",
       "2         2 2012-07-11 08:10:15 -37215.14   \n",
       "3        34 2012-07-07 17:11:38  -3178.67   \n",
       "4        34 2012-07-07 17:11:38  -3178.67   \n",
       "\n",
       "                                             CT_NAME  AccountID  SK_AccountID  \\\n",
       "0  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2             3   \n",
       "1  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2           109   \n",
       "2  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2           133   \n",
       "3  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34            35   \n",
       "4  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34           220   \n",
       "\n",
       "   SK_CustomerID EffectiveDate     EndDate  \n",
       "0              3    2007-07-07  2007-07-23  \n",
       "1           9952    2007-07-23  2007-07-28  \n",
       "2           9952    2007-07-28  9999-12-31  \n",
       "3             35    2007-07-11  2007-08-11  \n",
       "4             35    2007-08-11  9999-12-31  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = cash_txn_df.merge(\n",
    "    account_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"CT_CA_ID\",\n",
    "    right_on=\"AccountID\",\n",
    ")\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:42.852584Z",
     "iopub.status.busy": "2023-12-22T12:16:42.851584Z",
     "iopub.status.idle": "2023-12-22T12:16:43.426604Z",
     "shell.execute_reply": "2023-12-22T12:16:43.424788Z",
     "shell.execute_reply.started": "2023-12-22T12:16:42.852584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 602115 entries, 2 to 1197605\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   CT_CA_ID       602115 non-null  uint32        \n",
      " 1   CT_DTS         602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT         602115 non-null  float64       \n",
      " 3   CT_NAME        602115 non-null  object        \n",
      " 4   AccountID      602115 non-null  int64         \n",
      " 5   SK_AccountID   602115 non-null  int64         \n",
      " 6   SK_CustomerID  602115 non-null  int64         \n",
      " 7   EffectiveDate  602115 non-null  datetime64[ns]\n",
      " 8   EndDate        602115 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(3), object(2), uint32(1)\n",
      "memory usage: 43.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "      <td>36</td>\n",
       "      <td>5062</td>\n",
       "      <td>10007</td>\n",
       "      <td>2009-11-09</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "      <td>40</td>\n",
       "      <td>1050</td>\n",
       "      <td>9957</td>\n",
       "      <td>2007-12-30</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "      <td>19</td>\n",
       "      <td>6282</td>\n",
       "      <td>9960</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "2          2 2012-07-11 08:10:15 -37215.14   \n",
       "4         34 2012-07-07 17:11:38  -3178.67   \n",
       "8         36 2012-07-12 17:37:44  -3172.19   \n",
       "10        40 2012-09-20 03:12:34 -16621.00   \n",
       "14        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                              CT_NAME  AccountID  \\\n",
       "2   TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2   \n",
       "4   PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34   \n",
       "8   uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...         36   \n",
       "10  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...         40   \n",
       "14  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...         19   \n",
       "\n",
       "    SK_AccountID  SK_CustomerID EffectiveDate     EndDate  \n",
       "2            133           9952    2007-07-28  9999-12-31  \n",
       "4            220             35    2007-08-11  9999-12-31  \n",
       "8           5062          10007    2009-11-09  9999-12-31  \n",
       "10          1050           9957    2007-12-30  9999-12-31  \n",
       "14          6282           9960    2010-06-04  9999-12-31  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = cash_txn_df[\n",
    "    (cash_txn_df[\"CT_DTS\"] >= cash_txn_df[\"EffectiveDate\"])\n",
    "    & (cash_txn_df[\"CT_DTS\"].dt.date < cash_txn_df[\"EndDate\"])\n",
    "]\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK_DateID is obtained from DimDate by matching just the date portion of CT_DTS with\n",
    "DateValue to return the SK_DateID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:43.428603Z",
     "iopub.status.busy": "2023-12-22T12:16:43.427607Z",
     "iopub.status.idle": "2023-12-22T12:16:43.768602Z",
     "shell.execute_reply": "2023-12-22T12:16:43.767644Z",
     "shell.execute_reply.started": "2023-12-22T12:16:43.428603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25933 entries, 0 to 25932\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   DateValue  25933 non-null  datetime64[ns]\n",
      " 1   SK_DateID  25933 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 405.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateValue</th>\n",
       "      <th>SK_DateID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>19500101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-01-02</td>\n",
       "      <td>19500102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-01-03</td>\n",
       "      <td>19500103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-01-04</td>\n",
       "      <td>19500104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-01-05</td>\n",
       "      <td>19500105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DateValue  SK_DateID\n",
       "0 1950-01-01   19500101\n",
       "1 1950-01-02   19500102\n",
       "2 1950-01-03   19500103\n",
       "3 1950-01-04   19500104\n",
       "4 1950-01-05   19500105"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info[\"DateValue\"] = pd.to_datetime(date_info[\"DateValue\"])\n",
    "date_info.info()\n",
    "date_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:43.771607Z",
     "iopub.status.busy": "2023-12-22T12:16:43.770614Z",
     "iopub.status.idle": "2023-12-22T12:16:44.158606Z",
     "shell.execute_reply": "2023-12-22T12:16:44.157603Z",
     "shell.execute_reply.started": "2023-12-22T12:16:43.771607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 602115 entries, 2 to 1197605\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   CT_CA_ID       602115 non-null  uint32        \n",
      " 1   CT_DTS         602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT         602115 non-null  float64       \n",
      " 3   CT_NAME        602115 non-null  object        \n",
      " 4   AccountID      602115 non-null  int64         \n",
      " 5   SK_AccountID   602115 non-null  int64         \n",
      " 6   SK_CustomerID  602115 non-null  int64         \n",
      " 7   EffectiveDate  602115 non-null  datetime64[ns]\n",
      " 8   EndDate        602115 non-null  object        \n",
      " 9   SK_DateID      602115 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(4), object(2), uint32(1)\n",
      "memory usage: 48.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>SK_DateID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "      <td>36</td>\n",
       "      <td>5062</td>\n",
       "      <td>10007</td>\n",
       "      <td>2009-11-09</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "      <td>40</td>\n",
       "      <td>1050</td>\n",
       "      <td>9957</td>\n",
       "      <td>2007-12-30</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "      <td>19</td>\n",
       "      <td>6282</td>\n",
       "      <td>9960</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "2          2 2012-07-11 08:10:15 -37215.14   \n",
       "4         34 2012-07-07 17:11:38  -3178.67   \n",
       "8         36 2012-07-12 17:37:44  -3172.19   \n",
       "10        40 2012-09-20 03:12:34 -16621.00   \n",
       "14        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                              CT_NAME  AccountID  \\\n",
       "2   TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2   \n",
       "4   PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34   \n",
       "8   uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...         36   \n",
       "10  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...         40   \n",
       "14  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...         19   \n",
       "\n",
       "    SK_AccountID  SK_CustomerID EffectiveDate     EndDate  SK_DateID  \n",
       "2            133           9952    2007-07-28  9999-12-31   20120711  \n",
       "4            220             35    2007-08-11  9999-12-31   20120707  \n",
       "8           5062          10007    2009-11-09  9999-12-31   20120712  \n",
       "10          1050           9957    2007-12-30  9999-12-31   20120920  \n",
       "14          6282           9960    2010-06-04  9999-12-31   20120709  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df['SK_DateID'] = cash_txn_df['CT_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cash is calculated as the sum of the prior Cash amount for this account plus the sum of all\n",
    "CT_AMT values from all transactions in this account on this day. If there is no previous\n",
    "FactCashBalances record for the associated account, zero is used. Remember that the net effect of all cash transactions for a given account on a given day is totaled, and only a single record is generated per account that had changes per day.\n",
    "\n",
    "The procedure used to determine the new Cash total must account for the possibility that a\n",
    "new surrogate key is created in DimAccount since the last cash transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:44.160604Z",
     "iopub.status.busy": "2023-12-22T12:16:44.160604Z",
     "iopub.status.idle": "2023-12-22T12:16:45.364775Z",
     "shell.execute_reply": "2023-12-22T12:16:45.362776Z",
     "shell.execute_reply.started": "2023-12-22T12:16:44.160604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549361 entries, 0 to 549360\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   AccountID      549361 non-null  int64         \n",
      " 1   SK_DateID      549361 non-null  int64         \n",
      " 2   CT_CA_ID       549361 non-null  uint32        \n",
      " 3   CT_DTS         549361 non-null  datetime64[ns]\n",
      " 4   CT_AMT         549361 non-null  float64       \n",
      " 5   CT_NAME        549361 non-null  object        \n",
      " 6   SK_AccountID   549361 non-null  int64         \n",
      " 7   SK_CustomerID  549361 non-null  int64         \n",
      " 8   EffectiveDate  549361 non-null  datetime64[ns]\n",
      " 9   EndDate        549361 non-null  object        \n",
      " 10  PriorCash      549361 non-null  float64       \n",
      " 11  Cash           549361 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(3), int64(4), object(2), uint32(1)\n",
      "memory usage: 48.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>PriorCash</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20120708</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-08 17:58:21</td>\n",
       "      <td>-71563.60</td>\n",
       "      <td>hyaGSBCOXigNPHVAQxiPjJFgKBcBBQGDBQDpBxISwKkJ</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-71563.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120710</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-10 22:12:48</td>\n",
       "      <td>-89884.06</td>\n",
       "      <td>gSTsTBZrTEm PMYdHvhKxaJTrNxtosRUsJDwGBqwTbbjDO...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>3249.91</td>\n",
       "      <td>-86634.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20120711</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-11 04:19:10</td>\n",
       "      <td>8110.34</td>\n",
       "      <td>JGEQbvMIqUzPAbNiKtveoxbSUHRxlHkxdGZKeTdXWqhWGN...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-95309.80</td>\n",
       "      <td>-87199.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20120712</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-12 21:36:34</td>\n",
       "      <td>1641.86</td>\n",
       "      <td>YAROnGbtCACCSuAbFQJxIZxwibmZPuvKjoENySzzhmajQe...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-113718.54</td>\n",
       "      <td>-112076.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120713</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-13 16:23:08</td>\n",
       "      <td>-52115.15</td>\n",
       "      <td>xFePvUHkWgBKpuTjsCBcnRCYTUjEtIKYNtgeBVLTsQZfHj...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-604254.35</td>\n",
       "      <td>-656369.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountID  SK_DateID  CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0          0   20120708         0 2012-07-08 17:58:21 -71563.60   \n",
       "1          0   20120710         0 2012-07-10 22:12:48 -89884.06   \n",
       "2          0   20120711         0 2012-07-11 04:19:10   8110.34   \n",
       "3          0   20120712         0 2012-07-12 21:36:34   1641.86   \n",
       "4          0   20120713         0 2012-07-13 16:23:08 -52115.15   \n",
       "\n",
       "                                             CT_NAME  SK_AccountID  \\\n",
       "0       hyaGSBCOXigNPHVAQxiPjJFgKBcBBQGDBQDpBxISwKkJ           866   \n",
       "1  gSTsTBZrTEm PMYdHvhKxaJTrNxtosRUsJDwGBqwTbbjDO...           866   \n",
       "2  JGEQbvMIqUzPAbNiKtveoxbSUHRxlHkxdGZKeTdXWqhWGN...           866   \n",
       "3  YAROnGbtCACCSuAbFQJxIZxwibmZPuvKjoENySzzhmajQe...           866   \n",
       "4  xFePvUHkWgBKpuTjsCBcnRCYTUjEtIKYNtgeBVLTsQZfHj...           866   \n",
       "\n",
       "   SK_CustomerID EffectiveDate     EndDate  PriorCash       Cash  \n",
       "0           7802    2007-11-29  9999-12-31       0.00  -71563.60  \n",
       "1           7802    2007-11-29  9999-12-31    3249.91  -86634.15  \n",
       "2           7802    2007-11-29  9999-12-31  -95309.80  -87199.46  \n",
       "3           7802    2007-11-29  9999-12-31 -113718.54 -112076.68  \n",
       "4           7802    2007-11-29  9999-12-31 -604254.35 -656369.50  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by account ID and transaction date\n",
    "cash_txn_df.sort_values(by=['AccountID', 'CT_DTS'], inplace=True)\n",
    "\n",
    "# Create a new column to store the prior cash amount\n",
    "cash_txn_df['PriorCash'] = cash_txn_df.groupby('AccountID')['CT_AMT'].cumsum() - cash_txn_df['CT_AMT']\n",
    "cash_txn_df['PriorCash'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the cash balance\n",
    "cash_txn_df['Cash'] = cash_txn_df['PriorCash'] + cash_txn_df['CT_AMT']\n",
    "\n",
    "# Keep only the last record for each account on each day\n",
    "cash_txn_df = cash_txn_df.groupby(['AccountID', 'SK_DateID']).last().reset_index()\n",
    "\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:45.366802Z",
     "iopub.status.busy": "2023-12-22T12:16:45.365773Z",
     "iopub.status.idle": "2023-12-22T12:16:45.396788Z",
     "shell.execute_reply": "2023-12-22T12:16:45.394878Z",
     "shell.execute_reply.started": "2023-12-22T12:16:45.366802Z"
    }
   },
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    \"SK_CustomerID\",\n",
    "    \"SK_AccountID\",\n",
    "    \"SK_DateID\",\n",
    "    \"Cash\",\n",
    "]\n",
    "cash_txn_df = cash_txn_df[keep_cols]\n",
    "cash_txn_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:45.398785Z",
     "iopub.status.busy": "2023-12-22T12:16:45.398785Z",
     "iopub.status.idle": "2023-12-22T12:16:45.442779Z",
     "shell.execute_reply": "2023-12-22T12:16:45.441779Z",
     "shell.execute_reply.started": "2023-12-22T12:16:45.398785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549361 entries, 0 to 549360\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   SK_CustomerID  549361 non-null  int64  \n",
      " 1   SK_AccountID   549361 non-null  int64  \n",
      " 2   SK_DateID      549361 non-null  int64  \n",
      " 3   Cash           549361 non-null  float64\n",
      " 4   BatchID        549361 non-null  int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 21.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>Cash</th>\n",
       "      <th>BatchID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120708</td>\n",
       "      <td>-71563.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120710</td>\n",
       "      <td>-86634.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120711</td>\n",
       "      <td>-87199.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120712</td>\n",
       "      <td>-112076.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120713</td>\n",
       "      <td>-656369.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_CustomerID  SK_AccountID  SK_DateID       Cash  BatchID\n",
       "0           7802           866   20120708  -71563.60        1\n",
       "1           7802           866   20120710  -86634.15        1\n",
       "2           7802           866   20120711  -87199.46        1\n",
       "3           7802           866   20120712 -112076.68        1\n",
       "4           7802           866   20120713 -656369.50        1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:45.444779Z",
     "iopub.status.busy": "2023-12-22T12:16:45.443782Z",
     "iopub.status.idle": "2023-12-22T12:16:45.474831Z",
     "shell.execute_reply": "2023-12-22T12:16:45.472825Z",
     "shell.execute_reply.started": "2023-12-22T12:16:45.444779Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE FactCashBalances (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    SK_DateID INT UNSIGNED NOT NULL,\n",
    "    Cash DECIMAL(15, 2) NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL\n",
    ");\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:45.476827Z",
     "iopub.status.busy": "2023-12-22T12:16:45.475831Z",
     "iopub.status.idle": "2023-12-22T12:16:45.490831Z",
     "shell.execute_reply": "2023-12-22T12:16:45.488834Z",
     "shell.execute_reply.started": "2023-12-22T12:16:45.476827Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_AccountID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    \"Cash\": sqlalchemy.types.DECIMAL(precision=15, scale=2),\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:45.491841Z",
     "iopub.status.busy": "2023-12-22T12:16:45.491841Z",
     "iopub.status.idle": "2023-12-22T12:16:59.275140Z",
     "shell.execute_reply": "2023-12-22T12:16:59.274139Z",
     "shell.execute_reply.started": "2023-12-22T12:16:45.491841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d784fa046176428a86485a46bd8d9076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in trange(0, cash_txn_df.shape[0], 100000):\n",
    "    cash_txn_df.iloc[i:i+100000].to_sql('factcashbalances', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcb_end_time = datetime.now()\n",
    "print(f\"fcb took {(fcb_end_time - fcb_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactHoldings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:59.278140Z",
     "iopub.status.busy": "2023-12-22T12:16:59.277143Z",
     "iopub.status.idle": "2023-12-22T12:16:59.291143Z",
     "shell.execute_reply": "2023-12-22T12:16:59.290146Z",
     "shell.execute_reply.started": "2023-12-22T12:16:59.278140Z"
    }
   },
   "outputs": [],
   "source": [
    "# SQL queries\n",
    "sql_commands = [\n",
    "    \"DROP TABLE IF EXISTS TempHoldingHistory\",\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE TempHoldingHistory (\n",
    "        HH_H_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_BEFORE_QTY INT NOT NULL,\n",
    "        HH_AFTER_QTY INT NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'E:\\\\\\\\Documents\\\\\\\\BDMA\\\\\\\\ULB\\\\\\\\Data Warehouses\\\\\\\\tpc-di\\\\\\\\TPC-DI\\\\\\\\data\\\\\\\\sf5\\\\\\\\Batch1\\\\\\\\HoldingHistory.txt'\n",
    "    INTO TABLE TempHoldingHistory\n",
    "    FIELDS TERMINATED BY '|'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    (HH_H_T_ID, HH_T_ID, HH_BEFORE_QTY, HH_AFTER_QTY)\n",
    "    \"\"\",\n",
    "    \"DROP TABLE IF EXISTS FactHoldings\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE FactHoldings (\n",
    "        TradeID INT UNSIGNED NOT NULL,\n",
    "        CurrentTradeID INT UNSIGNED NOT NULL,\n",
    "        SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "        SK_AccountID INT UNSIGNED NOT NULL,\n",
    "        SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "        SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "        SK_DateID INT UNSIGNED NOT NULL,\n",
    "        SK_TimeID INT UNSIGNED NOT NULL,\n",
    "        CurrentPrice DECIMAL(8, 2) NOT NULL CHECK (CurrentPrice > 0),\n",
    "        CurrentHolding INT NOT NULL,\n",
    "        BatchID SMALLINT UNSIGNED NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    INSERT INTO FactHoldings (TradeID, CurrentTradeID, SK_CustomerID, SK_AccountID, SK_SecurityID, SK_CompanyID, SK_DateID, SK_TimeID, CurrentPrice, CurrentHolding, BatchID)\n",
    "    SELECT \n",
    "        thh.HH_H_T_ID AS TradeID,\n",
    "        thh.HH_T_ID AS CurrentTradeID,\n",
    "        dt.SK_CustomerID,\n",
    "        dt.SK_AccountID,\n",
    "        dt.SK_SecurityID,\n",
    "        dt.SK_CompanyID,\n",
    "        dt.SK_CloseDateID AS SK_DateID,\n",
    "        dt.SK_CloseTimeID AS SK_TimeID,\n",
    "        dt.TradePrice AS CurrentPrice,\n",
    "        thh.HH_AFTER_QTY AS CurrentHolding,\n",
    "        1 AS BatchID\n",
    "    FROM \n",
    "        TempHoldingHistory thh\n",
    "    JOIN \n",
    "        DimTrade dt ON thh.HH_T_ID = dt.TradeID\n",
    "    \"\"\",\n",
    "    \"DROP TABLE IF EXISTS TempHoldingHistory\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:16:59.295139Z",
     "iopub.status.busy": "2023-12-22T12:16:59.294139Z",
     "iopub.status.idle": "2023-12-22T12:17:09.265366Z",
     "shell.execute_reply": "2023-12-22T12:17:09.264680Z",
     "shell.execute_reply.started": "2023-12-22T12:16:59.295139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(\"SET GLOBAL local_infile = 1;\"))\n",
    "    for sql in sql_commands:\n",
    "        connection.execute(text(sql))\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_end_time = datetime.now()\n",
    "print(f\"fh took {(fh_end_time - fh_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactMarketHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmh_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:09.267367Z",
     "iopub.status.busy": "2023-12-22T12:17:09.267367Z",
     "iopub.status.idle": "2023-12-22T12:17:11.250370Z",
     "shell.execute_reply": "2023-12-22T12:17:11.248370Z",
     "shell.execute_reply.started": "2023-12-22T12:17:09.267367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2422064 entries, 0 to 2422063\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   DM_DATE    datetime64[ns]\n",
      " 1   DM_S_SYMB  object        \n",
      " 2   DM_CLOSE   float32       \n",
      " 3   DM_HIGH    float32       \n",
      " 4   DM_LOW     float32       \n",
      " 5   DM_VOL     int64         \n",
      "dtypes: datetime64[ns](1), float32(3), int64(1), object(1)\n",
      "memory usage: 83.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_CLOSE</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>DM_VOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYJ</td>\n",
       "      <td>445.459991</td>\n",
       "      <td>522.299988</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>78849320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEVC</td>\n",
       "      <td>910.590027</td>\n",
       "      <td>1148.890015</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>807515829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAACEZ</td>\n",
       "      <td>647.070007</td>\n",
       "      <td>756.679993</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>693226268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADOY</td>\n",
       "      <td>385.010010</td>\n",
       "      <td>564.669983</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>34628570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB    DM_CLOSE      DM_HIGH      DM_LOW     DM_VOL\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  242.929993   284.420013  185.080002  111904727\n",
       "1 2015-07-06  AAAAAAAAAAAAEYJ  445.459991   522.299988  386.480011   78849320\n",
       "2 2015-07-06  AAAAAAAAAAAAEVC  910.590027  1148.890015  723.369995  807515829\n",
       "3 2015-07-06  AAAAAAAAAAAACEZ  647.070007   756.679993  473.299988  693226268\n",
       "4 2015-07-06  AAAAAAAAAAAADOY  385.010010   564.669983  295.630005   34628570"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df = pd.read_csv(\n",
    "    DATA_DIR + \"DailyMarket.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"DM_DATE\",\n",
    "        \"DM_S_SYMB\",\n",
    "        \"DM_CLOSE\",\n",
    "        \"DM_HIGH\",\n",
    "        \"DM_LOW\",\n",
    "        \"DM_VOL\",\n",
    "    ],\n",
    "    dtype={\n",
    "        \"DM_DATE\": \"str\",\n",
    "        \"DM_S_SYMB\": \"str\",\n",
    "        \"DM_CLOSE\": \"float32\",\n",
    "        \"DM_HIGH\": \"float32\",\n",
    "        \"DM_LOW\": \"float32\",\n",
    "        \"DM_VOL\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"DM_DATE\"],\n",
    ")\n",
    "dailymarket_df[\"DM_DATE\"] = pd.to_datetime(dailymarket_df[\"DM_DATE\"])\n",
    "dailymarket_df.info()\n",
    "dailymarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:11.252371Z",
     "iopub.status.busy": "2023-12-22T12:17:11.252371Z",
     "iopub.status.idle": "2023-12-22T12:17:11.281374Z",
     "shell.execute_reply": "2023-12-22T12:17:11.279384Z",
     "shell.execute_reply.started": "2023-12-22T12:17:11.252371Z"
    }
   },
   "outputs": [],
   "source": [
    "# ClosePrice, DayHigh, DayLow, and Volume are copied from DM_CLOSE, DM_HIGH,\n",
    "# DM_LOW, and DM_VOL respectively.\n",
    "dailymarket_df[\"ClosePrice\"] = dailymarket_df[\"DM_CLOSE\"]\n",
    "dailymarket_df[\"DayHigh\"] = dailymarket_df[\"DM_HIGH\"]\n",
    "dailymarket_df[\"DayLow\"] = dailymarket_df[\"DM_LOW\"]\n",
    "dailymarket_df[\"Volume\"] = dailymarket_df[\"DM_VOL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:11.284369Z",
     "iopub.status.busy": "2023-12-22T12:17:11.283370Z",
     "iopub.status.idle": "2023-12-22T12:17:11.359410Z",
     "shell.execute_reply": "2023-12-22T12:17:11.357413Z",
     "shell.execute_reply.started": "2023-12-22T12:17:11.284369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DM_S_SYMB      4000 non-null   object        \n",
      " 1   SK_SecurityID  4000 non-null   int64         \n",
      " 2   SK_CompanyID   4000 non-null   int64         \n",
      " 3   EffectiveDate  4000 non-null   datetime64[ns]\n",
      " 4   EndDate        4000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_CompanyID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1967-04-25</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAB</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1967-04-26</td>\n",
       "      <td>1968-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAC</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1967-04-26</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAD</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1967-04-27</td>\n",
       "      <td>1979-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAE</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1967-04-27</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DM_S_SYMB  SK_SecurityID  SK_CompanyID EffectiveDate     EndDate\n",
       "0  AAAAAAAAAAAAAAA              1             5    1967-04-25  9999-12-31\n",
       "1  AAAAAAAAAAAAAAB              2            52    1967-04-26  1968-03-30\n",
       "2  AAAAAAAAAAAAAAC              3            13    1967-04-26  9999-12-31\n",
       "3  AAAAAAAAAAAAAAD              4            70    1967-04-27  1979-06-27\n",
       "4  AAAAAAAAAAAAAAE              5            46    1967-04-27  9999-12-31"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "security_info = pd.read_sql(\"SELECT Symbol AS DM_S_SYMB, SK_SecurityID, SK_CompanyID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "security_info.info()\n",
    "security_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:11.363413Z",
     "iopub.status.busy": "2023-12-22T12:17:11.362414Z",
     "iopub.status.idle": "2023-12-22T12:17:13.729861Z",
     "shell.execute_reply": "2023-12-22T12:17:13.729126Z",
     "shell.execute_reply.started": "2023-12-22T12:17:11.362414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2422064 entries, 0 to 2567327\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   DM_DATE        datetime64[ns]\n",
      " 1   DM_S_SYMB      object        \n",
      " 2   DM_CLOSE       float32       \n",
      " 3   DM_HIGH        float32       \n",
      " 4   DM_LOW         float32       \n",
      " 5   DM_VOL         int64         \n",
      " 6   ClosePrice     float32       \n",
      " 7   DayHigh        float32       \n",
      " 8   DayLow         float32       \n",
      " 9   Volume         int64         \n",
      " 10  SK_SecurityID  int64         \n",
      " 11  SK_CompanyID   int64         \n",
      "dtypes: datetime64[ns](1), float32(6), int64(4), object(1)\n",
      "memory usage: 184.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df = pd.merge(\n",
    "    dailymarket_df,\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    on=\"DM_S_SYMB\",\n",
    ")\n",
    "dailymarket_df = dailymarket_df[\n",
    "    (dailymarket_df[\"DM_DATE\"] >= dailymarket_df[\"EffectiveDate\"])\n",
    "    & (dailymarket_df[\"DM_DATE\"].dt.date < dailymarket_df[\"EndDate\"])\n",
    "]\n",
    "# drop temp columns\n",
    "dailymarket_df.drop(columns=[\"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:13.733445Z",
     "iopub.status.busy": "2023-12-22T12:17:13.732454Z",
     "iopub.status.idle": "2023-12-22T12:17:14.839519Z",
     "shell.execute_reply": "2023-12-22T12:17:14.837858Z",
     "shell.execute_reply.started": "2023-12-22T12:17:13.733445Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"SK_DateID is obtained from DimDate by matching DM_DATE with DateValue to return the\n",
    "SK_DateID. The match is guaranteed to succeed because DimDate has been populated\n",
    "with date information for all dates relevant to the benchmark.\"\"\"\n",
    "date_info = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info[\"DateValue\"] = pd.to_datetime(date_info[\"DateValue\"])\n",
    "date_info = date_info.set_index(\"DateValue\")[\"SK_DateID\"].to_dict()\n",
    "dailymarket_df[\"SK_DateID\"] = dailymarket_df[\"DM_DATE\"].dt.date.map(date_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:14.841490Z",
     "iopub.status.busy": "2023-12-22T12:17:14.840503Z",
     "iopub.status.idle": "2023-12-22T12:17:18.113488Z",
     "shell.execute_reply": "2023-12-22T12:17:18.112466Z",
     "shell.execute_reply.started": "2023-12-22T12:17:14.841490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>FiftyTwoWeekHigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>284.420013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYD</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>841.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABJB</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>1055.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADSX</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>747.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABYA</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>708.140015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB      DM_HIGH  FiftyTwoWeekHigh\n",
       "0 2015-07-06  AAAAAAAAAAAAERN   284.420013        284.420013\n",
       "1 2015-07-06  AAAAAAAAAAAAEYD   841.200012        841.200012\n",
       "2 2015-07-06  AAAAAAAAAAAABJB  1055.699951       1055.699951\n",
       "3 2015-07-06  AAAAAAAAAAAADSX   747.770020        747.770020\n",
       "4 2015-07-06  AAAAAAAAAAAABYA   708.140015        708.140015"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Sort the DataFrame\n",
    "dailymarket_df.sort_values(by='DM_DATE', inplace=True)\n",
    "\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling max\n",
    "rolling_max = dailymarket_df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_HIGH'].max()\n",
    "\n",
    "# Reset index to make merging easier\n",
    "rolling_max = rolling_max.reset_index()\n",
    "\n",
    "# Step 5: Merge with the original DataFrame\n",
    "dailymarket_df = dailymarket_df.merge(rolling_max, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekHigh'))\n",
    "\n",
    "# Rename the column for clarity\n",
    "dailymarket_df.rename(columns={'DM_HIGH_52WeekHigh': 'FiftyTwoWeekHigh'}, inplace=True)\n",
    "dailymarket_df[['DM_DATE', 'DM_S_SYMB', 'DM_HIGH', 'FiftyTwoWeekHigh']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:18.116465Z",
     "iopub.status.busy": "2023-12-22T12:17:18.115450Z",
     "iopub.status.idle": "2023-12-22T12:17:21.963267Z",
     "shell.execute_reply": "2023-12-22T12:17:21.962268Z",
     "shell.execute_reply.started": "2023-12-22T12:17:18.116465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>Rank</th>\n",
       "      <th>SK_FiftyTwoWeekHighDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>1</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>1</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>4</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DM_S_SYMB    DM_DATE  Rank  SK_FiftyTwoWeekHighDate\n",
       "0  AAAAAAAAAAAAAAA 2015-07-06     1                 20150706\n",
       "1  AAAAAAAAAAAAAAA 2015-07-07     1                 20150707\n",
       "2  AAAAAAAAAAAAAAA 2015-07-08     2                 20150707\n",
       "3  AAAAAAAAAAAAAAA 2015-07-09     2                 20150707\n",
       "4  AAAAAAAAAAAAAAA 2015-07-10     4                 20150707"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostly wrote this myself but dont ask me to explain...........\n",
    "rolling_rank = (\n",
    "    dailymarket_df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_HIGH\"]\n",
    "    .rank(method=\"average\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_HIGH\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['SK_FiftyTwoWeekHighDate'].dt.date.map(date_info)\n",
    "rolling_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:21.965272Z",
     "iopub.status.busy": "2023-12-22T12:17:21.964267Z",
     "iopub.status.idle": "2023-12-22T12:17:22.103784Z",
     "shell.execute_reply": "2023-12-22T12:17:22.101823Z",
     "shell.execute_reply.started": "2023-12-22T12:17:21.965272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_CLOSE</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>DM_VOL</th>\n",
       "      <th>ClosePrice</th>\n",
       "      <th>DayHigh</th>\n",
       "      <th>DayLow</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_CompanyID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>FiftyTwoWeekHigh</th>\n",
       "      <th>SK_FiftyTwoWeekHighDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>3523</td>\n",
       "      <td>1275</td>\n",
       "      <td>20150706</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYD</td>\n",
       "      <td>624.479980</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>505.109985</td>\n",
       "      <td>448826960</td>\n",
       "      <td>624.479980</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>505.109985</td>\n",
       "      <td>448826960</td>\n",
       "      <td>3709</td>\n",
       "      <td>1825</td>\n",
       "      <td>20150706</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABJB</td>\n",
       "      <td>918.270020</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>808.450012</td>\n",
       "      <td>187580057</td>\n",
       "      <td>918.270020</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>808.450012</td>\n",
       "      <td>187580057</td>\n",
       "      <td>986</td>\n",
       "      <td>461</td>\n",
       "      <td>20150706</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADSX</td>\n",
       "      <td>593.820007</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>593.119995</td>\n",
       "      <td>625016548</td>\n",
       "      <td>593.820007</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>593.119995</td>\n",
       "      <td>625016548</td>\n",
       "      <td>2794</td>\n",
       "      <td>811</td>\n",
       "      <td>20150706</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABYA</td>\n",
       "      <td>517.380005</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>394.940002</td>\n",
       "      <td>278873866</td>\n",
       "      <td>517.380005</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>394.940002</td>\n",
       "      <td>278873866</td>\n",
       "      <td>1420</td>\n",
       "      <td>229</td>\n",
       "      <td>20150706</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB    DM_CLOSE      DM_HIGH      DM_LOW     DM_VOL  \\\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  242.929993   284.420013  185.080002  111904727   \n",
       "1 2015-07-06  AAAAAAAAAAAAEYD  624.479980   841.200012  505.109985  448826960   \n",
       "2 2015-07-06  AAAAAAAAAAAABJB  918.270020  1055.699951  808.450012  187580057   \n",
       "3 2015-07-06  AAAAAAAAAAAADSX  593.820007   747.770020  593.119995  625016548   \n",
       "4 2015-07-06  AAAAAAAAAAAABYA  517.380005   708.140015  394.940002  278873866   \n",
       "\n",
       "   ClosePrice      DayHigh      DayLow     Volume  SK_SecurityID  \\\n",
       "0  242.929993   284.420013  185.080002  111904727           3523   \n",
       "1  624.479980   841.200012  505.109985  448826960           3709   \n",
       "2  918.270020  1055.699951  808.450012  187580057            986   \n",
       "3  593.820007   747.770020  593.119995  625016548           2794   \n",
       "4  517.380005   708.140015  394.940002  278873866           1420   \n",
       "\n",
       "   SK_CompanyID  SK_DateID  FiftyTwoWeekHigh  SK_FiftyTwoWeekHighDate  \n",
       "0          1275   20150706        284.420013                 20150706  \n",
       "1          1825   20150706        841.200012                 20150707  \n",
       "2           461   20150706       1055.699951                 20150707  \n",
       "3           811   20150706        747.770020                 20150707  \n",
       "4           229   20150706        708.140015                 20150707  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df = pd.concat([dailymarket_df, rolling_rank['SK_FiftyTwoWeekHighDate']], axis=1)\n",
    "dailymarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:22.105786Z",
     "iopub.status.busy": "2023-12-22T12:17:22.104784Z",
     "iopub.status.idle": "2023-12-22T12:17:25.567072Z",
     "shell.execute_reply": "2023-12-22T12:17:25.565108Z",
     "shell.execute_reply.started": "2023-12-22T12:17:22.105786Z"
    }
   },
   "outputs": [],
   "source": [
    "dailymarket_df.sort_values(by='DM_DATE', inplace=True)\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling min\n",
    "rolling_min = dailymarket_df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_LOW'].min()\n",
    "# Reset index to make merging easier\n",
    "rolling_min = rolling_min.reset_index()\n",
    "# Step 5: Merge with the original DataFrame\n",
    "dailymarket_df = dailymarket_df.merge(rolling_min, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekLow'))\n",
    "# Rename the column for clarity\n",
    "dailymarket_df.rename(columns={'DM_LOW_52WeekLow': 'FiftyTwoWeekLow'}, inplace=True)\n",
    "# dailymarket_df[['DM_DATE', 'DM_S_SYMB', 'DM_LOW', 'FiftyTwoWeekLow']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:25.570069Z",
     "iopub.status.busy": "2023-12-22T12:17:25.569070Z",
     "iopub.status.idle": "2023-12-22T12:17:29.561813Z",
     "shell.execute_reply": "2023-12-22T12:17:29.560807Z",
     "shell.execute_reply.started": "2023-12-22T12:17:25.569070Z"
    }
   },
   "outputs": [],
   "source": [
    "# same...\n",
    "rolling_rank = (\n",
    "    dailymarket_df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_LOW\"]\n",
    "    .rank(method=\"average\", ascending=True)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_LOW\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['SK_FiftyTwoWeekLowDate'].dt.date.map(date_info)\n",
    "# rolling_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:29.564767Z",
     "iopub.status.busy": "2023-12-22T12:17:29.563766Z",
     "iopub.status.idle": "2023-12-22T12:17:29.703157Z",
     "shell.execute_reply": "2023-12-22T12:17:29.702403Z",
     "shell.execute_reply.started": "2023-12-22T12:17:29.564767Z"
    }
   },
   "outputs": [],
   "source": [
    "dailymarket_df = pd.concat([dailymarket_df, rolling_rank['SK_FiftyTwoWeekLowDate']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:29.705153Z",
     "iopub.status.busy": "2023-12-22T12:17:29.705153Z",
     "iopub.status.idle": "2023-12-22T12:17:30.109869Z",
     "shell.execute_reply": "2023-12-22T12:17:30.108120Z",
     "shell.execute_reply.started": "2023-12-22T12:17:29.705153Z"
    }
   },
   "outputs": [],
   "source": [
    "dailymarket_df['SK_SecurityID'] = dailymarket_df['SK_SecurityID'].astype('uint32')\n",
    "dailymarket_df['SK_CompanyID'] = dailymarket_df['SK_CompanyID'].astype('uint32')\n",
    "dailymarket_df['SK_DateID'] = dailymarket_df['SK_DateID'].astype('uint32')\n",
    "dailymarket_df['FiftyTwoWeekHigh'] = dailymarket_df['FiftyTwoWeekHigh'].astype('float32')\n",
    "dailymarket_df['SK_FiftyTwoWeekHighDate'] = dailymarket_df['SK_FiftyTwoWeekHighDate'].astype('uint32')\n",
    "dailymarket_df['FiftyTwoWeekLow'] = dailymarket_df['FiftyTwoWeekLow'].astype('float32')\n",
    "dailymarket_df['SK_FiftyTwoWeekLowDate'] = dailymarket_df['SK_FiftyTwoWeekLowDate'].astype('uint32')\n",
    "dailymarket_df['DM_S_SYMB'] = dailymarket_df['DM_S_SYMB'].astype('category')\n",
    "\n",
    "dailymarket_df.drop(columns=['DM_HIGH', 'DM_LOW', 'DM_VOL', 'DM_CLOSE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:30.111880Z",
     "iopub.status.busy": "2023-12-22T12:17:30.110820Z",
     "iopub.status.idle": "2023-12-22T12:17:30.186823Z",
     "shell.execute_reply": "2023-12-22T12:17:30.185818Z",
     "shell.execute_reply.started": "2023-12-22T12:17:30.111880Z"
    }
   },
   "outputs": [],
   "source": [
    "security_info = pd.read_sql(\"SELECT Symbol, Dividend, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:30.188821Z",
     "iopub.status.busy": "2023-12-22T12:17:30.188821Z",
     "iopub.status.idle": "2023-12-22T12:17:32.672565Z",
     "shell.execute_reply": "2023-12-22T12:17:32.671550Z",
     "shell.execute_reply.started": "2023-12-22T12:17:30.188821Z"
    }
   },
   "outputs": [],
   "source": [
    "dailymarket_df = dailymarket_df.merge(\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"DM_S_SYMB\",\n",
    "    right_on=\"Symbol\",\n",
    ")\n",
    "dailymarket_df = dailymarket_df[\n",
    "    (dailymarket_df[\"DM_DATE\"] >= dailymarket_df[\"EffectiveDate\"])\n",
    "    & (dailymarket_df[\"DM_DATE\"].dt.date < dailymarket_df[\"EndDate\"])\n",
    "]\n",
    "dailymarket_df.drop(columns=[\"Symbol\", \"EffectiveDate\", \"EndDate\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:32.675548Z",
     "iopub.status.busy": "2023-12-22T12:17:32.674545Z",
     "iopub.status.idle": "2023-12-22T12:17:32.829545Z",
     "shell.execute_reply": "2023-12-22T12:17:32.828594Z",
     "shell.execute_reply.started": "2023-12-22T12:17:32.675548Z"
    }
   },
   "outputs": [],
   "source": [
    "dailymarket_df['Yield'] = dailymarket_df['Dividend'] / dailymarket_df['ClosePrice'] * 100\n",
    "dailymarket_df.drop(columns=[\"Dividend\"], inplace=True)\n",
    "dailymarket_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:32.832548Z",
     "iopub.status.busy": "2023-12-22T12:17:32.831549Z",
     "iopub.status.idle": "2023-12-22T12:17:32.845546Z",
     "shell.execute_reply": "2023-12-22T12:17:32.844545Z",
     "shell.execute_reply.started": "2023-12-22T12:17:32.832548Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    # PERatio to be done in MySQL\n",
    "    # \"PERatio\": sqlalchemy.types.DECIMAL(precision=10, scale=2),\n",
    "    \"Yield\": sqlalchemy.types.DECIMAL(precision=5, scale=2),\n",
    "    \"FiftyTwoWeekHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekHighDate\": sqlalchemy.types.Integer,\n",
    "    \"FiftyTwoWeekLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekLowDate\": sqlalchemy.types.Integer,\n",
    "    \"ClosePrice\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"Volume\": sqlalchemy.types.BigInteger,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "    \"DM_DATE\": sqlalchemy.types.Date,\n",
    "    \"DM_S_SYMB\": sqlalchemy.types.CHAR(16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:32.848546Z",
     "iopub.status.busy": "2023-12-22T12:17:32.847545Z",
     "iopub.status.idle": "2023-12-22T12:17:32.877546Z",
     "shell.execute_reply": "2023-12-22T12:17:32.875550Z",
     "shell.execute_reply.started": "2023-12-22T12:17:32.848546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2422064 entries, 0 to 2567327\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                object        \n",
      " 2   ClosePrice               float32       \n",
      " 3   DayHigh                  float32       \n",
      " 4   DayLow                   float32       \n",
      " 5   Volume                   int64         \n",
      " 6   SK_SecurityID            uint32        \n",
      " 7   SK_CompanyID             uint32        \n",
      " 8   SK_DateID                uint32        \n",
      " 9   FiftyTwoWeekHigh         float32       \n",
      " 10  SK_FiftyTwoWeekHighDate  uint32        \n",
      " 11  FiftyTwoWeekLow          float32       \n",
      " 12  SK_FiftyTwoWeekLowDate   uint32        \n",
      " 13  Yield                    float64       \n",
      " 14  BatchID                  int64         \n",
      "dtypes: datetime64[ns](1), float32(5), float64(1), int64(2), object(1), uint32(5)\n",
      "memory usage: 203.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-22T12:17:32.880546Z",
     "iopub.status.busy": "2023-12-22T12:17:32.879551Z",
     "iopub.status.idle": "2023-12-22T12:18:45.822279Z",
     "shell.execute_reply": "2023-12-22T12:18:45.820310Z",
     "shell.execute_reply.started": "2023-12-22T12:17:32.879551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2c63c4bff84e2c9c23f7a661b7f09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PendingRollbackError",
     "evalue": "Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPendingRollbackError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, dailymarket_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mdailymarket_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtempfactmarketprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dtypes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\pandas\\core\\generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\pandas\\io\\sql.py:787\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[1;32m--> 787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    789\u001b[0m         frame,\n\u001b[0;32m    790\u001b[0m         name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    800\u001b[0m     )\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\pandas\\io\\sql.py:1585\u001b[0m, in \u001b[0;36mSQLDatabase.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_generator:\n\u001b[1;32m-> 1585\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\contextlib.py:584\u001b[0m, in \u001b[0;36mExitStack.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    583\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Immediately unwind the context stack.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\contextlib.py:576\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[1;34m(self, *exc_details)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# bare \"raise exc_details[1]\" replaces our carefully\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# set-up context\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     fixed_ctx \u001b[38;5;241m=\u001b[39m exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_details[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     exc_details[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m fixed_ctx\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\contextlib.py:561\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[1;34m(self, *exc_details)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_sync\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexc_details\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    562\u001b[0m         suppressed_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         pending_raise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\util.py:146\u001b[0m, in \u001b[0;36mTransactionalContext.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rollback_can_be_called():\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollback()\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\util.py:144\u001b[0m, in \u001b[0;36mTransactionalContext.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction_is_active():\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2619\u001b[0m, in \u001b[0;36mTransaction.commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2603\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Commit this :class:`.Transaction`.\u001b[39;00m\n\u001b[0;32m   2604\u001b[0m \n\u001b[0;32m   2605\u001b[0m \u001b[38;5;124;03mThe implementation of this may vary based on the type of transaction in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2616\u001b[0m \n\u001b[0;32m   2617\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2619\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_commit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2621\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_active\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2724\u001b[0m, in \u001b[0;36mRootTransaction._do_commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2721\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2723\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2724\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_commit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2725\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2726\u001b[0m     \u001b[38;5;66;03m# whether or not commit succeeds, cancel any\u001b[39;00m\n\u001b[0;32m   2727\u001b[0m     \u001b[38;5;66;03m# nested transactions, make this transaction \"inactive\"\u001b[39;00m\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;66;03m# and remove it as a reset agent\u001b[39;00m\n\u001b[0;32m   2729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39m_nested_transaction:\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2695\u001b[0m, in \u001b[0;36mRootTransaction._connection_commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_connection_commit_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2695\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_commit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1138\u001b[0m, in \u001b[0;36mConnection._commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_commit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2346\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2344\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2345\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2346\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   2347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2348\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1136\u001b[0m, in \u001b[0;36mConnection._commit_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOMMIT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_commit(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(e, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:577\u001b[0m, in \u001b[0;36mConnection.connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_revalidate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (exc\u001b[38;5;241m.\u001b[39mPendingRollbackError, exc\u001b[38;5;241m.\u001b[39mResourceClosedError):\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:669\u001b[0m, in \u001b[0;36mConnection._revalidate_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__can_reconnect \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalidated:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invalid_transaction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection\n",
      "File \u001b[1;32mE:\\miniconda3\\envs\\tpcdi\\lib\\site-packages\\sqlalchemy\\engine\\base.py:659\u001b[0m, in \u001b[0;36mConnection._invalid_transaction\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invalid_transaction\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m--> 659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mPendingRollbackError(\n\u001b[0;32m    660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reconnect until invalid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124mtransaction is rolled \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback.  Please rollback() fully before proceeding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavepoint \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    663\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8s2b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    664\u001b[0m     )\n",
      "\u001b[1;31mPendingRollbackError\u001b[0m: Can't reconnect until invalid transaction is rolled back.  Please rollback() fully before proceeding (Background on this error at: https://sqlalche.me/e/20/8s2b)"
     ]
    }
   ],
   "source": [
    "for i in trange(0, dailymarket_df.shape[0], 100000):\n",
    "    dailymarket_df.iloc[i:i+100000].to_sql('tempfactmarketprice', engine, if_exists='append', index=False,\n",
    "                                           dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.823268Z",
     "iopub.status.idle": "2023-12-22T12:18:45.823268Z",
     "shell.execute_reply": "2023-12-22T12:18:45.823268Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.823268Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_commands = [\n",
    "    \"CREATE INDEX idx_sk_companyid ON tempfactmarketprice(SK_CompanyID);\",\n",
    "    \"\"\"CREATE TABLE FactMarketHistory (\n",
    "        SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "        SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "        SK_DateID INT UNSIGNED NOT NULL,\n",
    "        PERatio DECIMAL(10, 2),\n",
    "        Yield DECIMAL(5, 2) NOT NULL,\n",
    "        FiftyTwoWeekHigh DECIMAL(8, 2) NOT NULL,\n",
    "        SK_FiftyTwoWeekHighDate INT UNSIGNED NOT NULL,\n",
    "        FiftyTwoWeekLow DECIMAL(8, 2) NOT NULL,\n",
    "        SK_FiftyTwoWeekLowDate INT UNSIGNED NOT NULL,\n",
    "        ClosePrice DECIMAL(8, 2) NOT NULL,\n",
    "        DayHigh DECIMAL(8, 2) NOT NULL,\n",
    "        DayLow DECIMAL(8, 2) NOT NULL,\n",
    "        Volume BIGINT UNSIGNED NOT NULL,\n",
    "        BatchID SMALLINT UNSIGNED NOT NULL\n",
    "    );\"\"\",\n",
    "    \"ALTER TABLE factmarkethistory ADD COLUMN DM_S_SYMB TEXT;\",\n",
    "    \"\"\"INSERT INTO factmarkethistory\n",
    "        SELECT SK_SecurityID, fmp.SK_CompanyID, SK_DateID, fmp.ClosePrice / T.Sum_EPS AS PERatio, Yield, FiftyTwoWeekHigh,\n",
    "        SK_FiftyTwoWeekHighDate, FiftyTwoWeekLow, SK_FiftyTwoWeekLowDate, ClosePrice, DayHigh, DayLow, Volume, BatchID, DM_S_SYMB\n",
    "        FROM tempfactmarketprice fmp\n",
    "        LEFT JOIN (SELECT \n",
    "            c.CompanyID, \n",
    "            c.SK_CompanyID AS SKCID, \n",
    "            f.FI_QTR_START_DATE,\n",
    "            SUM(f.FI_BASIC_EPS) OVER (\n",
    "                PARTITION BY c.CompanyID \n",
    "                ORDER BY f.FI_QTR_START_DATE \n",
    "                ROWS BETWEEN 3 PRECEDING AND CURRENT ROW\n",
    "            ) AS Sum_EPS\n",
    "        FROM financial f RIGHT JOIN dimCompany c ON f.SK_CompanyID = c.SK_CompanyID\n",
    "        ORDER BY c.CompanyID, f.FI_QTR_START_DATE) T\n",
    "        ON T.SKCID = fmp.SK_CompanyID\n",
    "        AND T.FI_QTR_START_DATE < fmp.DM_DATE \n",
    "        AND T.FI_QTR_START_DATE >= DATE_SUB(fmp.DM_DATE, INTERVAL 3 MONTH);\"\"\",\n",
    "    \"\"\"INSERT INTO dimessages\n",
    "        SELECT NOW() AS MessageDateAndTime, 1 AS BATCHID, 'FactMarketHistory' AS MessageSource, 'No earnings for company' AS MessageText,\n",
    "        'Alert' AS MessageType, CONCAT('DM_S_SYMB = ', DM_S_SYMB)\n",
    "        FROM factmarkethistory \n",
    "        WHERE PERatio IS NULL;\"\"\",\n",
    "    \"ALTER TABLE factmarkethistory DROP COLUMN DM_S_SYMB;\",\n",
    "    \"DROP TABLE tempfactmarketprice;\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.825270Z",
     "iopub.status.idle": "2023-12-22T12:18:45.826269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.825270Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.825270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "with engine.connect() as connection:\n",
    "    for sql in sql_commands:\n",
    "        connection.execute(text(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmh_end_time = datetime.now()\n",
    "print(f\"fmh took {(fmh_end_time - fmh_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactWatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.828269Z",
     "iopub.status.idle": "2023-12-22T12:18:45.828269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.828269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.828269Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"WatchHistory.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"W_C_ID\",\n",
    "        \"W_S_SYMB\",\n",
    "        \"W_DTS\",\n",
    "        \"W_ACTION\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"W_C_ID\": \"uint32\",\n",
    "        \"W_S_SYMB\": \"str\",\n",
    "        \"W_DTS\": \"str\",\n",
    "        \"W_ACTION\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"W_DTS\"]\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.830284Z",
     "iopub.status.idle": "2023-12-22T12:18:45.831268Z",
     "shell.execute_reply": "2023-12-22T12:18:45.831268Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.830284Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_info = pd.read_sql_query(\"SELECT CustomerID, SK_CustomerID, EffectiveDate, EndDate FROM dimcustomer\", engine)\n",
    "customer_info['EffectiveDate'] = pd.to_datetime(customer_info['EffectiveDate'])\n",
    "security_info = pd.read_sql_query(\"SELECT Symbol, SK_SecurityID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "date_info = pd.read_sql_query(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info['DateValue'] = pd.to_datetime(date_info['DateValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.833269Z",
     "iopub.status.idle": "2023-12-22T12:18:45.833269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.833269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.833269Z"
    }
   },
   "outputs": [],
   "source": [
    "# get SK_CustomerID\n",
    "df = df.merge(customer_info, how=\"left\", left_on=\"W_C_ID\", right_on=\"CustomerID\")\n",
    "# filter based on date\n",
    "df = df[\n",
    "    (df[\"W_DTS\"] >= df[\"EffectiveDate\"])\n",
    "    & (df[\"W_DTS\"].dt.date < df[\"EndDate\"])\n",
    "]\n",
    "# drop cols\n",
    "df.drop(columns=[\"CustomerID\", \"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "# get SK_SecurityID\n",
    "df = df.merge(security_info, how=\"left\", left_on=\"W_S_SYMB\", right_on=\"Symbol\")\n",
    "# filter based on date\n",
    "df = df[\n",
    "    (df[\"W_DTS\"] >= df[\"EffectiveDate\"])\n",
    "    & (df[\"W_DTS\"].dt.date < df[\"EndDate\"])\n",
    "]\n",
    "# drop cols\n",
    "df.drop(columns=[\"Symbol\", \"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "# SK_DateID_DatePlaced - set based on W_DTS.\n",
    "df['SK_DateID_DatePlaced'] = df['W_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "# BatchID - set to 1.\n",
    "df['BatchID'] = 1\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.836270Z",
     "iopub.status.idle": "2023-12-22T12:18:45.837269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.837269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.837269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mask for rows where W_ACTION is 'CNCL'\n",
    "mask_cncl = df['W_ACTION'] == 'CNCL'\n",
    "df.loc[mask_cncl, 'SK_DateID_DateRemoved'] = df.loc[mask_cncl, 'W_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "df.loc[~mask_cncl, 'SK_DateID_DateRemoved'] = None\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.839292Z",
     "iopub.status.idle": "2023-12-22T12:18:45.839292Z",
     "shell.execute_reply": "2023-12-22T12:18:45.839292Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.839292Z"
    }
   },
   "outputs": [],
   "source": [
    "keep_cols = [\"SK_CustomerID\", \"SK_SecurityID\", \"SK_DateID_DatePlaced\", \"SK_DateID_DateRemoved\", \"BatchID\"]\n",
    "df = df.groupby([\"W_C_ID\", \"W_S_SYMB\"]).first().reset_index()[keep_cols]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.841269Z",
     "iopub.status.idle": "2023-12-22T12:18:45.842272Z",
     "shell.execute_reply": "2023-12-22T12:18:45.841269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.841269Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DatePlaced\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DateRemoved\": sqlalchemy.types.Integer,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.844268Z",
     "iopub.status.idle": "2023-12-22T12:18:45.845269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.844268Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.844268Z"
    }
   },
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE FactWatches (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    SK_DateID_DatePlaced INT UNSIGNED NOT NULL,\n",
    "    SK_DateID_DateRemoved INT UNSIGNED,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL\n",
    ");\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.847269Z",
     "iopub.status.idle": "2023-12-22T12:18:45.847269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.847269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.847269Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in trange(0, df.shape[0], 100000):\n",
    "    df.iloc[i:i+100000].to_sql('factwatches', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_end_time = datetime.now()\n",
    "print(f\"Prospect took {(fw_end_time - fw_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Batch Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.849273Z",
     "iopub.status.idle": "2023-12-22T12:18:45.850269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.850269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.850269Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = r\"fk.sql\"\n",
    "# Read the SQL file\n",
    "with open(filepath, 'r') as file:\n",
    "    sql_file = file.read()\n",
    "queries = sql_file.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.854301Z",
     "iopub.status.idle": "2023-12-22T12:18:45.855269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.854301Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.854301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Execute the SQL commands\n",
    "with engine.connect() as connection:\n",
    "    for query in tqdm(queries):\n",
    "        query = query.strip() + \";\"\n",
    "        if len(query) < 5:\n",
    "            continue\n",
    "        connection.execute(text(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_end_time = datetime.now()\n",
    "print(f\"fk took {(fk_end_time - fk_start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.857269Z",
     "iopub.status.idle": "2023-12-22T12:18:45.857269Z",
     "shell.execute_reply": "2023-12-22T12:18:45.857269Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.857269Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = r\"..\\validation\\tpcdi_validation.sql\"\n",
    "# Read the SQL file\n",
    "with open(filepath, 'r') as file:\n",
    "    sql_file = file.read()\n",
    "\n",
    "# Execute the SQL commands\n",
    "with engine.connect() as connection:\n",
    "    for query in sql_file.split(\";\"):\n",
    "        query = query.strip() + \";\"\n",
    "        if len(query) < 5:\n",
    "            continue\n",
    "        connection.execute(text(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-22T12:18:45.860270Z",
     "iopub.status.idle": "2023-12-22T12:18:45.860270Z",
     "shell.execute_reply": "2023-12-22T12:18:45.860270Z",
     "shell.execute_reply.started": "2023-12-22T12:18:45.860270Z"
    }
   },
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print(f\"Historical load took {(end_time - start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"SELECT concat('ALTER TABLE `', TABLE_NAME, '` DROP FOREIGN KEY `', CONSTRAINT_NAME, '`;') \n",
    "# FROM information_schema.key_column_usage \n",
    "# WHERE CONSTRAINT_SCHEMA = 'tpcdi_sf5' \n",
    "# AND referenced_table_name IS NOT NULL;\"\"\"\n",
    "# result = pd.read_sql_query(query, engine).iloc[:, 0]\n",
    "# for value in result.values:\n",
    "#     with engine.connect() as cnxn:\n",
    "#         cnxn.execute(text(value))\n",
    "#         cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_ID = 2\n",
    "DATA_DIR = f\"..\\\\data\\\\sf5\\\\Batch{BATCH_ID}\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"BatchDate.txt\") as f:\n",
    "    BATCH_DATE = f.read().strip()\n",
    "BATCH_DATE = pd.to_datetime(BATCH_DATE)\n",
    "BATCH_DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimCustomer & Prospect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### dimCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "column_names = [\n",
    "    \"CDC_FLAG\", \"CDC_DSN\", \"C_ID\", \"C_TAX_ID\", \"C_ST_ID\",\n",
    "    \"C_L_NAME\", \"C_F_NAME\", \"C_M_NAME\", \"C_GNDR\", \"C_TIER\",\n",
    "    \"C_DOB\", \"C_ADLINE1\", \"C_ADLINE2\", \"C_ZIPCODE\", \"C_CITY\",\n",
    "    \"C_STATE_PROV\", \"C_CTRY\", \"C_CTRY_1\", \"C_AREA_1\", \"C_LOCAL_1\",\n",
    "    \"C_EXT_1\", \"C_CTRY_2\", \"C_AREA_2\", \"C_LOCAL_2\", \"C_EXT_2\",\n",
    "    \"C_CTRY_3\", \"C_AREA_3\", \"C_LOCAL_3\", \"C_EXT_3\", \"C_EMAIL_1\",\n",
    "    \"C_EMAIL_2\", \"C_LCL_TX_ID\", \"C_NAT_TX_ID\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data types\n",
    "data_types = {\n",
    "    \"CDC_FLAG\": \"category\",\n",
    "    \"CDC_DSN\": \"int64\",\n",
    "    \"C_ID\": \"int64\",\n",
    "    \"C_TAX_ID\": \"str\",\n",
    "    \"C_ST_ID\": \"category\",\n",
    "    \"C_L_NAME\": \"str\",\n",
    "    \"C_F_NAME\": \"str\",\n",
    "    \"C_M_NAME\": \"str\",\n",
    "    \"C_GNDR\": \"category\",\n",
    "    \"C_TIER\": \"int64\",\n",
    "    \"C_DOB\": \"str\",\n",
    "    \"C_ADLINE1\": \"str\",\n",
    "    \"C_ADLINE2\": \"str\",\n",
    "    \"C_ZIPCODE\": \"str\",\n",
    "    \"C_CITY\": \"str\",\n",
    "    \"C_STATE_PROV\": \"str\",\n",
    "    \"C_CTRY\": \"str\",\n",
    "    \"C_CTRY_1\": \"str\",\n",
    "    \"C_AREA_1\": \"str\",\n",
    "    \"C_LOCAL_1\": \"str\",\n",
    "    \"C_EXT_1\": \"str\",\n",
    "    \"C_CTRY_2\": \"str\",\n",
    "    \"C_AREA_2\": \"str\",\n",
    "    \"C_LOCAL_2\": \"str\",\n",
    "    \"C_EXT_2\": \"str\",\n",
    "    \"C_CTRY_3\": \"str\",\n",
    "    \"C_AREA_3\": \"str\",\n",
    "    \"C_LOCAL_3\": \"str\",\n",
    "    \"C_EXT_3\": \"str\",\n",
    "    \"C_EMAIL_1\": \"str\",\n",
    "    \"C_EMAIL_2\": \"str\",\n",
    "    \"C_LCL_TX_ID\": \"str\",\n",
    "    \"C_NAT_TX_ID\": \"str\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the file\n",
    "file_path = DATA_DIR + \"Customer.txt\"\n",
    "df = pd.read_csv(file_path, sep='|', header=None, names=column_names, dtype=data_types, parse_dates=[\"C_DOB\"])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    \"C_ID\": \"CustomerID\",\n",
    "    \"C_TAX_ID\": \"TaxID\",\n",
    "    \"C_L_NAME\": \"LastName\",\n",
    "    \"C_F_NAME\": \"FirstName\",\n",
    "    \"C_M_NAME\": \"MiddleInitial\",\n",
    "    \"C_TIER\": \"Tier\",\n",
    "    \"C_DOB\": \"DOB\",\n",
    "    \"C_EMAIL_1\": \"Email1\",\n",
    "    \"C_EMAIL_2\": \"Email2\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['C_GNDR'].str.upper()\n",
    "df.loc[~df['Gender'].isin(['M', 'F']), 'Gender'] = 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    \"C_ADLINE1\": \"AddressLine1\",\n",
    "    \"C_ADLINE2\": \"AddressLine2\",\n",
    "    \"C_ZIPCODE\": \"PostalCode\",\n",
    "    \"C_CITY\": \"City\",\n",
    "    \"C_STATE_PROV\": \"StateProv\",\n",
    "    \"C_CTRY\": \"Country\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status is copied from ST_NAME of the StatusType table by matching C_ST_ID with ST_ID of the StatusType table.\n",
    "status_mapping = pd.read_sql_query(\"SELECT ST_ID AS C_ST_ID, ST_NAME from StatusType\", engine).set_index(\"C_ST_ID\")[\"ST_NAME\"].to_dict()\n",
    "df.loc[:, \"Status\"] = df.loc[:, \"C_ST_ID\"].map(status_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_phone_number(row, i):\n",
    "    # Extract components of the phone number\n",
    "    ctry_code = row[f\"C_CTRY_{i}\"]\n",
    "    area_code = row[f\"C_AREA_{i}\"]\n",
    "    local = row[f\"C_LOCAL_{i}\"]\n",
    "    ext = row[f\"C_EXT_{i}\"]        \n",
    "\n",
    "    if pd.isna(ctry_code):\n",
    "        ctry_code = None\n",
    "    if pd.isna(area_code):\n",
    "        area_code = None\n",
    "    if pd.isna(local):\n",
    "        local = None\n",
    "    if pd.isna(ext):\n",
    "        ext = None\n",
    "\n",
    "    # Apply transformation rules\n",
    "    if ctry_code and area_code and local:\n",
    "        phone = f\"+{ctry_code} ({area_code}) {local}\"\n",
    "    elif area_code and local:\n",
    "        phone = f\"({area_code}) {local}\"\n",
    "    elif local:\n",
    "        phone = local\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Add extension if present\n",
    "    if ext:\n",
    "        phone += f\"{ext}\"\n",
    "\n",
    "    return phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    df[f'Phone{i}'] = df.apply(format_phone_number, axis=1, args=(i, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_info = pd.read_sql_query(\"SELECT TX_ID, TX_NAME, TX_RATE FROM TaxRate\", engine).set_index('TX_ID')\n",
    "tax_name_mapping = tax_info['TX_NAME'].to_dict()\n",
    "tax_rate_mapping = tax_info['TX_RATE'].to_dict()\n",
    "\n",
    "# NationalTaxRateDesc and NationalTaxRate are copied from TX_NAME and TX_RATE respectively by matching C_NAT_TX_ID with TX_ID.\n",
    "df.loc[:, 'NationalTaxRateDesc'] = df.loc[:, 'C_NAT_TX_ID'].map(tax_name_mapping)\n",
    "df.loc[:, 'NationalTaxRate'] = df.loc[:, 'C_NAT_TX_ID'].map(tax_rate_mapping)\n",
    "\n",
    "# LocalTaxRateDesc and LocalTaxRate are copied from TX_NAME and TX_RATE respectively by matching C_LCL_TX_ID with TX_ID.\n",
    "df.loc[:, 'LocalTaxRateDesc'] = df.loc[:, 'C_LCL_TX_ID'].map(tax_name_mapping)\n",
    "df.loc[:, 'LocalTaxRate'] = df.loc[:, 'C_LCL_TX_ID'].map(tax_rate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'IsCurrent'] = 1\n",
    "df.loc[:, 'EffectiveDate'] = pd.to_datetime(BATCH_DATE)\n",
    "df.loc[:, 'EndDate'] = pd.Timestamp(\"9999-12-31\")\n",
    "df.loc[:, 'BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Prospect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prospect_file(filepath):\n",
    "    # Define the column names and their data types\n",
    "    columns = [\n",
    "        'AgencyID', 'LastName', 'FirstName', 'MiddleInitial', 'Gender', \n",
    "        'AddressLine1', 'AddressLine2', 'PostalCode', 'City', 'State', \n",
    "        'Country', 'Phone', 'Income', 'NumberCars', 'NumberChildren', \n",
    "        'MaritalStatus', 'Age', 'CreditRating', 'OwnOrRentFlag', \n",
    "        'Employer', 'NumberCreditCards', 'NetWorth'\n",
    "    ]\n",
    "\n",
    "    # Define the data types for reading the file\n",
    "    dtypes = {\n",
    "        'AgencyID': 'str', 'LastName': 'str', 'FirstName': 'str', \n",
    "        'MiddleInitial': 'str', 'Gender': 'str', 'AddressLine1': 'str', \n",
    "        'AddressLine2': 'str', 'PostalCode': 'str', 'City': 'str', \n",
    "        'State': 'str', 'Country': 'str', 'Phone': 'str', \n",
    "        'Income': 'Int64', 'NumberCars': 'Int8', 'NumberChildren': 'Int8', \n",
    "        'MaritalStatus': 'str', 'Age': 'Int8', 'CreditRating': 'Int16', \n",
    "        'OwnOrRentFlag': 'str', 'Employer': 'str', \n",
    "        'NumberCreditCards': 'Int8', 'NetWorth': 'Int64'\n",
    "    }\n",
    "\n",
    "    # Read the CSV file\n",
    "    raw_prospect_df = pd.read_csv(\n",
    "        filepath, \n",
    "        header=None, \n",
    "        names=columns, \n",
    "        dtype=dtypes\n",
    "    )\n",
    "\n",
    "    return raw_prospect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prospect_df = read_prospect_file(DATA_DIR + \"Prospect.csv\")\n",
    "raw_prospect_df.info()\n",
    "raw_prospect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_cols = ['LastName', 'FirstName', 'City', 'State']\n",
    "for col in not_null_cols:\n",
    "    raw_prospect_df.loc[raw_prospect_df[col].isna(), col] = ''\n",
    "raw_prospect_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'AgencyID': 'str',\n",
    "    'SK_RecordDateID': 'uint32',\n",
    "    'SK_UpdateDateID': 'uint32',\n",
    "    'BatchID': 'uint16',\n",
    "    'IsCustomer': 'boolean',\n",
    "    'LastName': 'str',\n",
    "    'FirstName': 'str',\n",
    "    'MiddleInitial': 'str',\n",
    "    'Gender': 'str',\n",
    "    'AddressLine1': 'str',\n",
    "    'AddressLine2': 'str',\n",
    "    'PostalCode': 'str',\n",
    "    'City': 'str',\n",
    "    'State': 'str',\n",
    "    'Country': 'str',\n",
    "    'Phone': 'str',\n",
    "    'Income': 'uint32',\n",
    "    'NumberCars': 'uint8',\n",
    "    'NumberChildren': 'uint8',\n",
    "    'MaritalStatus': 'str',\n",
    "    'Age': 'uint8',\n",
    "    'CreditRating': 'uint16',\n",
    "    'OwnOrRentFlag': 'str',\n",
    "    'Employer': 'str',\n",
    "    'NumberCreditCards': 'uint8',\n",
    "    'NetWorth': 'int64',\n",
    "    'MarketingNameplate': 'str'\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame with the specified schema\n",
    "prospect_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in dtypes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df[\"AgencyID\"] = raw_prospect_df[\"AgencyID\"]\n",
    "prospect_df[\"LastName\"] = raw_prospect_df[\"LastName\"]\n",
    "prospect_df[\"FirstName\"] = raw_prospect_df[\"FirstName\"]\n",
    "prospect_df[\"MiddleInitial\"] = raw_prospect_df[\"MiddleInitial\"]\n",
    "prospect_df[\"Gender\"] = raw_prospect_df[\"Gender\"]\n",
    "# fix data quality issues\n",
    "prospect_df['Gender'] = prospect_df['Gender'].str.upper()\n",
    "mask = ~prospect_df['Gender'].isin([\"M\", \"F\"])\n",
    "prospect_df.loc[mask, \"Gender\"] = \"U\"\n",
    "prospect_df[\"AddressLine1\"] = raw_prospect_df[\"AddressLine1\"]\n",
    "prospect_df[\"AddressLine2\"] = raw_prospect_df[\"AddressLine2\"]\n",
    "prospect_df[\"PostalCode\"] = raw_prospect_df[\"PostalCode\"]\n",
    "prospect_df[\"City\"] = raw_prospect_df[\"City\"]\n",
    "prospect_df[\"State\"] = raw_prospect_df[\"State\"]\n",
    "prospect_df[\"Country\"] = raw_prospect_df[\"Country\"]\n",
    "prospect_df[\"Phone\"] = raw_prospect_df[\"Phone\"]\n",
    "prospect_df[\"Income\"] = raw_prospect_df[\"Income\"]\n",
    "prospect_df[\"NumberCars\"] = raw_prospect_df[\"NumberCars\"]\n",
    "prospect_df[\"NumberChildren\"] = raw_prospect_df[\"NumberChildren\"]\n",
    "prospect_df[\"MaritalStatus\"] = raw_prospect_df[\"MaritalStatus\"]\n",
    "prospect_df[\"MaritalStatus\"] = prospect_df[\"MaritalStatus\"].str.upper()\n",
    "mask = ~prospect_df[\"MaritalStatus\"].isin([\"S\", \"M\", \"D\", \"W\"])\n",
    "prospect_df.loc[mask, \"MaritalStatus\"] = \"U\"\n",
    "prospect_df[\"Age\"] = raw_prospect_df[\"Age\"]\n",
    "prospect_df[\"CreditRating\"] = raw_prospect_df[\"CreditRating\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = raw_prospect_df[\"OwnOrRentFlag\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = prospect_df[\"OwnOrRentFlag\"].str.upper()\n",
    "mask = ~prospect_df[\"OwnOrRentFlag\"].isin([\"O\", \"R\"])\n",
    "prospect_df.loc[mask, \"OwnOrRentFlag\"] = \"U\"\n",
    "prospect_df[\"Employer\"] = raw_prospect_df[\"Employer\"]\n",
    "prospect_df[\"NumberCreditCards\"] = raw_prospect_df[\"NumberCreditCards\"]\n",
    "prospect_df[\"NetWorth\"] = raw_prospect_df[\"NetWorth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_dateid = pd.read_sql_query(f\"SELECT SK_DateID FROM DimDate where DateValue = '{BATCH_DATE}'\", engine).iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load old data from MySQL\n",
    "old_prospect_df = pd.read_sql('SELECT * FROM Prospect', engine)\n",
    "\n",
    "# Merge new and old data on AgencyID\n",
    "merged_df = pd.merge(prospect_df, old_prospect_df, on='AgencyID', suffixes=('_new', '_old'), how='left')\n",
    "\n",
    "# List of fields to compare\n",
    "fields_to_compare = ['LastName', 'FirstName', 'MiddleInitial', 'Gender', 'AddressLine1', 'AddressLine2',\n",
    "                     'PostalCode', 'City', 'State', 'Country', 'Phone', 'Income', 'NumberCars',\n",
    "                     'NumberChildren', 'MaritalStatus', 'Age', 'CreditRating', 'OwnOrRentFlag',\n",
    "                     'Employer', 'NumberCreditCards', 'NetWorth']\n",
    "\n",
    "# Identify changed records\n",
    "is_changed = merged_df[[f + '_new' for f in fields_to_compare]] != merged_df[[f + '_old' for f in fields_to_compare]].values\n",
    "has_changed = is_changed.any(axis=1)\n",
    "# only update the records if the left join succeeded\n",
    "same_agency_id = ~merged_df['SK_UpdateDateID_old'].isna()\n",
    "\n",
    "# Update SK_UpdateDateID for changed records\n",
    "merged_df.loc[(has_changed) & (same_agency_id), 'SK_UpdateDateID_new'] = sk_dateid\n",
    "# the old ones keep the old SK_UpdateDateID\n",
    "merged_df.loc[(~has_changed) & (same_agency_id), 'SK_UpdateDateID_new'] = merged_df.loc[(~has_changed) & (same_agency_id), 'SK_UpdateDateID_old']\n",
    "\n",
    "# For new records (those that are NaN in old data), set SK_UpdateDateID to batch_date_sk\n",
    "is_new_record = merged_df['SK_UpdateDateID_old'].isna()\n",
    "merged_df.loc[is_new_record, 'SK_UpdateDateID_new'] = sk_dateid\n",
    "\n",
    "# Finalize the DataFrame with updated SK_UpdateDateID\n",
    "prospect_df_updated = merged_df[['AgencyID'] + [f + '_new' for f in fields_to_compare] + ['SK_UpdateDateID_new']]\n",
    "\n",
    "# rename cols\n",
    "cols = prospect_df_updated.columns.tolist()\n",
    "cols = {col: col.replace(\"_new\", \"\") for col in cols}\n",
    "prospect_df_updated.rename(columns=cols, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SK_RecordDateID is set to the DimDate SK_DateID field that corresponds to the Batch Date.\n",
    "prospect_df_updated['SK_RecordDateID'] = sk_dateid\n",
    "prospect_df_updated['SK_RecordDateID'] = prospect_df_updated['SK_RecordDateID'].astype('uint32')\n",
    "\n",
    "prospect_df_updated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions for each tag with null checks\n",
    "conditions = {\n",
    "    \"HighValue\": (prospect_df_updated[\"NetWorth\"].notnull() & prospect_df_updated[\"Income\"].notnull())\n",
    "    & ((prospect_df_updated[\"NetWorth\"] > 1_000_000) | (prospect_df_updated[\"Income\"] > 200_000)),\n",
    "    \"Expenses\": (\n",
    "        prospect_df_updated[\"NumberChildren\"].notnull()\n",
    "        & prospect_df_updated[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df_updated[\"NumberChildren\"] > 3) | (prospect_df_updated[\"NumberCreditCards\"] > 5)),\n",
    "    \"Boomer\": prospect_df_updated[\"Age\"].notnull() & (prospect_df_updated[\"Age\"] > 45),\n",
    "    \"MoneyAlert\": (\n",
    "        prospect_df_updated[\"Income\"].notnull()\n",
    "        & prospect_df_updated[\"CreditRating\"].notnull()\n",
    "        & prospect_df_updated[\"NetWorth\"].notnull()\n",
    "    )\n",
    "    & (\n",
    "        (prospect_df_updated[\"Income\"] < 50_000)\n",
    "        | (prospect_df_updated[\"CreditRating\"] < 600)\n",
    "        | (prospect_df_updated[\"NetWorth\"] < 100_000)\n",
    "    ),\n",
    "    \"Spender\": (\n",
    "        prospect_df_updated[\"NumberCars\"].notnull() & prospect_df_updated[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df_updated[\"NumberCars\"] > 3) | (prospect_df_updated[\"NumberCreditCards\"] > 7)),\n",
    "    \"Inherited\": (prospect_df_updated[\"Age\"].notnull() & prospect_df_updated[\"NetWorth\"].notnull())\n",
    "    & ((prospect_df_updated[\"Age\"] < 25) & (prospect_df_updated[\"NetWorth\"] > 1_000_000)),\n",
    "}\n",
    "\n",
    "# Apply conditions to assign tags\n",
    "prospect_df_updated[\"MarketingNameplate\"] = \"\"\n",
    "for tag, condition in conditions.items():\n",
    "    prospect_df_updated[\"MarketingNameplate\"] += np.where(condition, tag + \"+\", \"\")\n",
    "\n",
    "# Remove trailing '+' and replace empty strings with None\n",
    "prospect_df_updated[\"MarketingNameplate\"] = (\n",
    "    prospect_df_updated[\"MarketingNameplate\"].str.rstrip(\"+\").replace(\"\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df_updated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df_updated['BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Update Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary prospect_df for matching\n",
    "prospect_df_temp = prospect_df_updated[\n",
    "    [\n",
    "        \"AgencyID\",\n",
    "        \"CreditRating\",\n",
    "        \"NetWorth\",\n",
    "        \"MarketingNameplate\",\n",
    "        \"LastName\",\n",
    "        \"FirstName\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "    ]\n",
    "].copy()\n",
    "prospect_df_temp[\"LastName\"] = prospect_df_temp[\"LastName\"].str.upper()\n",
    "prospect_df_temp[\"FirstName\"] = prospect_df_temp[\"FirstName\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine1\"] = prospect_df_temp[\"AddressLine1\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine2\"] = prospect_df_temp[\"AddressLine2\"].str.upper()\n",
    "prospect_df_temp[\"PostalCode\"] = prospect_df_temp[\"PostalCode\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    # first check previous batch\n",
    "    first_name, last_name = row['FirstName'].upper(), row[\"LastName\"].upper()\n",
    "    address1, address2 = row['AddressLine1'], row[\"AddressLine2\"]\n",
    "    postcode = row['PostalCode']\n",
    "    if not pd.isna(address1):\n",
    "        address1 = address1.upper()\n",
    "    if not pd.isna(address2):\n",
    "        address2 = address1.upper()\n",
    "    if not pd.isna(postcode):\n",
    "        postcode = postcode.upper()\n",
    "    \n",
    "    query = f\"\"\"SELECT AgencyID, CreditRating, NetWorth, MarketingNameplate FROM Prospect\n",
    "    WHERE UPPER(FirstName) = '{first_name}' AND UPPER(LastName) = '{last_name}'\"\"\"\n",
    "    if pd.isna(row['AddressLine1']):\n",
    "        query += \" AND AddressLine1 IS NULL\"\n",
    "    else:\n",
    "        query += f\" AND UPPER(AddressLine1) = '{address1}'\"\n",
    "    if pd.isna(row['AddressLine2']):\n",
    "        query += \" AND AddressLine2 IS NULL\"\n",
    "    else:\n",
    "        query += f\" AND UPPER(AddressLine2) = '{address2}'\"\n",
    "    if pd.isna(row['PostalCode']):\n",
    "        query += \" AND PostalCode IS NULL;\"\n",
    "    else:\n",
    "        query += f\" AND UPPER(PostalCode) = '{postcode}';\"\n",
    "\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    if len(result) > 0:\n",
    "        df.loc[index, \"AgencyID\"] = result.iloc[0, 0]\n",
    "        df.loc[index, \"CreditRating\"] = result.iloc[0, 1]\n",
    "        df.loc[index, \"NetWorth\"] = result.iloc[0, 2]\n",
    "        df.loc[index, \"MarketingNameplate\"] = result.iloc[0, 3]\n",
    "    else:\n",
    "        # check current batch\n",
    "        match = prospect_df_temp[\n",
    "            (prospect_df_temp[\"LastName\"] == last_name)\n",
    "            & (prospect_df_temp[\"FirstName\"] == first_name)\n",
    "            & (prospect_df_temp[\"AddressLine1\"] == address1)\n",
    "            & (prospect_df_temp[\"AddressLine2\"] == address2)\n",
    "            & (prospect_df_temp[\"PostalCode\"] == postcode)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            df.loc[index, \"AgencyID\"] = match[\"AgencyID\"].iloc[-1]\n",
    "            df.loc[index, \"CreditRating\"] = match[\"CreditRating\"].iloc[-1]\n",
    "            df.loc[index, \"NetWorth\"] = match[\"NetWorth\"].iloc[-1]\n",
    "            df.loc[index, \"MarketingNameplate\"] = match[\"MarketingNameplate\"].iloc[-1]\n",
    "        else:\n",
    "            # set empty\n",
    "            df.loc[index, \"AgencyID\"] = None\n",
    "            df.loc[index, \"CreditRating\"] = None\n",
    "            df.loc[index, \"NetWorth\"] = None\n",
    "            df.loc[index, \"MarketingNameplate\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sk = pd.read_sql_query('SELECT MAX(SK_CustomerID) FROM dimCustomer', engine).iloc[0, 0]\n",
    "df.loc[:, 'SK_CustomerID'] = range(max_sk + 1, max_sk + 1 + len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A record will be reported in the DImessages table if a customers Tier is not one of the valid\n",
    "values (1,2,3). The MessageSource is DimCustomer, the MessageType is Alert and the\n",
    "MessageText is Invalid customer tier. The MessageData field is C_ID =  followed by the\n",
    "key value of the record, then , C_TIER =  and the C_TIER value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_tiers = df[~df['Tier'].isin([1,2,3])][[\"CustomerID\", \"Tier\"]]\n",
    "if len(invalid_tiers) > 0:\n",
    "    invalid_tiers.loc[:, \"MessageDateAndTime\"] = datetime.now()\n",
    "    invalid_tiers['BatchID'] = BATCH_ID\n",
    "    invalid_tiers['MessageSource'] = 'DimCustomer'\n",
    "    invalid_tiers['MessageText'] = 'Invalid customer tier'\n",
    "    invalid_tiers['MessageType'] = 'Alert'\n",
    "    invalid_tiers['MessageData'] = \"C_ID = \" + invalid_tiers[\"CustomerID\"].astype(str) + \", C_TIER = \" + invalid_tiers[\"Tier\"].astype(str)\n",
    "    \n",
    "    sql_dtypes = {\n",
    "        \"MessageDateAndTime\": sqlalchemy.types.DATETIME,\n",
    "        \"BatchID\": sqlalchemy.types.Integer,\n",
    "        \"MessageSource\": sqlalchemy.types.CHAR(30),\n",
    "        \"MessageText\": sqlalchemy.types.CHAR(50),\n",
    "        \"MessageType\": sqlalchemy.types.CHAR(12),\n",
    "        \"MessageData\": sqlalchemy.types.CHAR(100)\n",
    "    }\n",
    "    invalid_tiers.to_sql('dimessages', con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A record will be reported in the DImessages table if a customers DOB is invalid. A customers\n",
    "DOB is invalid if DOB < Batch Date  100 years or DOB > Batch Date (customer over 100 years\n",
    "old or born in the future). The MessageSource is DimCustomer, the MessageType is Alert\n",
    "and the MessageText is DOB out of range. The MessageData field is C_ID =  followed by\n",
    "the key value of the record, then , C_DOB =  and the C_DOB value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dobs = df[(df['DOB'] < BATCH_DATE - pd.Timedelta(days=100*365)) | (df['DOB'] > BATCH_DATE + pd.Timedelta(days=100*365))]\n",
    "if len(invalid_dobs) > 0:\n",
    "    invalid_dobs.loc[:, \"MessageDateAndTime\"] = datetime.now()\n",
    "    invalid_dobs['BatchID'] = BATCH_ID\n",
    "    invalid_dobs['MessageSource'] = 'DimCustomer'\n",
    "    invalid_dobs['MessageText'] = 'DOB out of range'\n",
    "    invalid_dobs['MessageType'] = 'Alert'\n",
    "    invalid_dobs['MessageData'] = \"C_ID = \" + invalid_tiers[\"CustomerID\"].astype(str) + \", C_DOB = \" + invalid_tiers[\"DOB\"].astype(str)\n",
    "    \n",
    "    sql_dtypes = {\n",
    "        \"MessageDateAndTime\": sqlalchemy.types.DATETIME,\n",
    "        \"BatchID\": sqlalchemy.types.Integer,\n",
    "        \"MessageSource\": sqlalchemy.types.CHAR(30),\n",
    "        \"MessageText\": sqlalchemy.types.CHAR(50),\n",
    "        \"MessageType\": sqlalchemy.types.CHAR(12),\n",
    "        \"MessageData\": sqlalchemy.types.CHAR(100)\n",
    "    }\n",
    "    invalid_dobs.to_sql('dimessages', con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_customers_mask = df['CDC_FLAG'] == 'I'\n",
    "keep_cols = [\n",
    "    \"SK_CustomerID\", \"CustomerID\", \"TaxID\", \"Status\", \"LastName\", \n",
    "    \"FirstName\", \"MiddleInitial\", \"Gender\", \"Tier\", \"DOB\", \n",
    "    \"AddressLine1\", \"AddressLine2\", \"PostalCode\", \"City\", \"StateProv\", \n",
    "    \"Country\", \"Phone1\", \"Phone2\", \"Phone3\", \"Email1\", \n",
    "    \"Email2\", \"NationalTaxRateDesc\", \"NationalTaxRate\", \"LocalTaxRateDesc\", \n",
    "    \"LocalTaxRate\", \"AgencyID\", \"CreditRating\", \"NetWorth\", \"MarketingNameplate\", \n",
    "    \"IsCurrent\", \"BatchID\", \"EffectiveDate\", \"EndDate\"\n",
    "]\n",
    "df_insert = df.loc[insert_customers_mask, keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'CustomerID': sqlalchemy.types.Integer,\n",
    "    'TaxID': sqlalchemy.types.String(20),\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'LastName': sqlalchemy.types.String(30),\n",
    "    'FirstName': sqlalchemy.types.String(30),\n",
    "    'MiddleInitial': sqlalchemy.types.String(1),\n",
    "    'Gender': sqlalchemy.types.String(1),\n",
    "    'Tier': sqlalchemy.types.SmallInteger,\n",
    "    'DOB': sqlalchemy.types.Date,\n",
    "    'AddressLine1': sqlalchemy.types.String(80),\n",
    "    'AddressLine2': sqlalchemy.types.String(80),\n",
    "    'PostalCode': sqlalchemy.types.String(12),\n",
    "    'City': sqlalchemy.types.String(25),\n",
    "    'StateProv': sqlalchemy.types.String(20),\n",
    "    'Country': sqlalchemy.types.String(24),\n",
    "    'Phone1': sqlalchemy.types.String(30),\n",
    "    'Phone2': sqlalchemy.types.String(30),\n",
    "    'Phone3': sqlalchemy.types.String(30),\n",
    "    'Email1': sqlalchemy.types.String(50),\n",
    "    'Email2': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'LocalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'LocalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'AgencyID': sqlalchemy.types.String(30),\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.Numeric(10),\n",
    "    'MarketingNameplate': sqlalchemy.types.String(100),\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}\n",
    "df_insert.to_sql('dimcustomer', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_customers_mask = df['CDC_FLAG'] == 'U'\n",
    "keep_cols = [\n",
    "    \"SK_CustomerID\", \"CustomerID\", \"TaxID\", \"Status\", \"LastName\", \n",
    "    \"FirstName\", \"MiddleInitial\", \"Gender\", \"Tier\", \"DOB\", \n",
    "    \"AddressLine1\", \"AddressLine2\", \"PostalCode\", \"City\", \"StateProv\", \n",
    "    \"Country\", \"Phone1\", \"Phone2\", \"Phone3\", \"Email1\", \n",
    "    \"Email2\", \"NationalTaxRateDesc\", \"NationalTaxRate\", \"LocalTaxRateDesc\", \n",
    "    \"LocalTaxRate\", \"AgencyID\", \"CreditRating\", \"NetWorth\", \"MarketingNameplate\", \n",
    "    \"IsCurrent\", \"BatchID\", \"EffectiveDate\", \"EndDate\"\n",
    "]\n",
    "df_update = df.loc[update_customers_mask, keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(df_update.iterrows(), total=df_update.shape[0]):\n",
    "    customer_id = row['CustomerID']\n",
    "    required_rows = df_update[df_update['CustomerID'].isin([customer_id])]\n",
    "    # only one update per day\n",
    "    if len(required_rows) > 1 and index != required_rows.index[-1]:\n",
    "        continue\n",
    "    effective_date = row['EffectiveDate']\n",
    "\n",
    "    # Obtain the current SK_CustomerID from dimCustomer\n",
    "    current_customer = pd.read_sql_query(\n",
    "        f\"SELECT SK_CustomerID, Status FROM dimCustomer WHERE IsCurrent = 1 AND CustomerID = {customer_id}\",\n",
    "        engine\n",
    "    )\n",
    "\n",
    "    sk_customer_id = current_customer['SK_CustomerID'].iloc[0]\n",
    "    customer_status = current_customer['Status'].iloc[0]\n",
    "\n",
    "    # Find all current records in dimAccount with the obtained SK_CustomerID\n",
    "    current_accounts = pd.read_sql_query(\n",
    "        f\"SELECT * FROM dimAccount WHERE IsCurrent = 1 AND SK_CustomerID = {sk_customer_id}\",\n",
    "        engine\n",
    "    )\n",
    "\n",
    "    # Update these records by setting IsCurrent to 0 and EndDate to effective_date\n",
    "    update_query = f\"\"\"\n",
    "    UPDATE dimAccount\n",
    "    SET IsCurrent = 0, EndDate = '{effective_date}'\n",
    "    WHERE IsCurrent = 1 AND SK_CustomerID = {sk_customer_id};\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(update_query))\n",
    "        connection.commit()\n",
    "    # Prepare new account records\n",
    "    new_accounts = current_accounts.copy()\n",
    "    new_accounts['EffectiveDate'] = effective_date\n",
    "    new_accounts['EndDate'] = pd.Timestamp(\"9999-12-31\")\n",
    "    new_accounts['Status'] = new_accounts['Status'].apply(lambda x: 'INACTIVE' if customer_status == 'INACTIVE' else x)\n",
    "    new_accounts['IsCurrent'] = 1\n",
    "    new_accounts['BatchID'] = BATCH_ID\n",
    "    max_sk = pd.read_sql(\"SELECT MAX(SK_AccountID) FROM dimAccount\", engine).iloc[0, 0]\n",
    "    new_accounts[\"SK_AccountID\"] = range(max_sk + 1, max_sk + 1 + new_accounts.shape[0])\n",
    "\n",
    "    # Bulk insert new account records\n",
    "    new_accounts.to_sql('dimaccount', con=engine, if_exists='append', index=False, dtype={\n",
    "        'SK_AccountID': sqlalchemy.types.Integer,\n",
    "        'AccountID': sqlalchemy.types.Integer,\n",
    "        'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "        'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "        'Status': sqlalchemy.types.String(10),\n",
    "        'AccountDesc': sqlalchemy.types.String(50),\n",
    "        'TaxStatus': sqlalchemy.types.SmallInteger,\n",
    "        'IsCurrent': sqlalchemy.types.Boolean,\n",
    "        'BatchID': sqlalchemy.types.SmallInteger,\n",
    "        'EffectiveDate': sqlalchemy.types.Date,\n",
    "        'EndDate': sqlalchemy.types.Date\n",
    "    })\n",
    "\n",
    "    # History-tracking update for the customer\n",
    "    history_update_query = f\"\"\"\n",
    "    UPDATE dimCustomer\n",
    "    SET IsCurrent = 0, EndDate = '{effective_date}'\n",
    "    WHERE IsCurrent = 1 AND CustomerID = {customer_id};\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(history_update_query))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to the appropriate types\n",
    "df_update['SK_CustomerID'] = df_update['SK_CustomerID'].astype(np.int32)\n",
    "df_update['CustomerID'] = df_update['CustomerID'].astype(np.int32)\n",
    "df_update['Tier'] = df_update['Tier'].astype(pd.Int8Dtype())\n",
    "df_update['NationalTaxRate'] = df_update['NationalTaxRate'].astype(np.float64)\n",
    "df_update['LocalTaxRate'] = df_update['LocalTaxRate'].astype(np.float64)\n",
    "df_update['CreditRating'] = df_update['CreditRating'].astype(pd.Int16Dtype())\n",
    "df_update['NetWorth'] = df_update['NetWorth'].astype(pd.Float64Dtype())\n",
    "df_update['BatchID'] = df_update['BatchID'].astype(np.int16)\n",
    "\n",
    "# Convert date columns to datetime.date\n",
    "df_update['DOB'] = pd.to_datetime(df_update['DOB']).dt.date\n",
    "df_update['EffectiveDate'] = pd.to_datetime(df_update['EffectiveDate']).dt.date\n",
    "df_update['EndDate'] = pd.to_datetime(df_update['EndDate']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update.to_sql('dimcustomer', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_customers = pd.read_sql_query(\"\"\"SELECT UPPER(FirstName) FirstName , UPPER(LastName) LastName, UPPER(AddressLine1) AddressLine1,\n",
    "UPPER(AddressLine2) AddressLine2, UPPER(PostalCode) PostalCode FROM dimCustomer WHERE IsCurrent = 1 AND Status = 'ACTIVE';\"\"\", engine)\n",
    "active_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary uppercase columns for merging in both DataFrames\n",
    "merge_fields = [\"FirstName\", \"LastName\", \"AddressLine1\", \"AddressLine2\", \"PostalCode\"]\n",
    "merged_df = prospect_df_temp.merge(active_customers, how='left', on=merge_fields, indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = merged_df['_merge'] == 'both'\n",
    "prospect_df_updated.loc[:, 'IsCustomer'] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df_updated['SK_UpdateDateID'] = prospect_df_updated['SK_UpdateDateID'].astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_ids = pd.read_sql_query(\"SELECT DISTINCT AgencyID FROM Prospect\", engine).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_records = prospect_df_updated[prospect_df_updated['AgencyID'].isin(agency_ids)]\n",
    "new_records = prospect_df_updated[~prospect_df_updated['AgencyID'].isin(agency_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the MySQL table 'prospect'\n",
    "prospect_df = pd.read_sql_table('prospect', con=engine)\n",
    "\n",
    "# Merge the DataFrame with the MySQL table data on 'AgencyID'\n",
    "merged_df = pd.merge(existing_records, prospect_df, on='AgencyID', suffixes=('_existing', '_prospect'))\n",
    "\n",
    "# Define a function to compare rows, treating NaNs as equal\n",
    "def compare_rows(row, columns):\n",
    "    for col in columns:\n",
    "        # Both values are NaN\n",
    "        if pd.isna(row[col + '_existing']) and pd.isna(row[col + '_prospect']):\n",
    "            continue\n",
    "        # One value is NaN and the other is not\n",
    "        elif pd.isna(row[col + '_existing']) or pd.isna(row[col + '_prospect']):\n",
    "            return False\n",
    "        # Both values are not NaN, but are different\n",
    "        elif row[col + '_existing'] != row[col + '_prospect']:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Filter to find records where all columns are the same except 'IsCustomer'\n",
    "filter_columns = [col.replace('_existing', '') for col in merged_df.columns if 'IsCustomer' not in col and '_existing' in col]\n",
    "diff_is_customer = merged_df[merged_df.apply(lambda row: compare_rows(row, filter_columns) and (pd.isna(row['IsCustomer_existing']) != pd.isna(row['IsCustomer_prospect']) or row['IsCustomer_existing'] != row['IsCustomer_prospect']), axis=1)]\n",
    "\n",
    "# Count these records\n",
    "count_diff_is_customer = diff_is_customer.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'AgencyID': sqlalchemy.types.CHAR(30),\n",
    "    'SK_RecordDateID': sqlalchemy.types.Integer,\n",
    "    'SK_UpdateDateID': sqlalchemy.types.Integer,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'IsCustomer': sqlalchemy.types.Boolean,\n",
    "    'LastName': sqlalchemy.types.CHAR(30),\n",
    "    'FirstName': sqlalchemy.types.CHAR(30),\n",
    "    'MiddleInitial': sqlalchemy.types.CHAR(1),\n",
    "    'Gender': sqlalchemy.types.CHAR(1),\n",
    "    'AddressLine1': sqlalchemy.types.CHAR(80),\n",
    "    'AddressLine2': sqlalchemy.types.CHAR(80),\n",
    "    'PostalCode': sqlalchemy.types.CHAR(12),\n",
    "    'City': sqlalchemy.types.CHAR(25),\n",
    "    'State': sqlalchemy.types.CHAR(20),\n",
    "    'Country': sqlalchemy.types.CHAR(24),\n",
    "    'Phone': sqlalchemy.types.CHAR(30),\n",
    "    'Income': sqlalchemy.types.Integer,\n",
    "    'NumberCars': sqlalchemy.types.SmallInteger,\n",
    "    'NumberChildren': sqlalchemy.types.SmallInteger,\n",
    "    'MaritalStatus': sqlalchemy.types.CHAR(1),\n",
    "    'Age': sqlalchemy.types.SmallInteger,\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'OwnOrRentFlag': sqlalchemy.types.CHAR(1),\n",
    "    'Employer': sqlalchemy.types.CHAR(30),\n",
    "    'NumberCreditCards': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.BigInteger,\n",
    "    'MarketingNameplate': sqlalchemy.types.CHAR(100)\n",
    "}\n",
    "\n",
    "new_records.to_sql('prospect', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    for _, row in tqdm(existing_records.iterrows(), total=existing_records.shape[0]):\n",
    "        agencyid = row['AgencyID']\n",
    "        query_parts = []\n",
    "        for key, value in row.to_dict().items():\n",
    "            if key != 'AgencyID':\n",
    "                if pd.isna(value):\n",
    "                    query_part = f\"{key} = NULL\"\n",
    "                elif isinstance(value, str):\n",
    "                    value = value.replace('\"', '\\\\\"')\n",
    "                    query_part = f\"{key} = \\\"{value}\\\"\"\n",
    "                else:  # for numeric and boolean types\n",
    "                    query_part = f\"{key} = {value}\"\n",
    "                query_parts.append(query_part)\n",
    "        query = f\"UPDATE prospect SET {', '.join(query_parts)} WHERE AgencyID = \\\"{agencyid}\\\"\"\n",
    "        connection.execute(text(query))\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = prospect_df_updated.shape[0]\n",
    "message_type = \"Status\"\n",
    "message_source = \"Prospect\"\n",
    "message_text = \"Source rows\"\n",
    "MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "\n",
    "query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {BATCH_ID}, '{message_source}', '{message_text}', '{message_type}', '{num_rows}')\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = new_records.shape[0]\n",
    "message_type = \"Status\"\n",
    "message_source = \"Prospect\"\n",
    "message_text = \"Inserted rows\"\n",
    "MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "\n",
    "query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {BATCH_ID}, '{message_source}', '{message_text}', '{message_type}', '{num_rows}')\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_rows = existing_records.shape[0] - count_diff_is_customer\n",
    "message_type = \"Status\"\n",
    "message_source = \"Prospect\"\n",
    "message_text = \"Updated rows\"\n",
    "MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "\n",
    "query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {BATCH_ID}, '{message_source}', '{message_text}', '{message_type}', '{updated_rows}')\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"Account.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"CDC_FLAG\", \"CDC_DSN\", \"CA_ID\", \"CA_B_ID\", \"CA_C_ID\", \"CA_NAME\", \"CA_TAX_ST\", \"CA_ST_ID\"],\n",
    "    dtype={\n",
    "        \"CDC_FLAG\": \"str\",\n",
    "        \"CDC_DSN\": \"int64\",\n",
    "        \"CA_ID\": \"int64\",\n",
    "        \"CA_B_ID\": \"int64\",\n",
    "        \"CA_C_ID\": \"int64\",\n",
    "        \"CA_NAME\": \"str\",\n",
    "        \"CA_TAX_ST\": \"uint8\",\n",
    "        \"CA_ST_ID\": \"str\"\n",
    "    }\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({\n",
    "    \"CA_ID\": \"AccountID\",\n",
    "    \"CA_NAME\": \"AccountDesc\",\n",
    "    \"CA_TAX_ST\": \"TaxStatus\"\n",
    "}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker_mapping = pd.read_sql_query(\"SELECT BrokerID AS CA_B_ID, SK_BrokerID FROM dimbroker WHERE isCurrent = 1\", engine).set_index(\"CA_B_ID\")[\"SK_BrokerID\"].to_dict()\n",
    "customer_mapping = pd.read_sql_query(\"SELECT CustomerID AS CA_C_ID, SK_CustomerID FROM dimcustomer WHERE isCurrent = 1\", engine).set_index(\"CA_C_ID\")[\"SK_CustomerID\"].to_dict()\n",
    "status_mapping = pd.read_sql_query(\"SELECT ST_ID AS CA_ST_ID, ST_NAME FROM statustype\", engine).set_index(\"CA_ST_ID\")[\"ST_NAME\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'SK_BrokerID'] = df['CA_B_ID'].map(broker_mapping)\n",
    "df.loc[:, 'SK_CustomerID'] = df['CA_C_ID'].map(customer_mapping)\n",
    "df.loc[:, 'Status'] = df['CA_ST_ID'].map(status_mapping)\n",
    "df.loc[:, 'EffectiveDate'] = pd.to_datetime(BATCH_DATE)\n",
    "df.loc[:, 'EndDate'] = pd.Timestamp(\"9999-12-31\")\n",
    "df.loc[:, 'BatchID'] = BATCH_ID\n",
    "df.loc[:, 'IsCurrent'] = 1\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sk = pd.read_sql_query(\"SELECT MAX(SK_AccountID) FROM dimAccount\", engine).iloc[0, 0]\n",
    "df.loc[:, 'SK_AccountID'] = range(max_sk + 1, max_sk + 1 + df.shape[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"CDC_FLAG\", \"CDC_DSN\", \"CA_B_ID\", \"CA_C_ID\", \"CA_ST_ID\"]\n",
    "df_insert = df[df[\"CDC_FLAG\"] == \"I\"].drop(columns=drop_cols)\n",
    "df_insert.info()\n",
    "df_insert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'AccountID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'AccountDesc': sqlalchemy.types.String(50),\n",
    "    'TaxStatus': sqlalchemy.types.SmallInteger,\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert.to_sql('dimaccount', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"CDC_FLAG\", \"CDC_DSN\", \"CA_B_ID\", \"CA_C_ID\", \"CA_ST_ID\"]\n",
    "df_update = df[df[\"CDC_FLAG\"] == \"U\"].drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    for index, row in df_update.iterrows():\n",
    "        account_id = row['AccountID']\n",
    "        required_rows = df_update[df_update['AccountID'].isin([account_id])]\n",
    "        # only one update per day\n",
    "        if len(required_rows) > 1 and index != required_rows.index[-1]:\n",
    "            continue\n",
    "        effective_date = row['EffectiveDate']\n",
    "        query = f\"\"\"UPDATE dimAccount\n",
    "        SET IsCurrent = 0, EndDate = '{effective_date}'\n",
    "        WHERE IsCurrent = 1 AND AccountID = {account_id};\"\"\"\n",
    "        connection.execute(text(query))\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update.to_sql('dimaccount', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"CDC_FLAG\", \"CDC_DSN\", \"T_ID\", \"T_DTS\", \"T_ST_ID\",\n",
    "    \"T_TT_ID\", \"T_IS_CASH\", \"T_S_SYMB\", \"T_QTY\", \"T_BID_PRICE\",\n",
    "    \"T_CA_ID\", \"T_EXEC_NAME\", \"T_TRADE_PRICE\", \"T_CHRG\", \"T_COMM\", \"T_TAX\"\n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    \"CDC_FLAG\": \"category\",\n",
    "    \"CDC_DSN\": \"int64\",\n",
    "    \"T_ID\": \"int64\",\n",
    "    \"T_DTS\": \"str\",\n",
    "    \"T_ST_ID\": \"str\",\n",
    "    \"T_TT_ID\": \"str\",\n",
    "    \"T_IS_CASH\": \"boolean\",\n",
    "    \"T_S_SYMB\": \"str\",\n",
    "    \"T_QTY\": \"int64\",\n",
    "    \"T_BID_PRICE\": \"float64\",\n",
    "    \"T_CA_ID\": \"int64\",\n",
    "    \"T_EXEC_NAME\": \"str\",\n",
    "    \"T_TRADE_PRICE\": \"float64\",\n",
    "    \"T_CHRG\": \"float64\",\n",
    "    \"T_COMM\": \"float64\",\n",
    "    \"T_TAX\": \"float64\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(DATA_DIR + \"Trade.txt\", sep='|', header=None, names=column_names, dtype=data_types, parse_dates=[\"T_DTS\"])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mapping = pd.read_sql_query(\"SELECT SK_DateID, DateValue FROM DimDate\", engine).set_index('DateValue')['SK_DateID'].to_dict()\n",
    "time_mapping = pd.read_sql_query(\"SELECT SK_TimeID, TimeValue FROM DimTime\", engine)\n",
    "\n",
    "def timedelta_to_time(td):\n",
    "    return (datetime.min + td).time()\n",
    "\n",
    "# Applying the function to the series\n",
    "time_mapping['TimeValue'] = time_mapping['TimeValue'].apply(timedelta_to_time)\n",
    "time_mapping = time_mapping.set_index('TimeValue')['SK_TimeID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is a new Trade record (CDC_FLAG = I) then SK_CreateDateID and \n",
    "# SK_CreateTimeID must be set based on T_DTS. SK_CloseDateID and SK_CloseTimeID must be set to NULL\n",
    "insert_mask = df['CDC_FLAG'] == 'I'\n",
    "df.loc[insert_mask, 'SK_CreateDateID'] = df.loc[insert_mask, 'T_DTS'].dt.date.map(date_mapping)\n",
    "df.loc[insert_mask, 'SK_CreateTimeID'] = df.loc[insert_mask, 'T_DTS'].dt.time.map(time_mapping)\n",
    "df.loc[insert_mask, 'SK_CloseDateID'] = None\n",
    "df.loc[insert_mask, 'SK_CloseTimeID'] = None\n",
    "df.info()\n",
    "df.loc[insert_mask, ['SK_CreateDateID', 'SK_CreateTimeID', 'SK_CloseDateID', 'SK_CloseTimeID']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If T_ST_ID is CMPT or CNCL, SK_CloseDateID and SK_CloseTimeID must be set based on T_DTS.\n",
    "close_mask = df['T_ST_ID'].isin(['CMPT', 'CNCL'])\n",
    "df.loc[close_mask, 'SK_CloseDateID'] = df.loc[close_mask, 'T_DTS'].dt.date.map(date_mapping)\n",
    "df.loc[close_mask, 'SK_CloseTimeID'] = df.loc[close_mask, 'T_DTS'].dt.time.map(time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'T_ID': 'TradeID',\n",
    "    'T_IS_CASH': 'CashFlag',\n",
    "    'T_QTY': 'Quantity',\n",
    "    'T_BID_PRICE': 'BidPrice',\n",
    "    'T_EXEC_NAME': 'ExecutedBy',\n",
    "    'T_TRADE_PRICE': 'TradePrice',\n",
    "    'T_CHRG': 'Fee',\n",
    "    'T_COMM': 'Commission',\n",
    "    'T_TAX': 'Tax'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_mapping = pd.read_sql(\"SELECT ST_ID, ST_NAME FROM statustype\", engine).set_index(\"ST_ID\")[\"ST_NAME\"].to_dict()\n",
    "trade_type_mapping = pd.read_sql(\"SELECT TT_ID, TT_NAME FROM tradetype\", engine).set_index(\"TT_ID\")[\"TT_NAME\"].to_dict()\n",
    "df[\"Status\"] = df[\"T_ST_ID\"].map(status_mapping)\n",
    "df[\"Type\"] = df[\"T_TT_ID\"].map(trade_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching security and account info in one go\n",
    "security_info = pd.read_sql(\"SELECT Symbol, SK_SecurityID, SK_CompanyID FROM dimsecurity WHERE IsCurrent = 1\", engine).set_index('Symbol')\n",
    "account_info = pd.read_sql(\"SELECT AccountID, SK_AccountID, SK_CustomerID, SK_BrokerID FROM dimaccount WHERE IsCurrent = 1\",\n",
    "                           engine).set_index('AccountID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'SK_SecurityID'] = df.loc[:, 'T_S_SYMB'].map(security_info['SK_SecurityID'].to_dict())\n",
    "df.loc[:, 'SK_CompanyID'] = df.loc[:, 'T_S_SYMB'].map(security_info['SK_CompanyID'].to_dict())\n",
    "df.loc[:, 'SK_AccountID'] = df.loc[:, 'T_CA_ID'].map(account_info['SK_AccountID'].to_dict())\n",
    "df.loc[:, 'SK_CustomerID'] = df.loc[:, 'T_CA_ID'].map(account_info['SK_CustomerID'].to_dict())\n",
    "df.loc[:, 'SK_BrokerID'] = df.loc[:, 'T_CA_ID'].map(account_info['SK_BrokerID'].to_dict())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "invalid_trades = df[\n",
    "    (df[\"Commission\"].notnull())\n",
    "    & (df[\"Commission\"] > (df[\"TradePrice\"] * df[\"Quantity\"]))\n",
    "]\n",
    "\n",
    "if invalid_trades.shape[0] > 0:\n",
    "    # Create lists without using iterrows\n",
    "    MessageSource = [\"DimTrade\"] * len(invalid_trades)\n",
    "    MessageType = [\"Alert\"] * len(invalid_trades)\n",
    "    MessageText = [\"Invalid trade commission\"] * len(invalid_trades)\n",
    "    MessageData = [\n",
    "        \"T_ID = \"\n",
    "        + invalid_trades[\"TradeID\"].astype(str)\n",
    "        + \", T_COMM = \"\n",
    "        + invalid_trades[\"Commission\"].astype(str)\n",
    "    ]\n",
    "    # Convert MessageData from a list of Series to a list of strings\n",
    "    MessageData = MessageData[0].tolist()\n",
    "    \n",
    "    query = f\"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "    VALUES \"\"\"\n",
    "    for i in range(len(MessageSource)):\n",
    "        query += f\"\"\"('{pd.Timestamp(\"now\")}', {BATCH_ID}, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(query[:-1]))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for invalid trade fees\n",
    "invalid_fee_trades = df[\n",
    "    (df[\"Fee\"].notnull())\n",
    "    & (df[\"Fee\"] > (df[\"TradePrice\"] / df[\"Quantity\"]))\n",
    "]\n",
    "\n",
    "if len(invalid_fee_trades) > 0:\n",
    "    # Create the required lists\n",
    "    MessageSource = [\"DimTrade\"] * len(invalid_fee_trades)\n",
    "    MessageType = [\"Alert\"] * len(invalid_fee_trades)\n",
    "    MessageText = [\"Invalid trade fee\"] * len(invalid_fee_trades)\n",
    "    \n",
    "    # Vectorized operation for MessageData\n",
    "    MessageData = (\n",
    "        \"T_ID = \"\n",
    "        + invalid_fee_trades[\"TradeID\"].astype(str)\n",
    "        + \", T_CHRG = \"\n",
    "        + invalid_fee_trades[\"Fee\"].astype(str)\n",
    "    )\n",
    "    MessageData = MessageData.tolist()\n",
    "    \n",
    "    query = \"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData) VALUES \"\"\"\n",
    "    for i in range(len(MessageSource)):\n",
    "        query += f\"\"\"('{pd.Timestamp(\"now\")}', {BATCH_ID}, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(query[:-1]))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'TradeID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateTimeID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseTimeID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.CHAR(10),\n",
    "    'Type': sqlalchemy.types.CHAR(12),\n",
    "    'CashFlag': sqlalchemy.types.Boolean,\n",
    "    'SK_SecurityID': sqlalchemy.types.Integer,\n",
    "    'SK_CompanyID': sqlalchemy.types.Integer,\n",
    "    'Quantity': sqlalchemy.types.Integer,\n",
    "    'BidPrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'ExecutedBy': sqlalchemy.types.CHAR(64),\n",
    "    'TradePrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'Fee': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Commission': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Tax': sqlalchemy.types.Numeric(10, 2),\n",
    "    'BatchID': sqlalchemy.types.SmallInteger\n",
    "}\n",
    "keep_cols = [col for col in df.columns if col in sql_dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert = df.loc[df[\"CDC_FLAG\"] == \"I\", keep_cols]\n",
    "df_insert.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert.to_sql('dimtrade', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_update = df.loc[df[\"CDC_FLAG\"] == \"U\", keep_cols]\n",
    "df_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    for index, row in df_update.iterrows():\n",
    "        trade_id = row['TradeID']\n",
    "        required_rows = df_update[df_update['TradeID'] == trade_id]\n",
    "        # only update using latest value\n",
    "        if len(required_rows) > 1 and index != required_rows.index[-1]:\n",
    "            continue\n",
    "        str_cols = ['Status', 'Type']\n",
    "        query_parts = []\n",
    "        for key, value in row.to_dict().items():\n",
    "            if key in ('TradeID', 'SK_CreateDateID', 'SK_CreateTimeID'):\n",
    "                continue\n",
    "            if pd.isna(value):\n",
    "                query_part = f\"{key} = NULL\"\n",
    "            elif key in str_cols:\n",
    "                value = value.replace(\"'\", \"\\\\'\")\n",
    "                query_part = f\"{key} = '{value}'\"\n",
    "            else:  # for numeric and boolean types\n",
    "                query_part = f\"{key} = {value}\"\n",
    "            query_parts.append(query_part)\n",
    "        query = f\"UPDATE dimtrade SET {', '.join(query_parts)} WHERE TradeID = {trade_id};\"\n",
    "        connection.execute(text(query))\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactCashBalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"CashTransaction.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"CDC_FLAG\",\n",
    "        \"CDC_DSN\",\n",
    "        \"CT_CA_ID\",\n",
    "        \"CT_DTS\",\n",
    "        \"CT_AMT\",\n",
    "        \"CT_NAME\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"CDC_FLAG\": \"category\",\n",
    "        \"CDC_DSN\": \"int64\",\n",
    "        \"CT_CA_ID\": \"uint32\",\n",
    "        \"CT_DTS\": \"str\",\n",
    "        \"CT_AMT\": \"float64\",\n",
    "        \"CT_NAME\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"CT_DTS\"],\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info = pd.read_sql(\n",
    "    \"SELECT AccountID, SK_AccountID, SK_CustomerID FROM dimaccount WHERE IsCurrent = 1\",\n",
    "    engine,\n",
    ").set_index('AccountID')\n",
    "df.loc[:, 'SK_AccountID'] = df.loc[:, 'CT_CA_ID'].map(account_info['SK_AccountID'].to_dict())\n",
    "df.loc[:, 'SK_CustomerID'] = df.loc[:, 'CT_CA_ID'].map(account_info['SK_CustomerID'].to_dict())\n",
    "\n",
    "date_info = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info[\"DateValue\"] = pd.to_datetime(date_info[\"DateValue\"])\n",
    "df.loc[:, 'SK_DateID'] = df.loc[:, 'CT_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by account ID and transaction date\n",
    "df.sort_values(by=['CT_CA_ID', 'CT_DTS'], inplace=True)\n",
    "\n",
    "# Create a new column to store the prior cash amount\n",
    "df['PriorCash'] = df.groupby('CT_CA_ID')['CT_AMT'].cumsum() - df['CT_AMT']\n",
    "df['PriorCash'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the cash balance\n",
    "df['Cash'] = df['PriorCash'] + df['CT_AMT']\n",
    "df = df.groupby(['CT_CA_ID', 'SK_DateID']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_AccountID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    \"Cash\": sqlalchemy.types.DECIMAL(precision=15, scale=2),\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}\n",
    "keep_cols = [col for col in df.columns if col in sql_dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert = df.loc[df[\"CDC_FLAG\"] == \"I\", keep_cols]\n",
    "df_insert.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert.to_sql('factcashbalances', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactHoldings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL queries\n",
    "sql_commands = [\n",
    "    \"DROP TABLE IF EXISTS TempHoldingHistory\",\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE TempHoldingHistory (\n",
    "        CDC_FLAG CHAR(1) NOT NULL,\n",
    "        CDC_DSN INT UNSIGNED NOT NULL,\n",
    "        HH_H_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_BEFORE_QTY INT NOT NULL,\n",
    "        HH_AFTER_QTY INT NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'E:\\\\\\\\Documents\\\\\\\\BDMA\\\\\\\\ULB\\\\\\\\Data Warehouses\\\\\\\\tpc-di\\\\\\\\TPC-DI\\\\\\\\data\\\\\\\\sf5\\\\\\\\Batch{BATCH_ID}\\\\\\\\HoldingHistory.txt'\n",
    "    INTO TABLE TempHoldingHistory\n",
    "    FIELDS TERMINATED BY '|'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    (CDC_FLAG, CDC_DSN, HH_H_T_ID, HH_T_ID, HH_BEFORE_QTY, HH_AFTER_QTY)\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    INSERT INTO FactHoldings (TradeID, CurrentTradeID, SK_CustomerID, SK_AccountID, SK_SecurityID, SK_CompanyID, SK_DateID, SK_TimeID, CurrentPrice, CurrentHolding, BatchID)\n",
    "    SELECT \n",
    "        thh.HH_H_T_ID AS TradeID,\n",
    "        thh.HH_T_ID AS CurrentTradeID,\n",
    "        dt.SK_CustomerID,\n",
    "        dt.SK_AccountID,\n",
    "        dt.SK_SecurityID,\n",
    "        dt.SK_CompanyID,\n",
    "        dt.SK_CloseDateID AS SK_DateID,\n",
    "        dt.SK_CloseTimeID AS SK_TimeID,\n",
    "        dt.TradePrice AS CurrentPrice,\n",
    "        thh.HH_AFTER_QTY AS CurrentHolding,\n",
    "        {BATCH_ID} AS BatchID\n",
    "    FROM \n",
    "        TempHoldingHistory thh\n",
    "    JOIN \n",
    "        DimTrade dt ON thh.HH_T_ID = dt.TradeID\n",
    "    \"\"\",\n",
    "    \"DROP TABLE TempHoldingHistory\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "with engine.connect() as connection:\n",
    "    for sql in sql_commands:\n",
    "        connection.execute(text(sql))\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactWatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"WatchHistory.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"CDC_FLAG\",\n",
    "        \"CDC_DSN\",\n",
    "        \"W_C_ID\",\n",
    "        \"W_S_SYMB\",\n",
    "        \"W_DTS\",\n",
    "        \"W_ACTION\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"CDC_FLAG\": \"category\",\n",
    "        \"CDC_DSN\": \"int64\",\n",
    "        \"W_C_ID\": \"uint32\",\n",
    "        \"W_S_SYMB\": \"str\",\n",
    "        \"W_DTS\": \"str\",\n",
    "        \"W_ACTION\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"W_DTS\"]\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_mapping = pd.read_sql_query(\n",
    "    \"SELECT CustomerID, SK_CustomerID FROM dimcustomer WHERE IsCurrent = 1\",\n",
    "    engine).set_index('CustomerID')['SK_CustomerID'].to_dict()\n",
    "\n",
    "security_mapping = pd.read_sql_query(\n",
    "    \"SELECT Symbol, SK_SecurityID FROM dimsecurity WHERE IsCurrent = 1\",\n",
    "    engine).set_index('Symbol')['SK_SecurityID'].to_dict()\n",
    "\n",
    "date_info = pd.read_sql_query(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info['DateValue'] = pd.to_datetime(date_info['DateValue'])\n",
    "date_mapping = date_info.set_index('DateValue')['SK_DateID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'SK_CustomerID'] = df.loc[:, 'W_C_ID'].map(customer_mapping)\n",
    "df.loc[:, 'SK_SecurityID'] = df.loc[:, 'W_S_SYMB'].map(security_mapping)\n",
    "df.loc[:, 'SK_DateID_DatePlaced'] = df.loc[:, 'W_DTS'].dt.date.map(date_mapping)\n",
    "df.loc[:, 'BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for rows where W_ACTION is 'CNCL'\n",
    "mask_cncl = df['W_ACTION'] == 'CNCL'\n",
    "df.loc[mask_cncl, 'SK_DateID_DateRemoved'] = df.loc[mask_cncl, 'W_DTS'].dt.date.map(date_mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"W_C_ID\", \"W_S_SYMB\"]).first().reset_index()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records_dict = {'SK_CustomerID': [], 'SK_SecurityID': [], 'SK_DateID_DatePlaced': [], 'SK_DateID_DateRemoved': [], 'BatchID': []}\n",
    "lst = [0, 0, 0]\n",
    "\n",
    "def update_or_insert(row, new_records):\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # Check if the record exists in factwatches\n",
    "        existing = pd.read_sql_query(\n",
    "            \"SELECT * FROM factwatches WHERE SK_CustomerID = {} AND SK_SecurityID = {}\".format(row['SK_CustomerID'], row['SK_SecurityID']),\n",
    "            connection\n",
    "        )\n",
    "\n",
    "        # Handle NaN in SK_DateID_DateRemoved\n",
    "        date_removed = \"NULL\" if pd.isna(row['SK_DateID_DateRemoved']) else row['SK_DateID_DateRemoved']\n",
    "\n",
    "        if not existing.empty:\n",
    "            # Update the existing record\n",
    "            query = \"\"\"\n",
    "            UPDATE factwatches\n",
    "            SET SK_DateID_DatePlaced = {}, SK_DateID_DateRemoved = {}, BatchID = {}\n",
    "            WHERE SK_CustomerID = {} AND SK_SecurityID = {}\n",
    "            \"\"\".format(row['SK_DateID_DatePlaced'], date_removed, row['BatchID'], row['SK_CustomerID'], row['SK_SecurityID'])\n",
    "            connection.execute(text(query))\n",
    "            lst[0] += 1\n",
    "            connection.commit()\n",
    "        else:\n",
    "            # Check for matching records in dimcustomer and dimsecurity\n",
    "            customer_sk = pd.read_sql_query(\n",
    "                \"SELECT SK_CustomerID FROM dimcustomer WHERE CustomerID = {}\".format(row['W_C_ID']),\n",
    "                connection\n",
    "            )\n",
    "            security_sk = pd.read_sql_query(\n",
    "                \"SELECT SK_SecurityID FROM dimsecurity WHERE Symbol = '{}'\".format(row['W_S_SYMB']),\n",
    "                connection\n",
    "            )\n",
    "\n",
    "            # Check for each combination of SKs in factwatches\n",
    "            for cust_id in customer_sk['SK_CustomerID']:\n",
    "                for sec_id in security_sk['SK_SecurityID']:\n",
    "                    existing = pd.read_sql_query(\n",
    "                        \"SELECT * FROM factwatches WHERE SK_CustomerID = {} AND SK_SecurityID = {}\".format(cust_id, sec_id),\n",
    "                        connection\n",
    "                    )\n",
    "                    if not existing.empty:\n",
    "                        # Update the existing record with new values\n",
    "                        query = \"\"\"\n",
    "                        UPDATE factwatches\n",
    "                        SET SK_DateID_DatePlaced = {}, SK_DateID_DateRemoved = {}, BatchID = {}\n",
    "                        WHERE SK_CustomerID = {} AND SK_SecurityID = {}\n",
    "                        \"\"\".format(row['SK_DateID_DatePlaced'], date_removed, row['BatchID'], cust_id, sec_id)\n",
    "                        connection.execute(text(query))\n",
    "                        connection.commit()\n",
    "                        lst[1] += 1\n",
    "                        return\n",
    "\n",
    "            # Accumulate new record for bulk insert\n",
    "            new_records_dict['SK_CustomerID'].append(row['SK_CustomerID'])\n",
    "            new_records_dict['SK_SecurityID'].append(row['SK_SecurityID'])\n",
    "            new_records_dict['SK_DateID_DatePlaced'].append(row['SK_DateID_DatePlaced'])\n",
    "            new_records_dict['SK_DateID_DateRemoved'].append(row['SK_DateID_DateRemoved'] if pd.notna(row['SK_DateID_DateRemoved']) else None)\n",
    "            new_records_dict['BatchID'].append(row['BatchID'])\n",
    "            lst[2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame and accumulate new records\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    update_or_insert(row, new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DatePlaced\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DateRemoved\": sqlalchemy.types.Integer,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}\n",
    "# Bulk insert new records\n",
    "new_records_df = pd.DataFrame(new_records_dict)\n",
    "new_records_df.to_sql('factwatches', con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactMarketHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"DailyMarket.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"CDC_FLAG\",\n",
    "        \"CDC_DSN\",\n",
    "        \"DM_DATE\",\n",
    "        \"DM_S_SYMB\",\n",
    "        \"DM_CLOSE\",\n",
    "        \"DM_HIGH\",\n",
    "        \"DM_LOW\",\n",
    "        \"DM_VOL\",\n",
    "    ],\n",
    "    dtype={\n",
    "        \"CDC_FLAG\": \"category\",\n",
    "        \"CDC_DSN\": \"int64\",\n",
    "        \"DM_DATE\": \"str\",\n",
    "        \"DM_S_SYMB\": \"str\",\n",
    "        \"DM_CLOSE\": \"float32\",\n",
    "        \"DM_HIGH\": \"float32\",\n",
    "        \"DM_LOW\": \"float32\",\n",
    "        \"DM_VOL\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"DM_DATE\"],\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClosePrice, DayHigh, DayLow, and Volume are copied from DM_CLOSE, DM_HIGH,\n",
    "# DM_LOW, and DM_VOL respectively.\n",
    "df[\"ClosePrice\"] = df[\"DM_CLOSE\"]\n",
    "df[\"DayHigh\"] = df[\"DM_HIGH\"]\n",
    "df[\"DayLow\"] = df[\"DM_LOW\"]\n",
    "df[\"Volume\"] = df[\"DM_VOL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_info = pd.read_sql(\"SELECT Symbol, SK_SecurityID, SK_CompanyID FROM dimsecurity WHERE IsCurrent = 1\",\n",
    "                            engine).set_index(\"Symbol\")\n",
    "security_mapping = security_info['SK_SecurityID'].to_dict()\n",
    "company_mapping = security_info['SK_CompanyID'].to_dict()\n",
    "\n",
    "df.loc[:, 'SK_SecurityID'] = df.loc[:, 'DM_S_SYMB'].map(security_mapping)\n",
    "df.loc[:, 'SK_CompanyID'] = df.loc[:, 'DM_S_SYMB'].map(company_mapping)\n",
    "\n",
    "date_info = pd.read_sql_query(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info['DateValue'] = pd.to_datetime(date_info['DateValue'])\n",
    "date_mapping = date_info.set_index('DateValue')['SK_DateID'].to_dict()\n",
    "df.loc[:, 'SK_DateID'] = df.loc[:, 'DM_DATE'].dt.date.map(date_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Sort the DataFrame\n",
    "df.sort_values(by='DM_DATE', inplace=True)\n",
    "\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling max\n",
    "rolling_max = df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_HIGH'].max()\n",
    "\n",
    "# Reset index to make merging easier\n",
    "rolling_max = rolling_max.reset_index()\n",
    "\n",
    "# Step 5: Merge with the original DataFrame\n",
    "df = df.merge(rolling_max, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekHigh'))\n",
    "\n",
    "# Rename the column for clarity\n",
    "df.rename(columns={'DM_HIGH_52WeekHigh': 'FiftyTwoWeekHigh'}, inplace=True)\n",
    "\n",
    "rolling_rank = (\n",
    "    df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_HIGH\"]\n",
    "    .rank(method=\"average\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_HIGH\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['SK_FiftyTwoWeekHighDate'].dt.date.map(date_mapping)\n",
    "\n",
    "df = pd.concat([df, rolling_rank['SK_FiftyTwoWeekHighDate']], axis=1)\n",
    "\n",
    "df.sort_values(by='DM_DATE', inplace=True)\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling min\n",
    "rolling_min = df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_LOW'].min()\n",
    "# Reset index to make merging easier\n",
    "rolling_min = rolling_min.reset_index()\n",
    "# Step 5: Merge with the original DataFrame\n",
    "df = df.merge(rolling_min, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekLow'))\n",
    "# Rename the column for clarity\n",
    "df.rename(columns={'DM_LOW_52WeekLow': 'FiftyTwoWeekLow'}, inplace=True)\n",
    "\n",
    "rolling_rank = (\n",
    "    df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_LOW\"]\n",
    "    .rank(method=\"average\", ascending=True)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_LOW\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['SK_FiftyTwoWeekLowDate'].dt.date.map(date_mapping)\n",
    "\n",
    "df = pd.concat([df, rolling_rank['SK_FiftyTwoWeekLowDate']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SK_SecurityID'] = df['SK_SecurityID'].astype('uint32')\n",
    "df['SK_CompanyID'] = df['SK_CompanyID'].astype('uint32')\n",
    "df['SK_DateID'] = df['SK_DateID'].astype('uint32')\n",
    "df['FiftyTwoWeekHigh'] = df['FiftyTwoWeekHigh'].astype('float32')\n",
    "df['SK_FiftyTwoWeekHighDate'] = df['SK_FiftyTwoWeekHighDate'].astype('uint32')\n",
    "df['FiftyTwoWeekLow'] = df['FiftyTwoWeekLow'].astype('float32')\n",
    "df['SK_FiftyTwoWeekLowDate'] = df['SK_FiftyTwoWeekLowDate'].astype('uint32')\n",
    "df['DM_S_SYMB'] = df['DM_S_SYMB'].astype('category')\n",
    "\n",
    "df.drop(columns=['DM_HIGH', 'DM_LOW', 'DM_VOL', 'DM_CLOSE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_mapping = pd.read_sql(\"SELECT Symbol, Dividend FROM dimsecurity WHERE IsCurrent = 1\", engine).set_index(\"Symbol\")[\"Dividend\"]\n",
    "df.loc[:, 'Yield'] = df.loc[:, 'DM_S_SYMB'].map(security_mapping) / df.loc[:, 'ClosePrice'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BatchID'] = BATCH_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    \"Yield\": sqlalchemy.types.DECIMAL(precision=5, scale=2),\n",
    "    \"FiftyTwoWeekHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekHighDate\": sqlalchemy.types.Integer,\n",
    "    \"FiftyTwoWeekLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekLowDate\": sqlalchemy.types.Integer,\n",
    "    \"ClosePrice\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"Volume\": sqlalchemy.types.BigInteger,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "    \"DM_DATE\": sqlalchemy.types.Date,\n",
    "    \"DM_S_SYMB\": sqlalchemy.types.CHAR(16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CDC_FLAG\", \"CDC_DSN\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('tempfactmarketprice', engine, if_exists='replace', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_commands = [\n",
    "    \"CREATE INDEX idx_sk_companyid ON tempfactmarketprice(SK_CompanyID);\",\n",
    "    \"\"\"SELECT fmp.ClosePrice / T.Sum_EPS AS PERatio\n",
    "        FROM tempfactmarketprice fmp\n",
    "        LEFT JOIN (SELECT \n",
    "            c.CompanyID, \n",
    "            c.SK_CompanyID AS SKCID, \n",
    "            f.FI_QTR_START_DATE,\n",
    "            SUM(f.FI_BASIC_EPS) OVER (\n",
    "                PARTITION BY c.CompanyID \n",
    "                ORDER BY f.FI_QTR_START_DATE \n",
    "                ROWS BETWEEN 3 PRECEDING AND CURRENT ROW\n",
    "            ) AS Sum_EPS\n",
    "        FROM financial f RIGHT JOIN dimCompany c ON f.SK_CompanyID = c.SK_CompanyID\n",
    "        ORDER BY c.CompanyID, f.FI_QTR_START_DATE) T\n",
    "        ON T.SKCID = fmp.SK_CompanyID\n",
    "        AND T.FI_QTR_START_DATE < fmp.DM_DATE \n",
    "        AND T.FI_QTR_START_DATE >= DATE_SUB(fmp.DM_DATE, INTERVAL 3 MONTH);\"\"\",\n",
    "    \"DROP TABLE tempfactmarketprice;\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    connection.execute(text(sql_commands[0]))\n",
    "    connection.commit()\n",
    "peratio = pd.read_sql_query(sql_commands[1], engine)\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(sql_commands[2]))\n",
    "    connection.commit()\n",
    "peratio.info()\n",
    "peratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, peratio], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_earnings = pd.DataFrame(df.loc[df['PERatio'].isna(), 'DM_S_SYMB'])\n",
    "no_earnings['MessageDateAndTime'] = datetime.now()\n",
    "no_earnings['BatchID'] = BATCH_ID\n",
    "no_earnings['MessageSource'] = 'FactMarketHistory'\n",
    "no_earnings['MessageText'] = 'No earnings for company'\n",
    "no_earnings['MessageType'] = 'Alert'\n",
    "no_earnings.rename(columns={\"DM_S_SYMB\":\"MessageData\"}, inplace=True)\n",
    "no_earnings['MessageData'] = \"DM_S_SYMB = \" + no_earnings['MessageData'].astype(str)\n",
    "\n",
    "sql_dtypes = {\n",
    "    \"MessageDateAndTime\": sqlalchemy.types.DATETIME,\n",
    "    \"BatchID\": sqlalchemy.types.Integer,\n",
    "    \"MessageSource\": sqlalchemy.types.CHAR(30),\n",
    "    \"MessageText\": sqlalchemy.types.CHAR(50),\n",
    "    \"MessageType\": sqlalchemy.types.CHAR(12),\n",
    "    \"MessageData\": sqlalchemy.types.CHAR(100)\n",
    "}\n",
    "no_earnings.to_sql('dimessages', con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"DM_DATE\", \"DM_S_SYMB\"], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    \"PERatio\": sqlalchemy.types.DECIMAL(precision=10, scale=2),\n",
    "    \"Yield\": sqlalchemy.types.DECIMAL(precision=5, scale=2),\n",
    "    \"FiftyTwoWeekHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekHighDate\": sqlalchemy.types.Integer,\n",
    "    \"FiftyTwoWeekLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekLowDate\": sqlalchemy.types.Integer,\n",
    "    \"ClosePrice\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"Volume\": sqlalchemy.types.BigInteger,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "}\n",
    "len(sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('factmarkethistory', con=engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_DIRS = ['..\\\\data\\\\sf5\\\\Batch1\\\\', '..\\\\data\\\\sf5\\\\Batch2\\\\', '..\\\\data\\\\sf5\\\\Batch3\\\\']\n",
    "BATCH_FILES = ['..\\\\data\\\\sf5\\\\Batch1_audit.csv', '..\\\\data\\\\sf5\\\\Batch2_audit.csv', '..\\\\data\\\\sf5\\\\Batch3_audit.csv']\n",
    "audit_dtypes = {\"DataSet\": str, \" BatchID\": int, \"Date\": 'datetime64', \" Attribute\": str, \" Value\": 'Int64', \" DValue\": 'float64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(BATCH_FILES[0], dtype=audit_dtypes)\n",
    "df = pd.concat([df, pd.read_csv(BATCH_FILES[1], dtype=audit_dtypes)])\n",
    "df = pd.concat([df, pd.read_csv(BATCH_FILES[2], dtype=audit_dtypes)])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.read_csv(r\"..\\data\\sf5\\Generator_audit.csv\", dtype=audit_dtypes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in BATCH_DIRS:\n",
    "    files = os.listdir(folder)\n",
    "    files = list(filter(lambda x: \"_audit\" in x, files))\n",
    "    for file in files:\n",
    "        df = pd.concat([df, pd.read_csv(folder + file, dtype=audit_dtypes)])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"drop table audit\"\"\"\n",
    "with engine.connect() as cxn:\n",
    "    cxn.execute(text(create_table))\n",
    "    cxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"drop table audit;\"\"\"\n",
    "with engine.connect() as cxn:\n",
    "    cxn.execute(text(create_table))\n",
    "    cxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Audit (\n",
    "    DataSet CHAR(20) NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED,\n",
    "    Date DATE,\n",
    "    Attribute CHAR(50) NOT NULL,\n",
    "    Value BIGINT,\n",
    "    DValue NUMERIC(15, 5)\n",
    ");\"\"\"\n",
    "with engine.connect() as cxn:\n",
    "    cxn.execute(text(create_table))\n",
    "    cxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('audit', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = pd.read_sql_table('audit', engine)\n",
    "audit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\Documents\\BDMA\\ULB\\Data Warehouses\\tpc-di\\TPC-DI\\validation\\tpcdi_audit.sql\", encoding='utf-8') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(content.split(\"union\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
