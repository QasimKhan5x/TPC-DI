{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPC-DI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection details\n",
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = \"password\"\n",
    "database = \"tpcdi-sf5\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{user}:{password}@{host}/{database}?allow_local_infile=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"..\\\\data\\\\sf5\\\\Batch1\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.read_csv(\n",
    "    r\"..\\data\\sf5\\Batch1\\Date.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"SK_DateID\", \"DateValue\", \"DateDesc\", \"CalendarYearID\", \"CalendarYearDesc\", \n",
    "        \"CalendarQtrID\", \"CalendarQtrDesc\", \"CalendarMonthID\", \"CalendarMonthDesc\", \n",
    "        \"CalendarWeekID\", \"CalendarWeekDesc\", \"DayOfWeekNum\", \"DayOfWeekDesc\", \n",
    "        \"FiscalYearID\", \"FiscalYearDesc\", \"FiscalQtrID\", \"FiscalQtrDesc\", \"HolidayFlag\"\n",
    "    ],\n",
    "    parse_dates=[\"DateValue\"],\n",
    "    dtype={\n",
    "        \"SK_DateID\": \"uint32\", \"DateDesc\": \"str\", \"CalendarYearID\": \"uint16\", \"CalendarYearDesc\": \"str\",\n",
    "        \"CalendarQtrID\": \"uint16\", \"CalendarQtrDesc\": \"str\", \"CalendarMonthID\": \"uint32\", \"CalendarMonthDesc\": \"str\",\n",
    "        \"CalendarWeekID\": \"uint32\", \"CalendarWeekDesc\": \"str\", \"DayOfWeekNum\": \"uint8\", \"DayOfWeekDesc\": \"str\",\n",
    "        \"FiscalYearID\": \"uint16\", \"FiscalYearDesc\": \"str\", \"FiscalQtrID\": \"uint16\", \"FiscalQtrDesc\": \"str\",\n",
    "        \"HolidayFlag\": \"bool\"\n",
    "    }\n",
    ")\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_DateID\": sqlalchemy.types.BigInteger,\n",
    "    \"DateValue\": sqlalchemy.types.Date,\n",
    "    \"DateDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarYearID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarYearDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarQtrID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarQtrDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarMonthID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarMonthDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"CalendarWeekID\": sqlalchemy.types.Integer,\n",
    "    \"CalendarWeekDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"DayOfWeekNum\": sqlalchemy.types.SmallInteger,\n",
    "    \"DayOfWeekDesc\": sqlalchemy.types.CHAR(length=10),\n",
    "    \"FiscalYearID\": sqlalchemy.types.Integer,\n",
    "    \"FiscalYearDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"FiscalQtrID\": sqlalchemy.types.Integer,\n",
    "    \"FiscalQtrDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"HolidayFlag\": sqlalchemy.types.Boolean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimDate (\n",
    "    SK_DateID INT UNSIGNED NOT NULL,\n",
    "    DateValue DATE NOT NULL,\n",
    "    DateDesc CHAR(20) NOT NULL,\n",
    "    CalendarYearID SMALLINT UNSIGNED NOT NULL,\n",
    "    CalendarYearDesc CHAR(20) NOT NULL,\n",
    "    CalendarQtrID SMALLINT UNSIGNED NOT NULL,\n",
    "    CalendarQtrDesc CHAR(20) NOT NULL,\n",
    "    CalendarMonthID MEDIUMINT UNSIGNED NOT NULL,\n",
    "    CalendarMonthDesc CHAR(20) NOT NULL,\n",
    "    CalendarWeekID MEDIUMINT UNSIGNED NOT NULL,\n",
    "    CalendarWeekDesc CHAR(20) NOT NULL,\n",
    "    DayOfWeekNum TINYINT UNSIGNED NOT NULL,\n",
    "    DayOfWeekDesc CHAR(10) NOT NULL,\n",
    "    FiscalYearID SMALLINT UNSIGNED NOT NULL,\n",
    "    FiscalYearDesc CHAR(20) NOT NULL,\n",
    "    FiscalQtrID SMALLINT UNSIGNED NOT NULL,\n",
    "    FiscalQtrDesc CHAR(20) NOT NULL,\n",
    "    HolidayFlag BOOLEAN,\n",
    "    PRIMARY KEY (SK_DateID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.to_sql(name='dimdate', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dimdate limit 10\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "file_path = r\"..\\data\\sf5\\Batch1\\Time.txt\"\n",
    "dim_time_df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"SK_TimeID\", \"TimeValue\", \"HourID\", \"HourDesc\", \n",
    "        \"MinuteID\", \"MinuteDesc\", \"SecondID\", \"SecondDesc\",\n",
    "        \"MarketHoursFlag\", \"OfficeHoursFlag\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"SK_TimeID\": \"uint32\", \"HourID\": \"uint8\", \n",
    "        \"HourDesc\": \"str\", \"MinuteID\": \"uint8\", \"MinuteDesc\": \"str\", \n",
    "        \"SecondID\": \"uint8\", \"SecondDesc\": \"str\", \"MarketHoursFlag\": \"bool\", \n",
    "        \"OfficeHoursFlag\": \"bool\"\n",
    "    },\n",
    "    parse_dates=[\"TimeValue\"],\n",
    "    date_format=\"%H:%M:%S\"\n",
    ")\n",
    "dim_time_df['TimeValue'] = dim_time_df['TimeValue'].dt.time\n",
    "\n",
    "dim_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_TimeID\": sqlalchemy.types.BigInteger,\n",
    "    \"TimeValue\": sqlalchemy.types.Time,\n",
    "    \"HourID\": sqlalchemy.types.SmallInteger,\n",
    "    \"HourDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"MinuteID\": sqlalchemy.types.SmallInteger,\n",
    "    \"MinuteDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"SecondID\": sqlalchemy.types.SmallInteger,\n",
    "    \"SecondDesc\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"MarketHoursFlag\": sqlalchemy.types.Boolean,\n",
    "    \"OfficeHoursFlag\": sqlalchemy.types.Boolean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimTime (\n",
    "    SK_TimeID INT UNSIGNED NOT NULL,\n",
    "    TimeValue TIME(3) NOT NULL,\n",
    "    HourID TINYINT UNSIGNED NOT NULL,\n",
    "    HourDesc CHAR(20) NOT NULL,\n",
    "    MinuteID TINYINT UNSIGNED NOT NULL,\n",
    "    MinuteDesc CHAR(20) NOT NULL,\n",
    "    SecondID TINYINT UNSIGNED NOT NULL,\n",
    "    SecondDesc CHAR(20) NOT NULL,\n",
    "    MarketHoursFlag BOOLEAN,\n",
    "    OfficeHoursFlag BOOLEAN,\n",
    "    PRIMARY KEY (SK_TimeID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))\n",
    "dim_time_df.to_sql(name='dimtime', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df = pd.read_csv(\n",
    "    r\"..\\data\\sf5\\Batch1\\HR.csv\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"EmployeeID\", \"ManagerID\", \"EmployeeFirstName\", \"EmployeeLastName\",\n",
    "        \"EmployeeMI\", \"EmployeeJobCode\", \"EmployeeBranch\",\n",
    "        \"EmployeeOffice\", \"EmployeePhone\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"EmployeeID\": \"uint32\",\n",
    "        \"ManagerID\": \"uint32\",\n",
    "        \"EmployeeFirstName\": \"str\",\n",
    "        \"EmployeeLastName\": \"str\",\n",
    "        \"EmployeeMI\": \"str\",\n",
    "        \"EmployeeJobCode\": \"UInt16\",\n",
    "        \"EmployeeBranch\": \"str\",\n",
    "        \"EmployeeOffice\": \"str\",\n",
    "        \"EmployeePhone\": \"str\"\n",
    "    }\n",
    ")\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for SCD operations as no duplicate natural keys\n",
    "hr_df.duplicated(subset=[\"EmployeeID\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter Records\n",
    "filtered_df = hr_df[hr_df['EmployeeJobCode'] == 314]\n",
    "filtered_df.drop(columns=['EmployeeJobCode'], inplace=True)\n",
    "# 2. Map Columns\n",
    "DimBroker = filtered_df.rename(columns={\n",
    "    'EmployeeID': 'BrokerID',\n",
    "    'ManagerID': 'ManagerID',\n",
    "    'EmployeeFirstName': 'FirstName',\n",
    "    'EmployeeLastName': 'LastName',\n",
    "    'EmployeeMI': 'MiddleInitial',\n",
    "    'EmployeeBranch': 'Branch',\n",
    "    'EmployeeOffice': 'Office',\n",
    "    'EmployeePhone': 'Phone'\n",
    "})\n",
    "# 3. Handle Surrogate Key (SK_BrokerID)\n",
    "# Using cumcount to generate a unique ID for each row\n",
    "DimBroker['SK_BrokerID'] = range(1, len(DimBroker) + 1)\n",
    "\n",
    "# 4. Set Default Values for New Fields\n",
    "DimBroker['IsCurrent'] = True\n",
    "DimBroker['BatchID'] = 1\n",
    "# EffectiveDate is set to the earliest date in the DimDate table and EndDate is set to 9999- 12-31\n",
    "DimBroker['EffectiveDate'] = pd.read_sql_query(\"SELECT MIN(datevalue) FROM dimdate\", engine).iloc[0, 0]\n",
    "DimBroker['EndDate'] = pd.Timestamp('9999-12-31')\n",
    "\n",
    "# Display the first few rows of the newly created DimBroker DataFrame\n",
    "DimBroker.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"SK_BrokerID\": sqlalchemy.types.BigInteger,\n",
    "    \"BrokerID\": sqlalchemy.types.BigInteger,\n",
    "    \"ManagerID\": sqlalchemy.types.BigInteger,\n",
    "    \"FirstName\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"LastName\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"MiddleInitial\": sqlalchemy.types.CHAR(length=1),\n",
    "    \"Branch\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"Office\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"Phone\": sqlalchemy.types.CHAR(length=14),\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.Integer,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimBroker (\n",
    "    SK_BrokerID INT UNSIGNED NOT NULL,\n",
    "    BrokerID INT UNSIGNED NOT NULL,\n",
    "    ManagerID INT UNSIGNED,\n",
    "    FirstName CHAR(50) NOT NULL,\n",
    "    LastName CHAR(50) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Branch CHAR(50),\n",
    "    Office CHAR(50),\n",
    "    Phone CHAR(14),\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_BrokerID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DimBroker.to_sql(name='dimbroker', con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "file_path = r\"..\\data\\sf5\\Batch1\\Industry.txt\"\n",
    "industry_df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"IN_ID\", \"IN_NAME\", \"IN_SC_ID\"],\n",
    "    dtype={\n",
    "        \"IN_ID\": \"str\",\n",
    "        \"IN_NAME\": \"str\",\n",
    "        \"IN_SC_ID\": \"str\"\n",
    "    }\n",
    ")\n",
    "industry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"IN_ID\": sqlalchemy.types.CHAR(length=2),\n",
    "    \"IN_NAME\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"IN_SC_ID\": sqlalchemy.types.CHAR(length=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Industry (\n",
    "    IN_ID CHAR(2) NOT NULL,\n",
    "    IN_NAME CHAR(50) NOT NULL,\n",
    "    IN_SC_ID CHAR(4) NOT NULL,\n",
    "    PRIMARY KEY (IN_ID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df.to_sql(name=\"industry\", con=engine, if_exists='append', index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### StatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read StatusType data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\StatusType.txt\"\n",
    "status_type_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"ST_ID\", \"ST_NAME\"],\n",
    "    dtype={\"ST_ID\": \"str\", \"ST_NAME\": \"str\"}\n",
    ")\n",
    "status_type_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"ST_ID\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"ST_NAME\": sqlalchemy.types.CHAR(length=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE StatusType (\n",
    "    ST_ID CHAR(4) NOT NULL,\n",
    "    ST_NAME CHAR(10) NOT NULL,\n",
    "    PRIMARY KEY (ST_ID)\n",
    ");\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_type_df.to_sql(name=\"statustype\", con=engine, if_exists='append', index=False, dtype=sql_dtypes)\n",
    "query = \"SELECT * FROM statustype LIMIT 10\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TradeType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TradeType data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\TradeType.txt\"\n",
    "trade_type_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"TT_ID\", \"TT_NAME\", \"TT_IS_SELL\", \"TT_IS_MRKT\"],\n",
    "    dtype={\"TT_ID\": \"str\", \"TT_NAME\": \"str\", \"TT_IS_SELL\": \"uint8\", \"TT_IS_MRKT\": \"uint8\"}\n",
    ")\n",
    "\n",
    "print(trade_type_df.shape)\n",
    "trade_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"TT_ID\": sqlalchemy.types.CHAR(length=3),\n",
    "    \"TT_NAME\": sqlalchemy.types.CHAR(length=12),\n",
    "    \"TT_IS_SELL\": sqlalchemy.types.SmallInteger,\n",
    "    \"TT_IS_MRKT\": sqlalchemy.types.SmallInteger\n",
    "}\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE TradeType (\n",
    "    TT_ID CHAR(3) NOT NULL,\n",
    "    TT_NAME CHAR(12) NOT NULL,\n",
    "    TT_IS_SELL TINYINT UNSIGNED NOT NULL CHECK (TT_IS_SELL IN (0, 1)),\n",
    "    TT_IS_MRKT TINYINT UNSIGNED NOT NULL CHECK (TT_IS_MRKT IN (0, 1)),\n",
    "    PRIMARY KEY (TT_ID)\n",
    ");\"\"\"))\n",
    "trade_type_df.to_sql(name=\"tradetype\", con=engine, if_exists='append', index=False, dtype=dtypes)\n",
    "query = \"SELECT * FROM tradetype LIMIT 10\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TaxRate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TaxRate data\n",
    "filepath = r\"..\\data\\sf5\\Batch1\\TaxRate.txt\"\n",
    "tax_rate_df = pd.read_csv(\n",
    "    filepath,\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"TX_ID\", \"TX_NAME\", \"TX_RATE\"],\n",
    "    dtype={\"TX_ID\": \"str\", \"TX_NAME\": \"str\", \"TX_RATE\": \"float64\"}\n",
    ")\n",
    "print(tax_rate_df.shape)\n",
    "tax_rate_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"TX_ID\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"TX_NAME\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"TX_RATE\": sqlalchemy.types.Numeric(precision=6, scale=5)\n",
    "}\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"CREATE TABLE TaxRate (\n",
    "    TX_ID CHAR(4) NOT NULL,\n",
    "    TX_NAME CHAR(50) NOT NULL,\n",
    "    TX_RATE DECIMAL(6, 5) NOT NULL,\n",
    "    PRIMARY KEY (TX_ID)\n",
    ");\"\"\"))\n",
    "\n",
    "tax_rate_df.to_sql(name=\"taxrate\", con=engine, if_exists='append', index=False, dtype=sql_dtypes)\n",
    "query = \"SELECT * FROM taxrate LIMIT 10\"\n",
    "result_df = pd.read_sql_query(query, engine)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimCompany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_finwire(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 60, 10, 4, 2, 4, 8, 80, 80, 12, 25, 20, 24, 46, 150]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"CompanyName\", \"CIK\", \"Status\", \"IndustryID\",\n",
    "        \"SPrating\", \"FoundingDate\", \"AddrLine1\", \"AddrLine2\", \"PostalCode\",\n",
    "        \"City\", \"StateProvince\", \"Country\", \"CEOname\", \"Description\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_cmp = df[df['RecType'] == 'CMP']\n",
    "    return df_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query StatusType table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    statustype_df = pd.read_sql(\"SELECT * FROM statustype\", conn)\n",
    "status_mapping = dict(statustype_df[[\"ST_ID\", \"ST_NAME\"]].values)\n",
    "\n",
    "# Query Industry table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    industry_df = pd.read_sql(\"SELECT * FROM industry\", conn)\n",
    "industry_mapping = dict(industry_df[[\"IN_ID\", \"IN_NAME\"]].values)\n",
    "\n",
    "# Valid SPrating values\n",
    "valid_spratings = [\n",
    "    \"AAA\",\n",
    "    \"AA+\",\n",
    "    \"AA\",\n",
    "    \"AA-\",\n",
    "    \"A+\",\n",
    "    \"A\",\n",
    "    \"A-\",\n",
    "    \"BBB+\",\n",
    "    \"BBB\",\n",
    "    \"BBB-\",\n",
    "    \"BB+\",\n",
    "    \"BB\",\n",
    "    \"BB-\",\n",
    "    \"B+\",\n",
    "    \"B\",\n",
    "    \"B-\",\n",
    "    \"CCC+\",\n",
    "    \"CCC\",\n",
    "    \"CCC-\",\n",
    "    \"CC\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATA_DIR)\n",
    "finwire_files = [file for file in files if file.startswith(\"FINWIRE\") and 'audit' not in file]\n",
    "len(finwire_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CompanyID\": sqlalchemy.types.BigInteger,\n",
    "    \"CompanyID\": sqlalchemy.types.BigInteger,\n",
    "    \"Status\": sqlalchemy.types.CHAR(length=10),\n",
    "    \"Name\": sqlalchemy.types.CHAR(length=60),\n",
    "    \"Industry\": sqlalchemy.types.CHAR(length=50),\n",
    "    \"SPrating\": sqlalchemy.types.CHAR(length=4),\n",
    "    \"isLowGrade\": sqlalchemy.types.Boolean,\n",
    "    \"CEO\": sqlalchemy.types.CHAR(length=100),\n",
    "    \"AddressLine1\": sqlalchemy.types.CHAR(length=80),\n",
    "    \"AddressLine2\": sqlalchemy.types.CHAR(length=80),\n",
    "    \"PostalCode\": sqlalchemy.types.CHAR(length=12),\n",
    "    \"City\": sqlalchemy.types.CHAR(length=25),\n",
    "    \"StateProv\": sqlalchemy.types.CHAR(length=20),\n",
    "    \"Country\": sqlalchemy.types.CHAR(length=24),\n",
    "    \"Description\": sqlalchemy.types.CHAR(length=150),\n",
    "    \"FoundingDate\": sqlalchemy.types.Date,\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.Integer,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dimcompany(filename, is_first_batch=False):\n",
    "    file_path = DATA_DIR + filename\n",
    "    df_cmp = read_finwire(file_path)\n",
    "\n",
    "    if len(df_cmp) == 0:\n",
    "        return\n",
    "    \n",
    "    # Define the column names and data types\n",
    "    column_names = [\n",
    "        \"SK_CompanyID\",\n",
    "        \"CompanyID\",\n",
    "        \"Status\",\n",
    "        \"Name\",\n",
    "        \"Industry\",\n",
    "        \"SPrating\",\n",
    "        \"isLowGrade\",\n",
    "        \"CEO\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "        \"City\",\n",
    "        \"StateProv\",\n",
    "        \"Country\",\n",
    "        \"Description\",\n",
    "        \"FoundingDate\",\n",
    "        \"IsCurrent\",\n",
    "        \"BatchID\",\n",
    "        \"EffectiveDate\",\n",
    "        \"EndDate\",\n",
    "    ]\n",
    "    dtypes = {\n",
    "        \"SK_CompanyID\": \"uint32\",\n",
    "        \"CompanyID\": \"uint32\",\n",
    "        \"Status\": \"str\",\n",
    "        \"Name\": \"str\",\n",
    "        \"Industry\": \"str\",\n",
    "        \"SPrating\": \"str\",\n",
    "        \"isLowGrade\": \"boolean\",\n",
    "        \"CEO\": \"str\",\n",
    "        \"AddressLine1\": \"str\",\n",
    "        \"AddressLine2\": \"str\",\n",
    "        \"PostalCode\": \"str\",\n",
    "        \"City\": \"str\",\n",
    "        \"StateProv\": \"str\",\n",
    "        \"Country\": \"str\",\n",
    "        \"Description\": \"str\",\n",
    "        \"FoundingDate\": \"datetime64[ns]\",\n",
    "        \"IsCurrent\": \"bool\",\n",
    "        \"BatchID\": \"uint8\",\n",
    "        \"EffectiveDate\": \"datetime64[ns]\",\n",
    "        \"EndDate\": \"datetime64[ns]\",\n",
    "    }\n",
    "    # Create an empty DataFrame with the specified schema\n",
    "    dimCompany = pd.DataFrame(columns=column_names).astype(dtypes)\n",
    "\n",
    "    # Copy and map relevant columns\n",
    "    df_cmp[\"CIK\"] = pd.to_numeric(df_cmp[\"CIK\"], downcast=\"unsigned\")\n",
    "    dimCompany[\"CompanyID\"] = pd.to_numeric(df_cmp[\"CIK\"], downcast=\"unsigned\")\n",
    "    dimCompany[\"Name\"] = df_cmp[\"CompanyName\"]\n",
    "    dimCompany[\"SPrating\"] = df_cmp[\"SPrating\"]\n",
    "    dimCompany[\"CEO\"] = df_cmp[\"CEOname\"]\n",
    "    dimCompany[\"Description\"] = df_cmp[\"Description\"]\n",
    "    dimCompany[\"FoundingDate\"] = pd.to_datetime(\n",
    "        df_cmp[\"FoundingDate\"], format=\"%Y%m%d\", errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # For address fields\n",
    "    dimCompany[\"AddressLine1\"] = df_cmp[\"AddrLine1\"]\n",
    "    dimCompany[\"AddressLine2\"] = df_cmp[\"AddrLine2\"]\n",
    "    dimCompany[\"PostalCode\"] = df_cmp[\"PostalCode\"]\n",
    "    dimCompany[\"City\"] = df_cmp[\"City\"]\n",
    "    dimCompany[\"StateProv\"] = df_cmp[\"StateProvince\"]\n",
    "    dimCompany[\"Country\"] = df_cmp[\"Country\"]\n",
    "\n",
    "    # Replace all-blank strings with None (NULL)\n",
    "    for col in [\n",
    "        \"Name\",\n",
    "        \"SPrating\",\n",
    "        \"CEO\",\n",
    "        \"Description\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "        \"City\",\n",
    "        \"StateProv\",\n",
    "        \"Country\",\n",
    "    ]:\n",
    "        dimCompany[col] = dimCompany[col].replace(r\"^\\s*$\", None, regex=True)\n",
    "\n",
    "    # Update Status in dimCompany\n",
    "    dimCompany[\"Status\"] = df_cmp[\"Status\"].map(status_mapping)\n",
    "    # Update Industry in dimCompany\n",
    "    dimCompany[\"Industry\"] = df_cmp[\"IndustryID\"].map(industry_mapping)\n",
    "    # isLowGrade is set to False if SPrating begins with ‘A’ or ‘BBB’ otherwise set to True\n",
    "    dimCompany[\"isLowGrade\"] = ~df_cmp[\"SPrating\"].str.startswith((\"A\", \"BBB\"))\n",
    "\n",
    "    # Identify invalid SPratings\n",
    "    invalid_sprating_mask = ~dimCompany[\"SPrating\"].isin(valid_spratings)\n",
    "    # Filter dimCompany for invalid SPrating\n",
    "    invalid_sprating_data = dimCompany[invalid_sprating_mask]\n",
    "    if len(invalid_sprating_data) > 0:\n",
    "        message_data = (\n",
    "            \"CO_ID = \"\n",
    "            + invalid_sprating_data[\"CompanyID\"].astype(str)\n",
    "            + \", CO_SP_RATE = \"\n",
    "            + invalid_sprating_data[\"SPrating\"]\n",
    "        )\n",
    "        # Create DImessages DataFrame\n",
    "        dimessages = pd.DataFrame(\n",
    "            {\n",
    "                \"MessageDateAndTime\": [datetime.now()] * len(message_data),\n",
    "                \"BatchID\": [1] * len(message_data),\n",
    "                \"MessageSource\": [\"DimCompany\"] * len(message_data),\n",
    "                \"MessageText\": [\"Invalid SPRating\"] * len(message_data),\n",
    "                \"MessageType\": [\"Alert\"] * len(message_data),\n",
    "                \"MessageData\": message_data,\n",
    "            }\n",
    "        )\n",
    "        # Update dimCompany for invalid SPrating\n",
    "        dimCompany.loc[invalid_sprating_mask, [\"SPrating\", \"isLowGrade\"]] = pd.NA\n",
    "        # Insert DImessages into MySQL\n",
    "        dimessages.to_sql(\"dimessages\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "    dimCompany.loc[:, \"BatchID\"] = 1\n",
    "    dimCompany[\"EffectiveDate\"] = pd.to_datetime(df_cmp[\"PTS\"], format=\"%Y%m%d-%H%M%S\")\n",
    "    # Identify new and existing records based on CIK\n",
    "    if is_first_batch:\n",
    "        new_records = dimCompany\n",
    "        existing_records = pd.DataFrame(columns=column_names).astype(dtypes)\n",
    "        next_sk_id = 0\n",
    "    else:\n",
    "        existing_cik = pd.read_sql_query(\n",
    "            \"SELECT CompanyID FROM dimCompany WHERE IsCurrent = 1\", engine\n",
    "        )[\"CompanyID\"]\n",
    "        new_records = dimCompany[~df_cmp[\"CIK\"].isin(existing_cik)]\n",
    "        existing_records = dimCompany[df_cmp[\"CIK\"].isin(existing_cik)]\n",
    "        next_sk_id_query = \"SELECT MAX(SK_CompanyID) FROM dimCompany\"\n",
    "        next_sk_id = pd.read_sql_query(next_sk_id_query, engine).iloc[0, 0] or 0\n",
    "\n",
    "    new_records.loc[:, \"SK_CompanyID\"] = range(\n",
    "        next_sk_id + 1, next_sk_id + 1 + len(new_records)\n",
    "    )\n",
    "    new_records.loc[:, \"IsCurrent\"] = True\n",
    "    new_records.loc[:, \"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "    new_records.to_sql(\n",
    "        \"dimcompany\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "    )\n",
    "    next_sk_id = new_records[\"SK_CompanyID\"].max()\n",
    "\n",
    "    # Process existing records\n",
    "    for _, row in existing_records.iterrows():\n",
    "        effective_date = row[\"EffectiveDate\"]\n",
    "        company_id = row[\"CompanyID\"]\n",
    "        # Expire the current record in MySQL\n",
    "        update_query = f\"\"\"UPDATE dimcompany \n",
    "        SET IsCurrent = 0, EndDate = '{effective_date}' \n",
    "        WHERE CompanyID = '{company_id}' AND IsCurrent = 1\n",
    "        \"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(update_query))\n",
    "            conn.commit()\n",
    "        # Insert updated record\n",
    "        row[\"SK_CompanyID\"] = next_sk_id + 1\n",
    "        row[\"IsCurrent\"] = True\n",
    "        row[\"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "        row_df = pd.DataFrame(row).T\n",
    "        # insert records with existing SK_CompanyID\n",
    "        row_df.to_sql(\n",
    "            \"dimcompany\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "        )        \n",
    "        next_sk_id += 1\n",
    "\n",
    "    return df_cmp, new_records, existing_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimCompany (\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    CompanyID INT UNSIGNED NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Name CHAR(60) NOT NULL,\n",
    "    Industry CHAR(50) NOT NULL,\n",
    "    SPrating CHAR(4),\n",
    "    isLowGrade BOOLEAN,\n",
    "    CEO CHAR(100) NOT NULL,\n",
    "    AddressLine1 CHAR(80),\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12) NOT NULL,\n",
    "    City CHAR(25) NOT NULL,\n",
    "    StateProv CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Description CHAR(150) NOT NULL,\n",
    "    FoundingDate DATE,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_CompanyID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(tqdm(finwire_files)):\n",
    "    load_dimcompany(file, i == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_finwire_fin(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 4, 1, 8, 8, 17, 17, 12, 12, 12, 17, 17, 17, 13, 13, 60]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"Year\", \"Quarter\", \"QtrStartDate\", \"PostingDate\",\n",
    "        \"Revenue\", \"Earnings\", \"EPS\", \"DilutedEPS\", \"Margin\", \"Inventory\",\n",
    "        \"Assets\", \"Liabilities\", \"ShOut\", \"DilutedShOut\", \"CoNameOrCIK\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df_fin = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_fin = df_fin[df_fin['RecType'] == 'FIN']\n",
    "    # Convert PTS to datetime\n",
    "    df_fin['PTS'] = pd.to_datetime(df_fin['PTS'], format='%Y%m%d-%H%M%S')\n",
    "\n",
    "    return df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_duplicate_indices_with_different_values(series):\n",
    "    duplicated_indices = series.index.duplicated(keep=False)\n",
    "    series_duplicates = series[duplicated_indices]\n",
    "\n",
    "    for index in series_duplicates.index.unique():\n",
    "        if series_duplicates.loc[index].drop_duplicates().shape[0] > 1:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_financial():\n",
    "    files = os.listdir(DATA_DIR)\n",
    "    finwire_files = [file for file in files if file.startswith(\"FINWIRE\") and 'audit' not in file]\n",
    "\n",
    "    for filename in tqdm(finwire_files):\n",
    "        file_path = DATA_DIR + filename\n",
    "        df_fin = read_finwire_fin(file_path)\n",
    "        if len(df_fin) == 0:\n",
    "            continue\n",
    "        # datatypes for the mysql table\n",
    "        sql_dtypes = {\n",
    "        \"SK_CompanyID\": sqlalchemy.types.BigInteger,\n",
    "        \"FI_YEAR\": sqlalchemy.types.Integer,\n",
    "        \"FI_QTR\": sqlalchemy.types.SmallInteger,\n",
    "        \"FI_QTR_START_DATE\": sqlalchemy.types.Date,\n",
    "        \"FI_REVENUE\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "        \"FI_NET_EARN\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "        \"FI_BASIC_EPS\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "        \"FI_DILUT_EPS\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "        \"FI_MARGIN\": sqlalchemy.types.Numeric(precision=10, scale=2),\n",
    "        \"FI_INVENTORY\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "        \"FI_ASSETS\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "        \"FI_LIABILITY\": sqlalchemy.types.Numeric(precision=15, scale=2),\n",
    "        \"FI_OUT_BASIC\": sqlalchemy.types.BigInteger,\n",
    "        \"FI_OUT_DILUT\": sqlalchemy.types.BigInteger\n",
    "    }\n",
    "\n",
    "        # data types for the DataFrame\n",
    "        dtypes = {\n",
    "            'SK_CompanyID': 'uint32',\n",
    "            'FI_YEAR': 'uint16',\n",
    "            'FI_QTR': 'uint8',\n",
    "            'FI_QTR_START_DATE': 'datetime64[ns]',\n",
    "            'FI_REVENUE': 'float64',\n",
    "            'FI_NET_EARN': 'float64',\n",
    "            'FI_BASIC_EPS': 'float64',\n",
    "            'FI_DILUT_EPS': 'float64',\n",
    "            'FI_MARGIN': 'float64',\n",
    "            'FI_INVENTORY': 'float64',\n",
    "            'FI_ASSETS': 'float64',\n",
    "            'FI_LIABILITY': 'float64',\n",
    "            'FI_OUT_BASIC': 'uint64',\n",
    "            'FI_OUT_DILUT': 'uint64'\n",
    "        }\n",
    "\n",
    "        # Create empty DataFrame\n",
    "        financial_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in dtypes.items()})\n",
    "\n",
    "        # copy directly\n",
    "        financial_df['FI_YEAR'] = pd.to_numeric(df_fin['Year'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_QTR'] = pd.to_numeric(df_fin['Quarter'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_QTR_START_DATE'] = pd.to_datetime(df_fin['QtrStartDate'], format='%Y%m%d')\n",
    "        financial_df['FI_REVENUE'] = pd.to_numeric(df_fin['Revenue'].str.strip(), downcast='float')\n",
    "        financial_df['FI_NET_EARN'] = pd.to_numeric(df_fin['Earnings'].str.strip(), downcast='float')\n",
    "        financial_df['FI_BASIC_EPS'] = pd.to_numeric(df_fin['EPS'].str.strip(), downcast='float')\n",
    "        financial_df['FI_DILUT_EPS'] = pd.to_numeric(df_fin['DilutedEPS'].str.strip(), downcast='float')\n",
    "        financial_df['FI_MARGIN'] = pd.to_numeric(df_fin['Margin'].str.strip(), downcast='float')\n",
    "        financial_df['FI_INVENTORY'] = pd.to_numeric(df_fin['Inventory'].str.strip(), downcast='float')\n",
    "        financial_df['FI_ASSETS'] = pd.to_numeric(df_fin['Assets'].str.strip(), downcast='float')\n",
    "        financial_df['FI_LIABILITY'] = pd.to_numeric(df_fin['Liabilities'].str.strip(), downcast='float')\n",
    "        financial_df['FI_OUT_BASIC'] = pd.to_numeric(df_fin['ShOut'].str.strip(), downcast='unsigned')\n",
    "        financial_df['FI_OUT_DILUT'] = pd.to_numeric(df_fin['DilutedShOut'].str.strip(), downcast='unsigned')\n",
    "\n",
    "        # Split df_fin based on the length of CoNameOrCIK\n",
    "        df_fin_id = df_fin[df_fin['CoNameOrCIK'].str.len() == 10][['PTS', 'CoNameOrCIK']]\n",
    "        df_fin_id['PTS'] = df_fin_id['PTS'].dt.strftime('%Y-%m-%d')\n",
    "        df_fin_id['CoNameOrCIK'] = pd.to_numeric(df_fin_id['CoNameOrCIK'], downcast='unsigned')\n",
    "        df_fin_name = df_fin[df_fin['CoNameOrCIK'].str.len() != 10][['PTS', 'CoNameOrCIK']]\n",
    "        df_fin_name['PTS'] = df_fin_name['PTS'].dt.strftime('%Y-%m-%d')\n",
    "        df_fin_name['CoNameOrCIK'] = df_fin_name['CoNameOrCIK'].str.strip()\n",
    "\n",
    "        def build_query(df, id_or_name_col):\n",
    "            '''Function to build SQL query for date range checks'''\n",
    "            query_parts = []\n",
    "            for _, row in df.iterrows():\n",
    "                pts = row['PTS']\n",
    "                if id_or_name_col == 'CompanyID':\n",
    "                    company_id = row['CoNameOrCIK']\n",
    "                    query_part = f\"(CompanyID = {company_id} AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "                else:  # Name\n",
    "                    company_name = row['CoNameOrCIK']\n",
    "                    query_part = f\"(Name = '{company_name}' AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "                query_parts.append(query_part)\n",
    "            return ' OR '.join(query_parts)\n",
    "\n",
    "        # Execute query and map results for ID-based records\n",
    "        if not df_fin_id.empty:\n",
    "            query_id = f\"SELECT CompanyID, SK_CompanyID FROM dimcompany WHERE \" + build_query(df_fin_id, 'CompanyID')\n",
    "            sk_id_map = pd.read_sql_query(query_id, engine).set_index('CompanyID')['SK_CompanyID']            \n",
    "            financial_df.loc[df_fin_id.index, 'SK_CompanyID'] = df_fin_id['CoNameOrCIK'].astype(int).map(sk_id_map)\n",
    "\n",
    "        # Execute query and map results for Name-based records\n",
    "        if not df_fin_name.empty:\n",
    "            query_name = f\"SELECT Name, SK_CompanyID FROM dimcompany WHERE \" + build_query(df_fin_name, 'Name')\n",
    "            sk_name_map = pd.read_sql_query(query_name, engine).set_index('Name')['SK_CompanyID']\n",
    "            financial_df.loc[df_fin_name.index, 'SK_CompanyID'] = df_fin_name['CoNameOrCIK'].map(sk_name_map)\n",
    "\n",
    "        financial_df['SK_CompanyID'] = financial_df['SK_CompanyID'].astype('uint32')\n",
    "\n",
    "        # perform migration\n",
    "        financial_df.to_sql('financial', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Financial (\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    FI_YEAR YEAR NOT NULL,\n",
    "    FI_QTR TINYINT UNSIGNED NOT NULL CHECK (FI_QTR IN (1, 2, 3, 4)),\n",
    "    FI_QTR_START_DATE DATE NOT NULL,\n",
    "    FI_REVENUE DECIMAL(15, 2) NOT NULL,\n",
    "    FI_NET_EARN DECIMAL(15, 2) NOT NULL,\n",
    "    FI_BASIC_EPS DECIMAL(10, 2) NOT NULL,\n",
    "    FI_DILUT_EPS DECIMAL(10, 2) NOT NULL,\n",
    "    FI_MARGIN DECIMAL(10, 2) NOT NULL,\n",
    "    FI_INVENTORY DECIMAL(15, 2) NOT NULL,\n",
    "    FI_ASSETS DECIMAL(15, 2) NOT NULL,\n",
    "    FI_LIABILITY DECIMAL(15, 2) NOT NULL,\n",
    "    FI_OUT_BASIC BIGINT NOT NULL,\n",
    "    FI_OUT_DILUT BIGINT NOT NULL,\n",
    "    PRIMARY KEY (SK_CompanyID, FI_YEAR, FI_QTR)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_financial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimSecurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_finwire_sec(file_path):\n",
    "    # Define the column widths and names\n",
    "    col_widths = [15, 3, 15, 6, 4, 70, 6, 13, 8, 8, 12, 60]\n",
    "    col_names = [\n",
    "        \"PTS\", \"RecType\", \"Symbol\", \"IssueType\", \"Status\", \"Name\", \"ExID\",\n",
    "        \"ShOut\", \"FirstTradeDate\", \"FirstTradeExchg\", \"Dividend\", \"CoNameOrCIK\"\n",
    "    ]\n",
    "    # Read the fixed-width file\n",
    "    df_sec = pd.read_fwf(file_path, widths=col_widths, header=None, names=col_names)\n",
    "    # Filter the DataFrame for CMP records\n",
    "    df_sec = df_sec[df_sec['RecType'] == 'SEC']\n",
    "    # Convert date cols to datetime\n",
    "    df_sec['PTS'] = pd.to_datetime(df_sec['PTS'], format='%Y%m%d-%H%M%S')\n",
    "    df_sec['FirstTradeDate'] = pd.to_datetime(df_sec['FirstTradeDate'], format='%Y%m%d')\n",
    "    df_sec['FirstTradeExchg'] = pd.to_datetime(df_sec['FirstTradeExchg'], format='%Y%m%d')\n",
    "\n",
    "    return df_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"Symbol\": sqlalchemy.types.String(15),\n",
    "    \"Issue\": sqlalchemy.types.String(6),\n",
    "    \"Status\": sqlalchemy.types.String(10),\n",
    "    \"Name\": sqlalchemy.types.String(70),\n",
    "    \"ExchangeID\": sqlalchemy.types.String(6),\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SharesOutstanding\": sqlalchemy.types.Integer,\n",
    "    \"FirstTrade\": sqlalchemy.types.Date,\n",
    "    \"FirstTradeOnExchange\": sqlalchemy.types.Date,\n",
    "    \"Dividend\": sqlalchemy.types.Numeric(10, 2),\n",
    "    \"IsCurrent\": sqlalchemy.types.Boolean,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "    \"EffectiveDate\": sqlalchemy.types.Date,\n",
    "    \"EndDate\": sqlalchemy.types.Date,\n",
    "}\n",
    "\n",
    "dtypes = {\n",
    "    \"SK_SecurityID\": \"uint32\",\n",
    "    \"Symbol\": \"str\",\n",
    "    \"Issue\": \"str\",\n",
    "    \"Status\": \"str\",\n",
    "    \"Name\": \"str\",\n",
    "    \"ExchangeID\": \"str\",\n",
    "    \"SK_CompanyID\": \"uint32\",\n",
    "    \"SharesOutstanding\": \"uint32\",\n",
    "    \"FirstTrade\": \"datetime64[ns]\",\n",
    "    \"FirstTradeOnExchange\": \"datetime64[ns]\",\n",
    "    \"Dividend\": \"float64\",\n",
    "    \"IsCurrent\": \"bool\",\n",
    "    \"BatchID\": \"uint8\",\n",
    "    \"EffectiveDate\": \"datetime64[ns]\",\n",
    "    \"EndDate\": \"datetime64[ns]\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query StatusType table and create a mapping dictionary\n",
    "with engine.connect() as conn:\n",
    "    statustype_df = pd.read_sql(\"SELECT * FROM statustype\", conn)\n",
    "status_mapping = dict(statustype_df[['ST_ID', 'ST_NAME']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(df, id_or_name_col):\n",
    "    '''Function to build SQL query for date range checks'''\n",
    "    query_parts = []\n",
    "    for _, row in df.iterrows():\n",
    "        pts = row['PTS']\n",
    "        if id_or_name_col == 'CompanyID':\n",
    "            company_id = row['CoNameOrCIK']\n",
    "            query_part = f\"(CompanyID = {company_id} AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "        else:  # Name\n",
    "            company_name = row['CoNameOrCIK']\n",
    "            query_part = f\"(Name = '{company_name}' AND EffectiveDate <= '{pts}' AND '{pts}' < EndDate)\"\n",
    "        query_parts.append(query_part)\n",
    "    return ' OR '.join(query_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dimsecurity():\n",
    "    finwire_files = os.listdir(DATA_DIR)\n",
    "    finwire_files = [\n",
    "        DATA_DIR + file\n",
    "        for file in finwire_files\n",
    "        if file.startswith(\"FINWIRE\") and \"audit\" not in file\n",
    "    ]\n",
    "    for i, file in enumerate(tqdm(finwire_files)):\n",
    "        # raw data from file\n",
    "        df_sec = read_finwire_sec(file)\n",
    "        # dimension table in data warehouse\n",
    "        security_df = pd.DataFrame(\n",
    "            {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    "        )\n",
    "        # copy directly\n",
    "        security_df[\"Symbol\"] = df_sec[\"Symbol\"]\n",
    "        security_df[\"Issue\"] = df_sec[\"IssueType\"]\n",
    "        security_df[\"Name\"] = df_sec[\"Name\"]\n",
    "        security_df[\"ExchangeID\"] = df_sec[\"ExID\"]\n",
    "        security_df[\"SharesOutstanding\"] = pd.to_numeric(\n",
    "            df_sec[\"ShOut\"], downcast=\"unsigned\"\n",
    "        )\n",
    "        security_df[\"FirstTrade\"] = df_sec[\"FirstTradeDate\"]\n",
    "        security_df[\"FirstTradeOnExchange\"] = df_sec[\"FirstTradeExchg\"]\n",
    "        security_df[\"Dividend\"] = pd.to_numeric(df_sec[\"Dividend\"], downcast=\"float\")\n",
    "        # Update Status in security_df\n",
    "        security_df[\"Status\"] = df_sec[\"Status\"].map(status_mapping)\n",
    "        # BatchID is set to 1\n",
    "        security_df[\"BatchID\"] = 1\n",
    "        # Split df_sec based on the length of CoNameOrCIK\n",
    "        df_sec_id = df_sec[df_sec[\"CoNameOrCIK\"].str.len() == 10][\n",
    "            [\"PTS\", \"CoNameOrCIK\"]\n",
    "        ]\n",
    "        df_sec_id[\"PTS\"] = df_sec_id[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        df_sec_id[\"CoNameOrCIK\"] = pd.to_numeric(\n",
    "            df_sec_id[\"CoNameOrCIK\"], downcast=\"unsigned\"\n",
    "        )\n",
    "        df_sec_name = df_sec[df_sec[\"CoNameOrCIK\"].str.len() != 10][\n",
    "            [\"PTS\", \"CoNameOrCIK\"]\n",
    "        ]\n",
    "        df_sec_name[\"PTS\"] = df_sec_name[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        df_sec_name[\"CoNameOrCIK\"] = df_sec_name[\"CoNameOrCIK\"].str.strip()\n",
    "        # Map results for ID-based records\n",
    "        if not df_sec_id.empty:\n",
    "            query_id = (\n",
    "                f\"SELECT CompanyID, SK_CompanyID FROM dimcompany WHERE \"\n",
    "                + build_query(df_sec_id, \"CompanyID\")\n",
    "            )\n",
    "            sk_id_map = pd.read_sql_query(query_id, engine).set_index(\"CompanyID\")[\n",
    "                \"SK_CompanyID\"\n",
    "            ]\n",
    "            # drop duplicates from the index\n",
    "            sk_id_map = sk_id_map[~sk_id_map.index.duplicated(keep=\"last\")]\n",
    "            security_df.loc[df_sec_id.index, \"SK_CompanyID\"] = (\n",
    "                df_sec_id[\"CoNameOrCIK\"].astype(int).map(sk_id_map)\n",
    "            )\n",
    "        # Map results for Name-based records\n",
    "        if not df_sec_name.empty:\n",
    "            query_name = (\n",
    "                f\"SELECT Name, SK_CompanyID FROM dimcompany WHERE \"\n",
    "                + build_query(df_sec_name, \"Name\")\n",
    "            )\n",
    "            sk_name_map = pd.read_sql_query(query_name, engine).set_index(\"Name\")[\n",
    "                \"SK_CompanyID\"\n",
    "            ]\n",
    "            # drop duplicates from the index\n",
    "            sk_name_map = sk_name_map[~sk_name_map.index.duplicated(keep=\"last\")]\n",
    "            security_df.loc[df_sec_name.index, \"SK_CompanyID\"] = df_sec_name[\n",
    "                \"CoNameOrCIK\"\n",
    "            ].map(sk_name_map)\n",
    "        # change the type back to uint32\n",
    "        security_df[\"SK_CompanyID\"] = security_df[\"SK_CompanyID\"].astype(\"uint32\")\n",
    "        # get effective date from posting date\n",
    "        security_df[\"EffectiveDate\"] = df_sec[\"PTS\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        # Identify new and existing records based on Symbol\n",
    "        is_first_batch = i == 0\n",
    "        if is_first_batch:\n",
    "            new_records = security_df\n",
    "            existing_records = pd.DataFrame(\n",
    "                {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    "            )\n",
    "            next_sk_id = 0\n",
    "        else:\n",
    "            existing_symbol = pd.read_sql_query(\n",
    "                \"SELECT Symbol FROM dimsecurity WHERE IsCurrent = 1\", engine\n",
    "            )[\"Symbol\"]\n",
    "            new_records = security_df[~security_df[\"Symbol\"].isin(existing_symbol)]\n",
    "            existing_records = security_df[security_df[\"Symbol\"].isin(existing_symbol)]\n",
    "            next_sk_id_query = \"SELECT MAX(SK_SecurityID) FROM dimsecurity\"\n",
    "            next_sk_id = pd.read_sql_query(next_sk_id_query, engine).iloc[0, 0] or 0\n",
    "        # update SK_SecurityID, IsCurrent, EndDate\n",
    "        new_records.loc[:, \"SK_SecurityID\"] = range(\n",
    "            next_sk_id + 1, next_sk_id + 1 + len(new_records)\n",
    "        )\n",
    "        new_records.loc[:, \"IsCurrent\"] = True\n",
    "        new_records.loc[:, \"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "        # Insert records with new SK_CompanyID\n",
    "        new_records.to_sql(\n",
    "            \"dimsecurity\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "        )\n",
    "        next_sk_id = new_records[\"SK_SecurityID\"].max()\n",
    "\n",
    "        # Process existing records\n",
    "        for _, row in existing_records.iterrows():\n",
    "            effective_date = row[\"EffectiveDate\"]\n",
    "            symbol = row[\"Symbol\"]\n",
    "            # Expire the current record in MySQL\n",
    "            update_query = f\"\"\"UPDATE dimsecurity \n",
    "            SET IsCurrent = 0, EndDate = '{effective_date}' \n",
    "            WHERE Symbol = '{symbol}' AND IsCurrent = 1\n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(update_query))\n",
    "                conn.commit()\n",
    "            row[\"SK_SecurityID\"] = next_sk_id + 1\n",
    "            row[\"IsCurrent\"] = True\n",
    "            row[\"EndDate\"] = pd.Timestamp(\"9999-12-31\")\n",
    "            row_df = pd.DataFrame(row).T\n",
    "            # insert records with existing SK_CompanyID\n",
    "            row_df.to_sql(\n",
    "                \"dimsecurity\", engine, if_exists=\"append\", index=False, dtype=sql_dtypes\n",
    "            )\n",
    "            next_sk_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimSecurity (\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    Symbol CHAR(15) NOT NULL,\n",
    "    Issue CHAR(6) NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Name CHAR(70) NOT NULL,\n",
    "    ExchangeID CHAR(6) NOT NULL,\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    SharesOutstanding BIGINT UNSIGNED NOT NULL,\n",
    "    FirstTrade DATE NOT NULL,\n",
    "    FirstTradeOnExchange DATE NOT NULL,\n",
    "    Dividend DECIMAL(10, 2) NOT NULL,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_SecurityID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dimsecurity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prospect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prospect_file(filepath):\n",
    "    # Define the column names and their data types\n",
    "    columns = [\n",
    "        'AgencyID', 'LastName', 'FirstName', 'MiddleInitial', 'Gender', \n",
    "        'AddressLine1', 'AddressLine2', 'PostalCode', 'City', 'State', \n",
    "        'Country', 'Phone', 'Income', 'NumberCars', 'NumberChildren', \n",
    "        'MaritalStatus', 'Age', 'CreditRating', 'OwnOrRentFlag', \n",
    "        'Employer', 'NumberCreditCards', 'NetWorth'\n",
    "    ]\n",
    "\n",
    "    # Define the data types for reading the file\n",
    "    dtypes = {\n",
    "        'AgencyID': 'str', 'LastName': 'str', 'FirstName': 'str', \n",
    "        'MiddleInitial': 'str', 'Gender': 'str', 'AddressLine1': 'str', \n",
    "        'AddressLine2': 'str', 'PostalCode': 'str', 'City': 'str', \n",
    "        'State': 'str', 'Country': 'str', 'Phone': 'str', \n",
    "        'Income': 'Int64', 'NumberCars': 'Int8', 'NumberChildren': 'Int8', \n",
    "        'MaritalStatus': 'str', 'Age': 'Int8', 'CreditRating': 'Int16', \n",
    "        'OwnOrRentFlag': 'str', 'Employer': 'str', \n",
    "        'NumberCreditCards': 'Int8', 'NetWorth': 'Int64'\n",
    "    }\n",
    "\n",
    "    # Define custom NA values for string columns, excluding 'nan'\n",
    "    na_values = {column: [] for column in dtypes if dtypes[column] == 'str'}\n",
    "\n",
    "    # Read the CSV file\n",
    "    raw_prospect_df = pd.read_csv(\n",
    "        filepath, \n",
    "        header=None, \n",
    "        names=columns, \n",
    "        dtype=dtypes,\n",
    "        na_values=na_values,  # Use custom NA values for string columns\n",
    "        keep_default_na=False  # This is important to avoid default NA values\n",
    "    )\n",
    "\n",
    "    return raw_prospect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prospect_df = read_prospect_file(DATA_DIR + \"Prospect.csv\")\n",
    "print(raw_prospect_df.info())\n",
    "raw_prospect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'AgencyID': 'str',\n",
    "    'SK_RecordDateID': 'uint32',\n",
    "    'SK_UpdateDateID': 'uint32',\n",
    "    'BatchID': 'uint16',\n",
    "    'IsCustomer': 'boolean',\n",
    "    'LastName': 'str',\n",
    "    'FirstName': 'str',\n",
    "    'MiddleInitial': 'str',\n",
    "    'Gender': 'str',\n",
    "    'AddressLine1': 'str',\n",
    "    'AddressLine2': 'str',\n",
    "    'PostalCode': 'str',\n",
    "    'City': 'str',\n",
    "    'State': 'str',\n",
    "    'Country': 'str',\n",
    "    'Phone': 'str',\n",
    "    'Income': 'uint32',\n",
    "    'NumberCars': 'uint8',\n",
    "    'NumberChildren': 'uint8',\n",
    "    'MaritalStatus': 'str',\n",
    "    'Age': 'uint8',\n",
    "    'CreditRating': 'uint16',\n",
    "    'OwnOrRentFlag': 'str',\n",
    "    'Employer': 'str',\n",
    "    'NumberCreditCards': 'uint8',\n",
    "    'NetWorth': 'int64',\n",
    "    'MarketingNameplate': 'str'\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame with the specified schema\n",
    "prospect_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in dtypes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df[\"AgencyID\"] = raw_prospect_df[\"AgencyID\"]\n",
    "prospect_df[\"LastName\"] = raw_prospect_df[\"LastName\"]\n",
    "prospect_df[\"FirstName\"] = raw_prospect_df[\"FirstName\"]\n",
    "prospect_df[\"MiddleInitial\"] = raw_prospect_df[\"MiddleInitial\"]\n",
    "prospect_df[\"Gender\"] = raw_prospect_df[\"Gender\"]\n",
    "# fix data quality issues\n",
    "prospect_df['Gender'] = prospect_df['Gender'].str.upper()\n",
    "mask = ~prospect_df['Gender'].isin([\"M\", \"F\"])\n",
    "prospect_df.loc[mask, \"Gender\"] = \"U\"\n",
    "prospect_df[\"AddressLine1\"] = raw_prospect_df[\"AddressLine1\"]\n",
    "prospect_df[\"AddressLine2\"] = raw_prospect_df[\"AddressLine2\"]\n",
    "prospect_df[\"PostalCode\"] = raw_prospect_df[\"PostalCode\"]\n",
    "prospect_df[\"City\"] = raw_prospect_df[\"City\"]\n",
    "prospect_df[\"State\"] = raw_prospect_df[\"State\"]\n",
    "prospect_df[\"Country\"] = raw_prospect_df[\"Country\"]\n",
    "prospect_df[\"Phone\"] = raw_prospect_df[\"Phone\"]\n",
    "prospect_df[\"Income\"] = raw_prospect_df[\"Income\"]\n",
    "prospect_df[\"NumberCars\"] = raw_prospect_df[\"NumberCars\"]\n",
    "prospect_df[\"NumberChildren\"] = raw_prospect_df[\"NumberChildren\"]\n",
    "prospect_df[\"MaritalStatus\"] = raw_prospect_df[\"MaritalStatus\"]\n",
    "prospect_df[\"MaritalStatus\"] = prospect_df[\"MaritalStatus\"].str.upper()\n",
    "mask = ~prospect_df[\"MaritalStatus\"].isin([\"S\", \"M\", \"D\", \"W\"])\n",
    "prospect_df.loc[mask, \"MaritalStatus\"] = \"U\"\n",
    "prospect_df[\"Age\"] = raw_prospect_df[\"Age\"]\n",
    "prospect_df[\"CreditRating\"] = raw_prospect_df[\"CreditRating\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = raw_prospect_df[\"OwnOrRentFlag\"]\n",
    "prospect_df[\"OwnOrRentFlag\"] = prospect_df[\"OwnOrRentFlag\"].str.upper()\n",
    "mask = ~prospect_df[\"OwnOrRentFlag\"].isin([\"O\", \"R\"])\n",
    "prospect_df.loc[mask, \"OwnOrRentFlag\"] = \"U\"\n",
    "prospect_df[\"Employer\"] = raw_prospect_df[\"Employer\"]\n",
    "prospect_df[\"NumberCreditCards\"] = raw_prospect_df[\"NumberCreditCards\"]\n",
    "prospect_df[\"NetWorth\"] = raw_prospect_df[\"NetWorth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"BatchDate.txt\", \"r\") as f:\n",
    "    batch_date = f.read().strip()\n",
    "sk_dateid = pd.read_sql_query(f\"select SK_DateID from dimdate where DateValue = '{batch_date}'\", engine).iloc[0, 0]\n",
    "# SK_RecordDateID is set to the DimDate SK_DateID field that corresponds to the Batch Date.\n",
    "prospect_df['SK_RecordDateID'] = sk_dateid\n",
    "# SK_UpdateDateID is set to the DimDate SK_DateID field that corresponds to the Batch Date\n",
    "prospect_df['SK_UpdateDateID'] = sk_dateid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions for each tag with null checks\n",
    "conditions = {\n",
    "    \"HighValue\": (prospect_df[\"NetWorth\"].notnull() & prospect_df[\"Income\"].notnull())\n",
    "    & ((prospect_df[\"NetWorth\"] > 1_000_000) | (prospect_df[\"Income\"] > 200_000)),\n",
    "    \"Expenses\": (\n",
    "        prospect_df[\"NumberChildren\"].notnull()\n",
    "        & prospect_df[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df[\"NumberChildren\"] > 3) | (prospect_df[\"NumberCreditCards\"] > 5)),\n",
    "    \"Boomer\": prospect_df[\"Age\"].notnull() & (prospect_df[\"Age\"] > 45),\n",
    "    \"MoneyAlert\": (\n",
    "        prospect_df[\"Income\"].notnull()\n",
    "        & prospect_df[\"CreditRating\"].notnull()\n",
    "        & prospect_df[\"NetWorth\"].notnull()\n",
    "    )\n",
    "    & (\n",
    "        (prospect_df[\"Income\"] < 50_000)\n",
    "        | (prospect_df[\"CreditRating\"] < 600)\n",
    "        | (prospect_df[\"NetWorth\"] < 100_000)\n",
    "    ),\n",
    "    \"Spender\": (\n",
    "        prospect_df[\"NumberCars\"].notnull() & prospect_df[\"NumberCreditCards\"].notnull()\n",
    "    )\n",
    "    & ((prospect_df[\"NumberCars\"] > 3) | (prospect_df[\"NumberCreditCards\"] > 7)),\n",
    "    \"Inherited\": (prospect_df[\"Age\"].notnull() & prospect_df[\"NetWorth\"].notnull())\n",
    "    & ((prospect_df[\"Age\"] < 25) & (prospect_df[\"NetWorth\"] > 1_000_000)),\n",
    "}\n",
    "\n",
    "# Apply conditions to assign tags\n",
    "prospect_df[\"MarketingNameplate\"] = \"\"\n",
    "for tag, condition in conditions.items():\n",
    "    prospect_df[\"MarketingNameplate\"] += np.where(condition, tag + \"+\", \"\")\n",
    "\n",
    "# Remove trailing '+' and replace empty strings with None\n",
    "prospect_df[\"MarketingNameplate\"] = (\n",
    "    prospect_df[\"MarketingNameplate\"].str.rstrip(\"+\").replace(\"\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IsCurrent and BatchID are set after processing dimCustomer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = DATA_DIR + \"CustomerMgmt.xml\"\n",
    "tree = etree.parse(data_file)\n",
    "namespace = {'tpcdi': 'http://www.tpc.org/tpc-di'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'SK_CustomerID': 'int32',\n",
    "    'CustomerID': 'int32',\n",
    "    'TaxID': 'str',\n",
    "    'Status': 'str',\n",
    "    'LastName': 'str',\n",
    "    'FirstName': 'str',\n",
    "    'MiddleInitial': 'str',\n",
    "    'Gender': 'str',\n",
    "    'Tier': 'UInt8',\n",
    "    'DOB': 'datetime64[ns]',\n",
    "    'AddressLine1': 'str',\n",
    "    'AddressLine2': 'str',\n",
    "    'PostalCode': 'str',\n",
    "    'City': 'str',\n",
    "    'StateProv': 'str',\n",
    "    'Country': 'str',\n",
    "    'Phone1': 'str',\n",
    "    'Phone2': 'str',\n",
    "    'Phone3': 'str',\n",
    "    'Email1': 'str',\n",
    "    'Email2': 'str',\n",
    "    'NationalTaxRateDesc': 'str',\n",
    "    'NationalTaxRate': 'Float64',\n",
    "    'LocalTaxRateDesc': 'str',\n",
    "    'LocalTaxRate': 'Float64',\n",
    "    'AgencyID': 'str',\n",
    "    'CreditRating': 'UInt16',\n",
    "    'NetWorth': 'Float64',\n",
    "    'MarketingNameplate': 'str',\n",
    "    'IsCurrent': 'boolean',\n",
    "    'BatchID': 'uint8',\n",
    "    'EffectiveDate': 'datetime64[ns]',\n",
    "    'EndDate': 'datetime64[ns]'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_phone_number(phone_element):\n",
    "    # Extract components of the phone number\n",
    "    ctry_code = phone_element.findtext('C_CTRY_CODE', default=None, namespaces=namespace)\n",
    "    area_code = phone_element.findtext('C_AREA_CODE', default=None, namespaces=namespace)\n",
    "    local = phone_element.findtext('C_LOCAL', default=None, namespaces=namespace)\n",
    "    ext = phone_element.findtext('C_EXT', default=None, namespaces=namespace)\n",
    "\n",
    "    # Apply transformation rules\n",
    "    if ctry_code and area_code and local:\n",
    "        phone = f\"+{ctry_code} ({area_code}) {local}\"\n",
    "    elif area_code and local:\n",
    "        phone = f\"({area_code}) {local}\"\n",
    "    elif local:\n",
    "        phone = local\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # Add extension if present\n",
    "    if ext:\n",
    "        phone += ext\n",
    "\n",
    "    return phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tax_info(tax_ids):\n",
    "    tax_ids_str = \"','\".join(tax_ids)\n",
    "    query = f\"SELECT TX_ID, TX_NAME, TX_RATE FROM taxrate WHERE TX_ID IN ('{tax_ids_str}')\"\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    return result.set_index('TX_ID').to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"BatchDate.txt\", \"r\") as f:\n",
    "    batch_date = f.read().strip()\n",
    "batch_date = pd.to_datetime(batch_date, format=\"%Y-%m-%d\")\n",
    "batch_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the latest index of 'UPDCUST' or 'INACT' for each CustomerID\n",
    "latest_updates = {}\n",
    "\n",
    "# Get all actions\n",
    "all_actions = tree.xpath(\".//tpcdi:Action\", namespaces=namespace)\n",
    "# NEW actions\n",
    "new_actions = [action for action in all_actions if action.get('ActionType') == 'NEW']\n",
    "# UPD actions\n",
    "upd_actions = [action for action in all_actions if action.get('ActionType') == 'UPDCUST']\n",
    "# INACT actions\n",
    "inact_actions = [action for action in all_actions if action.get('ActionType') == 'INACT']\n",
    "\n",
    "# Preprocess to fill the dictionary\n",
    "for i, action in enumerate(all_actions):\n",
    "    if action.get('ActionType') in ['UPDCUST', 'INACT']:\n",
    "        customer = action.find('Customer', namespaces=namespace)\n",
    "        customer_id = customer.get('C_ID', None)\n",
    "        if customer_id:\n",
    "            latest_updates[int(customer_id)] = i\n",
    "\n",
    "# Modified has_later_update function\n",
    "def has_later_update(customer_id, current_index):\n",
    "    \"\"\"Check for subsequent 'UPDCUST' or 'INACT' actions for a given CustomerID at current_index\"\"\"\n",
    "    return latest_updates.get(customer_id, -1) > current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified schema\n",
    "dimCustomer_df = pd.DataFrame(\n",
    "    {col: pd.Series(dtype=typ) for col, typ in dtypes.items()}\n",
    ")\n",
    "\n",
    "# Initialize lists to store tax IDs for each record\n",
    "national_tax_ids = []\n",
    "local_tax_ids = []\n",
    "\n",
    "# temporary prospect_df for matching\n",
    "prospect_df_temp = prospect_df[\n",
    "    [\n",
    "        \"AgencyID\",\n",
    "        \"CreditRating\",\n",
    "        \"NetWorth\",\n",
    "        \"MarketingNameplate\",\n",
    "        \"LastName\",\n",
    "        \"FirstName\",\n",
    "        \"AddressLine1\",\n",
    "        \"AddressLine2\",\n",
    "        \"PostalCode\",\n",
    "    ]\n",
    "].copy()\n",
    "prospect_df_temp[\"LastName\"] = prospect_df_temp[\"LastName\"].str.upper()\n",
    "prospect_df_temp[\"FirstName\"] = prospect_df_temp[\"FirstName\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine1\"] = prospect_df_temp[\"AddressLine1\"].str.upper()\n",
    "prospect_df_temp[\"AddressLine2\"] = prospect_df_temp[\"AddressLine2\"].str.upper()\n",
    "prospect_df_temp[\"PostalCode\"] = prospect_df_temp[\"PostalCode\"].str.upper()\n",
    "\n",
    "\n",
    "# Initialize lists to store data for NEW actions\n",
    "data = {\n",
    "    \"CustomerID\": [],\n",
    "    \"TaxID\": [],\n",
    "    \"LastName\": [],\n",
    "    \"FirstName\": [],\n",
    "    \"MiddleInitial\": [],\n",
    "    \"Tier\": [],\n",
    "    \"DOB\": [],\n",
    "    \"Gender\": [],\n",
    "    \"Email1\": [],\n",
    "    \"Email2\": [],\n",
    "    \"AddressLine1\": [],\n",
    "    \"AddressLine2\": [],\n",
    "    \"PostalCode\": [],\n",
    "    \"City\": [],\n",
    "    \"StateProv\": [],\n",
    "    \"Country\": [],\n",
    "    \"Phone1\": [],\n",
    "    \"Phone2\": [],\n",
    "    \"Phone3\": [],\n",
    "    \"NationalTaxRateDesc\": [],\n",
    "    \"NationalTaxRate\": [],\n",
    "    \"LocalTaxRateDesc\": [],\n",
    "    \"LocalTaxRate\": [],\n",
    "    \"AgencyID\": [],\n",
    "    \"CreditRating\": [],\n",
    "    \"NetWorth\": [],\n",
    "    \"MarketingNameplate\": [],\n",
    "    \"EffectiveDate\": [],\n",
    "}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"NEW\"\n",
    "for index, action in enumerate(tqdm(new_actions)):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    name = customer.find(\"Name\", namespaces=namespace)\n",
    "    contact_info = customer.find(\"ContactInfo\", namespaces=namespace)\n",
    "    address = customer.find(\"Address\", namespaces=namespace)\n",
    "    tax_info = customer.find(\"TaxInfo\", namespaces=namespace)\n",
    "\n",
    "    customer_id = customer.get(\"C_ID\", None)\n",
    "    customer_id = int(customer_id) if customer_id else None\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "    data[\"TaxID\"].append(customer.get(\"C_TAX_ID\", None))\n",
    "    tier = customer.get(\"C_TIER\", None)\n",
    "    tier = int(tier) if tier else None\n",
    "    if tier is not None and tier not in (1,2,3):\n",
    "        \"\"\"\n",
    "        A record will be inserted in the DImessages table if a customer's Tier is not one of the valid\n",
    "        values (1,2,3). The MessageSource is “DimCustomer”, the MessageType is “Alert” and the\n",
    "        MessageText is “Invalid customer tier”. The MessageData field is “C_ID = ” followed by the\n",
    "        natural key value of the record, then “, C_TIER = ” and the C_TIER value.\n",
    "        \"\"\"\n",
    "        MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "        batch_id = 1\n",
    "        sk_customer_id = len(data[\"CustomerID\"])\n",
    "        message = f\"C_ID = {sk_customer_id}, C_TIER = {tier}\"\n",
    "        message_source = \"DimCustomer\"\n",
    "        message_type = \"Alert\"\n",
    "        message_text = \"Invalid customer tier\"\n",
    "        query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "        VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "\n",
    "    data[\"Tier\"].append(tier)\n",
    "    dob = customer.get(\"C_DOB\", None)\n",
    "    dob = pd.to_datetime(dob, format=\"%Y-%m-%d\") if dob else None\n",
    "    \"\"\"A record will be reported in the DImessages table if a customer's DOB is invalid. A customer's\n",
    "    DOB is invalid if DOB < Batch Date - 100 years or DOB > Batch Date (customer is over 100\n",
    "    years old or born in the future). The MessageSource is “DimCustomer”, the MessageType is\n",
    "    “Alert” and the MessageText is “DOB out of range”. The MessageData field is “C_ID = ”\n",
    "    followed by the natural key value of the record, then “, C_DOB = ” and the C_DOB value.\"\"\"\n",
    "    if dob and (dob < batch_date - pd.Timedelta(days=100*365) or dob > batch_date):\n",
    "        MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "        batch_id = 1\n",
    "        sk_customer_id = len(data[\"CustomerID\"])\n",
    "        message = f\"C_ID = {sk_customer_id}, C_DOB = {dob}\"\n",
    "        message_source = \"DimCustomer\"\n",
    "        message_type = \"Alert\"\n",
    "        message_text = \"DOB out of range\"\n",
    "        query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "        VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(query))\n",
    "            conn.commit()\n",
    "    data[\"DOB\"].append(dob)\n",
    "    gender = customer.get(\"C_GNDR\", \"U\")\n",
    "    gender = \"U\" if gender not in (\"M\", \"F\") else gender\n",
    "    data[\"Gender\"].append(gender)\n",
    "    \n",
    "    first_name = name.findtext(\"C_F_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"FirstName\"].append(first_name if first_name else None)\n",
    "    middle_initial = name.findtext(\"C_M_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"MiddleInitial\"].append(middle_initial if middle_initial else None)\n",
    "    last_name = name.findtext(\"C_L_NAME\", default=None, namespaces=namespace)\n",
    "    data[\"LastName\"].append(last_name if last_name else None)\n",
    "\n",
    "    \n",
    "    prim_email = contact_info.findtext(\n",
    "        \"C_PRIM_EMAIL\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"Email1\"].append(prim_email if prim_email else None)\n",
    "    alt_email = contact_info.findtext(\n",
    "        \"C_ALT_EMAIL\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"Email2\"].append(alt_email if alt_email else None)\n",
    "    data[\"Phone1\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_1\", namespaces=namespace))\n",
    "    )\n",
    "    data[\"Phone2\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_2\", namespaces=namespace))\n",
    "    )\n",
    "    data[\"Phone3\"].append(\n",
    "        format_phone_number(contact_info.find(\"C_PHONE_3\", namespaces=namespace))\n",
    "    )\n",
    "\n",
    "    # Extracting address information\n",
    "    address_line1 = address.findtext(\n",
    "        \"C_ADLINE1\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"AddressLine1\"].append(address_line1 if address_line1 else None)\n",
    "    address_line2 = address.findtext(\n",
    "        \"C_ADLINE2\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"AddressLine2\"].append(address_line2 if address_line2 else None)\n",
    "    postalcode = address.findtext(\"C_ZIPCODE\", default=None, namespaces=namespace)\n",
    "    data[\"PostalCode\"].append(postalcode if postalcode else None)\n",
    "    city = address.findtext(\"C_CITY\", default=None, namespaces=namespace)\n",
    "    data[\"City\"].append(city if city else None)\n",
    "    state_prov = address.findtext(\n",
    "        \"C_STATE_PROV\", default=None, namespaces=namespace\n",
    "    )\n",
    "    data[\"StateProv\"].append(state_prov if state_prov else None)\n",
    "    country = address.findtext(\"C_CTRY\", default=None, namespaces=namespace)\n",
    "    data[\"Country\"].append(country if country else None)\n",
    "    \n",
    "    # Store TX_ID as placeholders\n",
    "    national_tax_id = tax_info.findtext(\n",
    "        \"C_NAT_TX_ID\", default=None, namespaces=namespace\n",
    "    )\n",
    "    national_tax_id = national_tax_id if national_tax_id else None\n",
    "    national_tax_ids.append(national_tax_id)\n",
    "    local_tax_id = tax_info.findtext(\n",
    "        \"C_LCL_TX_ID\", default=None, namespaces=namespace\n",
    "    )\n",
    "    local_tax_id = local_tax_id if local_tax_id else None\n",
    "    local_tax_ids.append(local_tax_id)\n",
    "\n",
    "    if not has_later_update(customer_id, index):\n",
    "        # Find matching prospect record\n",
    "        match = prospect_df[\n",
    "            (prospect_df_temp[\"LastName\"] == last_name.upper())\n",
    "            & (prospect_df_temp[\"FirstName\"] == first_name.upper())\n",
    "            & (prospect_df_temp[\"AddressLine1\"] == address_line1.upper())\n",
    "            & (prospect_df_temp[\"AddressLine2\"] == address_line2.upper())\n",
    "            & (prospect_df_temp[\"PostalCode\"] == postalcode.upper())\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            # Set values from the matching prospect record\n",
    "            data[\"AgencyID\"].append(match[\"AgencyID\"].iloc[0])\n",
    "            data[\"CreditRating\"].append(match[\"CreditRating\"].iloc[0])\n",
    "            data[\"NetWorth\"].append(match[\"NetWorth\"].iloc[0])\n",
    "            data[\"MarketingNameplate\"].append(match[\"MarketingNameplate\"].iloc[0])\n",
    "        else:\n",
    "            # Set values to NULL\n",
    "            data[\"AgencyID\"].append(None)\n",
    "            data[\"CreditRating\"].append(None)\n",
    "            data[\"NetWorth\"].append(None)\n",
    "            data[\"MarketingNameplate\"].append(None)\n",
    "    else:\n",
    "        # Set values to NULL due to later 'UPDCUST' or 'INACT'\n",
    "        data[\"AgencyID\"].append(None)\n",
    "        data[\"CreditRating\"].append(None)\n",
    "        data[\"NetWorth\"].append(None)\n",
    "        data[\"MarketingNameplate\"].append(None)\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Get unique TX_IDs and remove None values \n",
    "unique_tax_ids = set(national_tax_ids + local_tax_ids) - {None}\n",
    "all_tax_info = get_all_tax_info(unique_tax_ids)\n",
    "\n",
    "# map each tax ID to its description and rate\n",
    "for i in range(len(national_tax_ids)):\n",
    "    national_info = all_tax_info.get(\n",
    "        national_tax_ids[i], {\"TX_NAME\": None, \"TX_RATE\": None}\n",
    "    )\n",
    "    data[\"NationalTaxRateDesc\"].append(national_info[\"TX_NAME\"])\n",
    "    data[\"NationalTaxRate\"].append(national_info[\"TX_RATE\"])\n",
    "\n",
    "    local_info = all_tax_info.get(local_tax_ids[i], {\"TX_NAME\": None, \"TX_RATE\": None})\n",
    "    data[\"LocalTaxRateDesc\"].append(local_info[\"TX_NAME\"])\n",
    "    data[\"LocalTaxRate\"].append(local_info[\"TX_RATE\"])\n",
    "\n",
    "# Creating DataFrame\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, pd.DataFrame(data)])\n",
    "dimCustomer_df[\"Status\"] = \"ACTIVE\"\n",
    "print(dimCustomer_df.info())\n",
    "dimCustomer_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2dict(df, exclude_columns):\n",
    "    # Remove the specified columns from the DataFrame\n",
    "    df_filtered = df.drop(columns=exclude_columns)\n",
    "    # Convert the filtered DataFrame to a dictionary\n",
    "    df_dict = df_filtered.to_dict(orient='index')\n",
    "    # Create a new dictionary that maps CustomerID to a dictionary of column values\n",
    "    customer_dict = {row['CustomerID']: {col: val for col, val in row.items() if col != 'CustomerID'} for _, row in df_dict.items()}\n",
    "    return customer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['SK_CustomerID', 'IsCurrent', 'BatchID', 'EffectiveDate', 'EndDate', 'Status']\n",
    "# dictionary to track latest values for each customer\n",
    "customer_data = df2dict(dimCustomer_df, exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data for NEW actions\n",
    "data = {col: [] for col in data.keys()}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"UPDCUST\"\n",
    "for index, action in enumerate(upd_actions):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    name = customer.find(\"Name\", namespaces=namespace)\n",
    "    contact_info = customer.find(\"ContactInfo\", namespaces=namespace)\n",
    "    address = customer.find(\"Address\", namespaces=namespace)\n",
    "    tax_info = customer.find(\"TaxInfo\", namespaces=namespace)\n",
    "\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "\n",
    "    # Update tax_id\n",
    "    tax_id = customer.get(\"C_TAX_ID\", None)\n",
    "    if tax_id is None:\n",
    "        tax_id = customer_data[customer_id][\"TaxID\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"TaxID\"] = tax_id\n",
    "    data[\"TaxID\"].append(tax_id)\n",
    "    # Update tier\n",
    "    tier = customer.get(\"C_TIER\", None)\n",
    "    tier = int(tier) if tier else None\n",
    "    if tier is None:\n",
    "        tier = customer_data[customer_id][\"Tier\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"Tier\"] = tier\n",
    "        if tier is not None and tier not in (1,2,3):\n",
    "            \"\"\"\n",
    "            A record will be inserted in the DImessages table if a customer's Tier is not one of the valid\n",
    "            values (1,2,3). The MessageSource is “DimCustomer”, the MessageType is “Alert” and the\n",
    "            MessageText is “Invalid customer tier”. The MessageData field is “C_ID = ” followed by the\n",
    "            natural key value of the record, then “, C_TIER = ” and the C_TIER value.\n",
    "            \"\"\"\n",
    "            MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "            batch_id = 1\n",
    "            sk_customer_id = len(data[\"CustomerID\"]) + dimCustomer_df.shape[0]\n",
    "            message = f\"C_ID = {sk_customer_id}, C_TIER = {tier}\"\n",
    "            message_source = \"DimCustomer\"\n",
    "            message_type = \"Alert\"\n",
    "            message_text = \"Invalid customer tier\"\n",
    "            query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(query))\n",
    "                conn.commit()\n",
    "    data[\"Tier\"].append(tier)\n",
    "    # Update DOB\n",
    "    dob = customer.get(\"C_DOB\", None)\n",
    "    dob = pd.to_datetime(dob, format=\"%Y-%m-%d\") if dob else None\n",
    "    if dob is None:\n",
    "        dob = customer_data[customer_id][\"DOB\"]\n",
    "    else:\n",
    "        customer_data[customer_id][\"DOB\"] = dob\n",
    "        \"\"\"A record will be reported in the DImessages table if a customer's DOB is invalid. A customer's\n",
    "        DOB is invalid if DOB < Batch Date - 100 years or DOB > Batch Date (customer is over 100\n",
    "        years old or born in the future). The MessageSource is “DimCustomer”, the MessageType is\n",
    "        “Alert” and the MessageText is “DOB out of range”. The MessageData field is “C_ID = ”\n",
    "        followed by the natural key value of the record, then “, C_DOB = ” and the C_DOB value.\"\"\"\n",
    "        if dob and (dob < batch_date - pd.Timedelta(days=100*365) or dob > batch_date):\n",
    "            MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "            batch_id = 1\n",
    "            sk_customer_id = len(data[\"CustomerID\"])\n",
    "            message = f\"C_ID = {sk_customer_id}, C_DOB = {dob}\"\n",
    "            message_source = \"DimCustomer\"\n",
    "            message_type = \"Alert\"\n",
    "            message_text = \"DOB out of range\"\n",
    "            query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{message}')\"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                conn.execute(text(query))\n",
    "                conn.commit()\n",
    "    data[\"DOB\"].append(dob)\n",
    "    # Update gender\n",
    "    gender = customer.get(\"C_GNDR\", None)\n",
    "    if gender is None:\n",
    "        gender = customer_data[customer_id][\"Gender\"]\n",
    "    else:\n",
    "        gender = \"U\" if gender not in (\"M\", \"F\") else gender\n",
    "        customer_data[customer_id][\"Gender\"] = gender\n",
    "    data[\"Gender\"].append(gender)\n",
    "\n",
    "    # Update first name\n",
    "    if name is None:\n",
    "        first_name = customer_data[customer_id][\"FirstName\"]\n",
    "        data[\"FirstName\"].append(first_name)\n",
    "        middle_initial = customer_data[customer_id][\"MiddleInitial\"]\n",
    "        data[\"MiddleInitial\"].append(middle_initial)\n",
    "        last_name = customer_data[customer_id][\"LastName\"]\n",
    "        data[\"LastName\"].append(last_name)\n",
    "    else:\n",
    "        first_name = name.findtext(\"C_F_NAME\", default=None, namespaces=namespace)\n",
    "        if first_name is None:\n",
    "            first_name = customer_data[customer_id][\"FirstName\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"FirstName\"] = first_name\n",
    "        data[\"FirstName\"].append(first_name)\n",
    "        # Update middle initial\n",
    "        middle_initial = name.findtext(\"C_M_NAME\", default=None, namespaces=namespace)\n",
    "        if middle_initial is None:\n",
    "            middle_initial = customer_data[customer_id][\"MiddleInitial\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"MiddleInitial\"] = middle_initial\n",
    "        data[\"MiddleInitial\"].append(middle_initial)\n",
    "        # Update last name\n",
    "        last_name = name.findtext(\"C_L_NAME\", default=None, namespaces=namespace)\n",
    "        if last_name is None:\n",
    "            last_name = customer_data[customer_id][\"LastName\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"LastName\"] = last_name\n",
    "        data[\"LastName\"].append(last_name if last_name else None)\n",
    "\n",
    "    if contact_info is None:\n",
    "        prim_email = customer_data[customer_id][\"Email1\"]\n",
    "        data[\"Email1\"].append(prim_email)\n",
    "        alt_email = customer_data[customer_id][\"Email2\"]\n",
    "        data[\"Email2\"].append(alt_email)\n",
    "        phone1 = customer_data[customer_id][\"Phone1\"]\n",
    "        data[\"Phone1\"].append(phone1)\n",
    "        phone2 = customer_data[customer_id][\"Phone2\"]\n",
    "        data[\"Phone2\"].append(phone2)\n",
    "        phone3 = customer_data[customer_id][\"Phone3\"]\n",
    "        data[\"Phone3\"].append(phone3)\n",
    "    else:\n",
    "        # update primary email\n",
    "        prim_email = contact_info.findtext(\n",
    "            \"C_PRIM_EMAIL\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if prim_email is None:\n",
    "            prim_email = customer_data[customer_id][\"Email1\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Email1\"] = prim_email\n",
    "        data[\"Email1\"].append(prim_email if prim_email else None)\n",
    "        # update alternate email\n",
    "        alt_email = contact_info.findtext(\n",
    "            \"C_ALT_EMAIL\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if alt_email is None:\n",
    "            alt_email = customer_data[customer_id][\"Email2\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Email2\"] = alt_email\n",
    "        data[\"Email2\"].append(alt_email if alt_email else None)\n",
    "        # update phone numbers\n",
    "        phone1 = contact_info.find(\"C_PHONE_1\", namespaces=namespace)\n",
    "        if phone1 is None:\n",
    "            phone1 = customer_data[customer_id][\"Phone1\"]\n",
    "        else:\n",
    "            phone1 = format_phone_number(phone1)\n",
    "            customer_data[customer_id][\"Phone1\"] = phone1\n",
    "        data[\"Phone1\"].append(phone1)\n",
    "        phone2 = contact_info.find(\"C_PHONE_2\", namespaces=namespace)\n",
    "        if phone2 is None:\n",
    "            phone2 = customer_data[customer_id][\"Phone2\"]\n",
    "        else:\n",
    "            phone2 = format_phone_number(phone2)\n",
    "            customer_data[customer_id][\"Phone2\"] = phone2\n",
    "        data[\"Phone2\"].append(phone2)\n",
    "        phone3 = contact_info.find(\"C_PHONE_3\", namespaces=namespace)\n",
    "        if phone3 is None:\n",
    "            phone3 = customer_data[customer_id][\"Phone3\"]\n",
    "        else:\n",
    "            phone3 = format_phone_number(phone3)\n",
    "            customer_data[customer_id][\"Phone3\"] = phone3\n",
    "        data[\"Phone3\"].append(phone3)\n",
    "\n",
    "    if address is None:\n",
    "        address_line1 = customer_data[customer_id][\"AddressLine1\"]\n",
    "        data[\"AddressLine1\"].append(address_line1)\n",
    "        address_line2 = customer_data[customer_id][\"AddressLine2\"]\n",
    "        data[\"AddressLine2\"].append(address_line2)\n",
    "        postalcode = customer_data[customer_id][\"PostalCode\"]\n",
    "        data[\"PostalCode\"].append(postalcode)\n",
    "        city = customer_data[customer_id][\"City\"]\n",
    "        data[\"City\"].append(city)\n",
    "        state_prov = customer_data[customer_id][\"StateProv\"]\n",
    "        data[\"StateProv\"].append(state_prov)\n",
    "        country = customer_data[customer_id][\"Country\"]\n",
    "        data[\"Country\"].append(country)\n",
    "    else:\n",
    "        # Extracting address information\n",
    "        address_line1 = address.findtext(\n",
    "            \"C_ADLINE1\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if address_line1 is None:\n",
    "            address_line1 = customer_data[customer_id][\"AddressLine1\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"AddressLine1\"] = address_line1\n",
    "        data[\"AddressLine1\"].append(address_line1 if address_line1 else None)\n",
    "        address_line2 = address.findtext(\n",
    "            \"C_ADLINE2\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if address_line2 is None:\n",
    "            address_line2 = customer_data[customer_id][\"AddressLine2\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"AddressLine2\"] = address_line2\n",
    "        data[\"AddressLine2\"].append(address_line2 if address_line2 else None)\n",
    "        postalcode = address.findtext(\"C_ZIPCODE\", default=None, namespaces=namespace)\n",
    "        if postalcode is None:\n",
    "            postalcode = customer_data[customer_id][\"PostalCode\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"PostalCode\"] = postalcode\n",
    "        data[\"PostalCode\"].append(postalcode if postalcode else None)\n",
    "        city = address.findtext(\"C_CITY\", default=None, namespaces=namespace)\n",
    "        if city is None:\n",
    "            city = customer_data[customer_id][\"City\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"City\"] = city\n",
    "        data[\"City\"].append(city if city else None)\n",
    "        state_prov = address.findtext(\n",
    "            \"C_STATE_PROV\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if state_prov is None:\n",
    "            state_prov = customer_data[customer_id][\"StateProv\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"StateProv\"] = state_prov\n",
    "        data[\"StateProv\"].append(state_prov if state_prov else None)\n",
    "        country = address.findtext(\"C_CTRY\", default=None, namespaces=namespace)\n",
    "        if country is None:\n",
    "            country = customer_data[customer_id][\"Country\"]\n",
    "        else:\n",
    "            customer_data[customer_id][\"Country\"] = country\n",
    "        data[\"Country\"].append(country if country else None)\n",
    "    \n",
    "    # Store TX_ID as placeholders\n",
    "    if tax_info is None:\n",
    "        national_tax_rate_desc = customer_data[customer_id][\"NationalTaxRateDesc\"]\n",
    "        data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "        national_tax_rate = customer_data[customer_id][\"NationalTaxRate\"]\n",
    "        data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "        local_tax_rate_desc = customer_data[customer_id][\"LocalTaxRateDesc\"]\n",
    "        data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "        local_tax_rate = customer_data[customer_id][\"LocalTaxRate\"]\n",
    "        data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "        national_tax_ids.append(None)\n",
    "        local_tax_ids.append(None)        \n",
    "    else:\n",
    "        national_tax_id = tax_info.findtext(\n",
    "            \"C_NAT_TX_ID\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if national_tax_id is None:\n",
    "            national_tax_rate_desc = customer_data[customer_id][\"NationalTaxRateDesc\"]\n",
    "            data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "            national_tax_rate = customer_data[customer_id][\"NationalTaxRate\"]\n",
    "            data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "            national_tax_ids.append(None)\n",
    "        else:\n",
    "            result = pd.read_sql(f\"SELECT TX_NAME, TX_RATE FROM taxrate WHERE TX_ID = '{national_tax_id}'\", engine)\n",
    "            national_tax_rate_desc = result.iloc[0, 0]\n",
    "            national_tax_rate = result.iloc[0, 1]\n",
    "            customer_data[customer_id][\"NationalTaxRateDesc\"] = national_tax_rate_desc\n",
    "            customer_data[customer_id][\"NationalTaxRate\"] = national_tax_rate\n",
    "            data[\"NationalTaxRateDesc\"].append(national_tax_rate_desc)\n",
    "            data[\"NationalTaxRate\"].append(national_tax_rate)\n",
    "        local_tax_id = tax_info.findtext(\n",
    "            \"C_LCL_TX_ID\", default=None, namespaces=namespace\n",
    "        )\n",
    "        if local_tax_id is None:\n",
    "            local_tax_rate_desc = customer_data[customer_id][\"LocalTaxRateDesc\"]\n",
    "            data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "            local_tax_rate = customer_data[customer_id][\"LocalTaxRate\"]\n",
    "            data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "        else:\n",
    "            result = pd.read_sql(f\"SELECT TX_NAME, TX_RATE FROM taxrate WHERE TX_ID = '{local_tax_id}'\", engine)\n",
    "            local_tax_rate_desc = result.iloc[0, 0]\n",
    "            local_tax_rate = result.iloc[0, 1]\n",
    "            customer_data[customer_id][\"LocalTaxRateDesc\"] = local_tax_rate_desc\n",
    "            customer_data[customer_id][\"LocalTaxRate\"] = local_tax_rate\n",
    "            data[\"LocalTaxRateDesc\"].append(local_tax_rate_desc)\n",
    "            data[\"LocalTaxRate\"].append(local_tax_rate)\n",
    "\n",
    "\n",
    "    if not has_later_update(customer_id, index):\n",
    "        # Find matching prospect record\n",
    "        match = prospect_df[\n",
    "            (prospect_df_temp[\"LastName\"] == last_name.upper())\n",
    "            & (prospect_df_temp[\"FirstName\"] == first_name.upper())\n",
    "            & (prospect_df_temp[\"AddressLine1\"] == address_line1.upper())\n",
    "            & (prospect_df_temp[\"AddressLine2\"] == address_line2.upper())\n",
    "            & (prospect_df_temp[\"PostalCode\"] == postalcode.upper())\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            # Set values from the matching prospect record\n",
    "            data[\"AgencyID\"].append(match[\"AgencyID\"].iloc[0])\n",
    "            data[\"CreditRating\"].append(match[\"CreditRating\"].iloc[0])\n",
    "            data[\"NetWorth\"].append(match[\"NetWorth\"].iloc[0])\n",
    "            data[\"MarketingNameplate\"].append(match[\"MarketingNameplate\"].iloc[0])\n",
    "        else:\n",
    "            # Set values to those in customer_data\n",
    "            data[\"AgencyID\"].append(customer_data[customer_id][\"AgencyID\"])\n",
    "            data[\"CreditRating\"].append(customer_data[customer_id][\"CreditRating\"])\n",
    "            data[\"NetWorth\"].append(customer_data[customer_id][\"NetWorth\"])\n",
    "            data[\"MarketingNameplate\"].append(customer_data[customer_id][\"MarketingNameplate\"])\n",
    "    else:\n",
    "        # Set values to those in customer_data due to later 'UPDCUST' or 'INACT'\n",
    "        data[\"AgencyID\"].append(customer_data[customer_id][\"AgencyID\"])\n",
    "        data[\"CreditRating\"].append(customer_data[customer_id][\"CreditRating\"])\n",
    "        data[\"NetWorth\"].append(customer_data[customer_id][\"NetWorth\"])\n",
    "        data[\"MarketingNameplate\"].append(customer_data[customer_id][\"MarketingNameplate\"])\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Creating DataFrame\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, pd.DataFrame(data)])\n",
    "dimCustomer_df[\"Status\"] = \"ACTIVE\"\n",
    "print(dimCustomer_df.info())\n",
    "dimCustomer_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data for NEW actions\n",
    "data = {col: [] for col in data.keys()}\n",
    "\n",
    "# Iterate through each 'Action' element with ActionType=\"INACT\"\n",
    "for index, action in enumerate(inact_actions):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    data[\"CustomerID\"].append(customer_id)\n",
    "    # Copy all fields from customer_data\n",
    "    for col in data.keys():\n",
    "        if col in (\"CustomerID\", \"EffectiveDate\"):\n",
    "            continue\n",
    "        else:\n",
    "            data[col].append(customer_data[customer_id][col])\n",
    "    # history tracking\n",
    "    data[\"EffectiveDate\"].append(pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "\n",
    "# Creating DataFrame\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df[\"Status\"] = \"INACTIVE\"\n",
    "dimCustomer_df = pd.concat([dimCustomer_df, data_df])\n",
    "dimCustomer_df[\"BatchID\"] = 1\n",
    "print(dimCustomer_df.info())\n",
    "dimCustomer_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomer_df['SK_CustomerID'] = range(1, len(dimCustomer_df) + 1)\n",
    "dimCustomer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by CustomerID and EffectiveDate\n",
    "dimCustomer_df.sort_values(by=['CustomerID', 'EffectiveDate'], inplace=True)\n",
    "# Create a shifted DataFrame\n",
    "shifted_df = dimCustomer_df.shift(-1)\n",
    "# Update EndDate: If next row has same CustomerID, use its EffectiveDate; otherwise, use default date\n",
    "dimCustomer_df['EndDate'] = pd.Timestamp('9999-12-31')\n",
    "mask = dimCustomer_df['CustomerID'] == shifted_df['CustomerID']\n",
    "dimCustomer_df.loc[mask, 'EndDate'] = shifted_df.loc[mask, 'EffectiveDate']\n",
    "\n",
    "# Update IsCurrent: True if next row has different CustomerID or is the last row\n",
    "dimCustomer_df['IsCurrent'] = ~mask\n",
    "dimCustomer_df.sort_values(by=['SK_CustomerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'CustomerID': sqlalchemy.types.Integer,\n",
    "    'TaxID': sqlalchemy.types.String(20),\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'LastName': sqlalchemy.types.String(30),\n",
    "    'FirstName': sqlalchemy.types.String(30),\n",
    "    'MiddleInitial': sqlalchemy.types.String(1),\n",
    "    'Gender': sqlalchemy.types.String(1),\n",
    "    'Tier': sqlalchemy.types.SmallInteger,\n",
    "    'DOB': sqlalchemy.types.Date,\n",
    "    'AddressLine1': sqlalchemy.types.String(80),\n",
    "    'AddressLine2': sqlalchemy.types.String(80),\n",
    "    'PostalCode': sqlalchemy.types.String(12),\n",
    "    'City': sqlalchemy.types.String(25),\n",
    "    'StateProv': sqlalchemy.types.String(20),\n",
    "    'Country': sqlalchemy.types.String(24),\n",
    "    'Phone1': sqlalchemy.types.String(30),\n",
    "    'Phone2': sqlalchemy.types.String(30),\n",
    "    'Phone3': sqlalchemy.types.String(30),\n",
    "    'Email1': sqlalchemy.types.String(50),\n",
    "    'Email2': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'NationalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'LocalTaxRateDesc': sqlalchemy.types.String(50),\n",
    "    'LocalTaxRate': sqlalchemy.types.Numeric(6, 5),\n",
    "    'AgencyID': sqlalchemy.types.String(30),\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.Numeric(10),\n",
    "    'MarketingNameplate': sqlalchemy.types.String(100),\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int 32\n",
    "cols = ['SK_CustomerID', 'CustomerID', 'BatchID']\n",
    "for col in cols:\n",
    "    dimCustomer_df[col] = dimCustomer_df[col].astype('int')\n",
    "dimCustomer_df['Tier'] = dimCustomer_df['Tier'].astype('UInt8')\n",
    "dimCustomer_df['NationalTaxRate'] = dimCustomer_df['NationalTaxRate'].astype('float32')\n",
    "dimCustomer_df['LocalTaxRate'] = dimCustomer_df['LocalTaxRate'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to the appropriate types\n",
    "dimCustomer_df['SK_CustomerID'] = dimCustomer_df['SK_CustomerID'].astype(np.int32)\n",
    "dimCustomer_df['CustomerID'] = dimCustomer_df['CustomerID'].astype(np.int32)\n",
    "dimCustomer_df['Tier'] = dimCustomer_df['Tier'].astype(pd.Int8Dtype())\n",
    "dimCustomer_df['NationalTaxRate'] = dimCustomer_df['NationalTaxRate'].astype(np.float64)\n",
    "dimCustomer_df['LocalTaxRate'] = dimCustomer_df['LocalTaxRate'].astype(np.float64)\n",
    "dimCustomer_df['CreditRating'] = dimCustomer_df['CreditRating'].astype(pd.Int16Dtype())\n",
    "dimCustomer_df['NetWorth'] = dimCustomer_df['NetWorth'].astype(pd.Float64Dtype())\n",
    "dimCustomer_df['BatchID'] = dimCustomer_df['BatchID'].astype(np.int16)\n",
    "\n",
    "# Convert date columns to datetime.date\n",
    "dimCustomer_df['DOB'] = pd.to_datetime(dimCustomer_df['DOB']).dt.date\n",
    "dimCustomer_df['EffectiveDate'] = pd.to_datetime(dimCustomer_df['EffectiveDate']).dt.date\n",
    "dimCustomer_df['EndDate'] = pd.to_datetime(dimCustomer_df['EndDate']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimCustomer (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    CustomerID INT UNSIGNED NOT NULL,\n",
    "    TaxID CHAR(20) NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    LastName CHAR(30) NOT NULL,\n",
    "    FirstName CHAR(30) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Gender CHAR(1),\n",
    "    Tier TINYINT UNSIGNED,\n",
    "    DOB DATE NOT NULL,\n",
    "    AddressLine1 CHAR(80) NOT NULL,\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12) NOT NULL,\n",
    "    City CHAR(25) NOT NULL,\n",
    "    StateProv CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Phone1 CHAR(30),\n",
    "    Phone2 CHAR(30),\n",
    "    Phone3 CHAR(30),\n",
    "    Email1 CHAR(50),\n",
    "    Email2 CHAR(50),\n",
    "    NationalTaxRateDesc CHAR(50),\n",
    "    NationalTaxRate DECIMAL(6, 5),\n",
    "    LocalTaxRateDesc CHAR(50),\n",
    "    LocalTaxRate DECIMAL(6, 5),\n",
    "    AgencyID CHAR(30),\n",
    "    CreditRating SMALLINT UNSIGNED,\n",
    "    NetWorth DECIMAL(10),\n",
    "    MarketingNameplate CHAR(100),\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_CustomerID)\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomer_df.to_sql('dimcustomer', engine, if_exists='append', index=False, dtype=sql_dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary uppercase columns for merging in both DataFrames\n",
    "merge_fields = [\"FirstName\", \"LastName\", \"AddressLine1\", \"AddressLine2\", \"PostalCode\"]\n",
    "for field in merge_fields:\n",
    "    prospect_df[f\"temp_{field}\"] = prospect_df[field].str.upper()\n",
    "    dimCustomer_df[f\"temp_{field}\"] = dimCustomer_df[field].str.upper()\n",
    "\n",
    "# Filter dimCustomer_df for active and current customers\n",
    "active_customers = dimCustomer_df[(dimCustomer_df['IsCurrent'] == True) & (dimCustomer_df['Status'] == 'ACTIVE')]\n",
    "\n",
    "# Perform an outer merge on the temporary uppercase fields\n",
    "temp_merge_fields = [f\"temp_{field}\" for field in merge_fields]\n",
    "merged_df = prospect_df.merge(active_customers, how='left', \n",
    "                              left_on=temp_merge_fields, right_on=temp_merge_fields,\n",
    "                              indicator=True)\n",
    "\n",
    "# Update IsCustomer based on whether a match was found\n",
    "prospect_df['IsCustomer'] = merged_df['_merge'] == 'both'\n",
    "\n",
    "# Clean up by dropping the temporary columns\n",
    "prospect_df.drop(columns=temp_merge_fields, inplace=True)\n",
    "dimCustomer_df.drop(columns=temp_merge_fields, inplace=True)\n",
    "\n",
    "prospect_df['IsCustomer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'AgencyID': sqlalchemy.types.CHAR(30),\n",
    "    'SK_RecordDateID': sqlalchemy.types.Integer,\n",
    "    'SK_UpdateDateID': sqlalchemy.types.Integer,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'IsCustomer': sqlalchemy.types.Boolean,\n",
    "    'LastName': sqlalchemy.types.CHAR(30),\n",
    "    'FirstName': sqlalchemy.types.CHAR(30),\n",
    "    'MiddleInitial': sqlalchemy.types.CHAR(1),\n",
    "    'Gender': sqlalchemy.types.CHAR(1),\n",
    "    'AddressLine1': sqlalchemy.types.CHAR(80),\n",
    "    'AddressLine2': sqlalchemy.types.CHAR(80),\n",
    "    'PostalCode': sqlalchemy.types.CHAR(12),\n",
    "    'City': sqlalchemy.types.CHAR(25),\n",
    "    'State': sqlalchemy.types.CHAR(20),\n",
    "    'Country': sqlalchemy.types.CHAR(24),\n",
    "    'Phone': sqlalchemy.types.CHAR(30),\n",
    "    'Income': sqlalchemy.types.Integer,\n",
    "    'NumberCars': sqlalchemy.types.SmallInteger,\n",
    "    'NumberChildren': sqlalchemy.types.SmallInteger,\n",
    "    'MaritalStatus': sqlalchemy.types.CHAR(1),\n",
    "    'Age': sqlalchemy.types.SmallInteger,\n",
    "    'CreditRating': sqlalchemy.types.SmallInteger,\n",
    "    'OwnOrRentFlag': sqlalchemy.types.CHAR(1),\n",
    "    'Employer': sqlalchemy.types.CHAR(30),\n",
    "    'NumberCreditCards': sqlalchemy.types.SmallInteger,\n",
    "    'NetWorth': sqlalchemy.types.BigInteger,\n",
    "    'MarketingNameplate': sqlalchemy.types.CHAR(100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE Prospect (\n",
    "    AgencyID CHAR(30) NOT NULL,\n",
    "    SK_RecordDateID INT UNSIGNED NOT NULL,\n",
    "    SK_UpdateDateID INT UNSIGNED NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    IsCustomer BOOLEAN NOT NULL,\n",
    "    LastName CHAR(30) NOT NULL,\n",
    "    FirstName CHAR(30) NOT NULL,\n",
    "    MiddleInitial CHAR(1),\n",
    "    Gender CHAR(1) CHECK (Gender IN ('M', 'F', 'U')),\n",
    "    AddressLine1 CHAR(80),\n",
    "    AddressLine2 CHAR(80),\n",
    "    PostalCode CHAR(12),\n",
    "    City CHAR(25) NOT NULL,\n",
    "    State CHAR(20) NOT NULL,\n",
    "    Country CHAR(24),\n",
    "    Phone CHAR(30),\n",
    "    Income INT UNSIGNED,\n",
    "    NumberCars TINYINT UNSIGNED,\n",
    "    NumberChildren TINYINT UNSIGNED,\n",
    "    MaritalStatus CHAR(1) CHECK (MaritalStatus IN ('S', 'M', 'D', 'W', 'U')),\n",
    "    Age TINYINT UNSIGNED,\n",
    "    CreditRating SMALLINT UNSIGNED,\n",
    "    OwnOrRentFlag CHAR(1) CHECK (OwnOrRentFlag IN ('O', 'R', 'U')),\n",
    "    Employer CHAR(30),\n",
    "    NumberCreditCards TINYINT UNSIGNED,\n",
    "    NetWorth BIGINT,\n",
    "    MarketingNameplate CHAR(100),\n",
    "    PRIMARY KEY (AgencyID, SK_RecordDateID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prospect_df.to_sql('prospect', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Prospect file is processed, the number of source rows is counted. After the last\n",
    "row, a “Status” message is written to the DImessages table, with the MessageSource\n",
    "“Prospect”, MessageText “Source rows” and the MessageData field containing the\n",
    "number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = prospect_df.shape[0]\n",
    "message_type = \"Status\"\n",
    "message_source = \"Prospect\"\n",
    "message_text = f\"Inserted rows\"\n",
    "MessageDateAndTime = pd.Timestamp(\"now\")\n",
    "batch_id = 1\n",
    "\n",
    "query = f\"\"\"INSERT INTO dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "            VALUES ('{MessageDateAndTime}', {batch_id}, '{message_source}', '{message_text}', '{message_type}', '{num_rows}')\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema as a dictionary\n",
    "schema = {\n",
    "    'SK_AccountID': 'uint32',\n",
    "    'AccountID': 'uint32',\n",
    "    'SK_BrokerID': 'uint32',\n",
    "    'SK_CustomerID': 'uint32',\n",
    "    'Status': 'str',\n",
    "    'AccountDesc': 'str',\n",
    "    'TaxStatus': 'UInt8',\n",
    "    'IsCurrent': 'bool',\n",
    "    'BatchID': 'uint8',\n",
    "    'EffectiveDate': 'datetime64[ns]',\n",
    "    'EndDate': 'datetime64[ns]'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = DATA_DIR + \"CustomerMgmt.xml\"\n",
    "tree = etree.parse(data_file)\n",
    "namespace = {'tpcdi': 'http://www.tpc.org/tpc-di'}\n",
    "\n",
    "# Get all actions\n",
    "all_actions = tree.xpath(\".//tpcdi:Action\", namespaces=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified schema\n",
    "dimAccount_df = pd.DataFrame({col: pd.Series(dtype=typ) for col, typ in schema.items()})\n",
    "\n",
    "# initialize lists to store data\n",
    "relevant_cols = ['AccountID', 'SK_BrokerID', 'SK_CustomerID', 'Status', 'AccountDesc', 'TaxStatus', 'EffectiveDate']\n",
    "data = {col: [] for col in relevant_cols}\n",
    "\n",
    "# initialize dict to store most recent values for each account of a customer\n",
    "customer_accounts = dict()\n",
    "\n",
    "for index, action in enumerate(tqdm(all_actions)):\n",
    "    customer = action.find(\"Customer\", namespaces=namespace)\n",
    "    customer_id = int(customer.get(\"C_ID\", None))\n",
    "    if customer_id not in customer_accounts:\n",
    "        customer_accounts[customer_id] = dict()\n",
    "    if action.get(\"ActionType\") in (\"NEW\", \"ADDACCT\"):\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # Customer/Account/CA_NAME\n",
    "            account_desc = account.findtext(\"CA_NAME\", default=None, namespaces=namespace)\n",
    "            data[\"AccountDesc\"].append(account_desc)\n",
    "            # Customer/Account/@CA_TAX_ST\n",
    "            tax_status = account.get(\"CA_TAX_ST\", None)\n",
    "            tax_status = int(tax_status) if tax_status else None\n",
    "            data[\"TaxStatus\"].append(tax_status)\n",
    "            #  Customer/Account/CA_B_ID\n",
    "            broker_id = account.findtext(\"CA_B_ID\", default=None, namespaces=namespace)\n",
    "            broker_id = int(broker_id) if broker_id else None\n",
    "            data[\"SK_BrokerID\"].append((broker_id, action_ts))\n",
    "            data[\"SK_CustomerID\"].append((customer_id, action_ts))\n",
    "            status = \"ACTIVE\"\n",
    "            data[\"Status\"].append(status)\n",
    "            # update customer_accounts\n",
    "            customer_accounts[customer_id][account_id] = {\n",
    "                \"AccountDesc\": account_desc,\n",
    "                \"TaxStatus\": tax_status,\n",
    "                \"SK_BrokerID\": (broker_id, action_ts),\n",
    "                \"SK_CustomerID\": (customer_id, action_ts),\n",
    "                \"Status\": status,\n",
    "            }\n",
    "    elif action.get(\"ActionType\") == \"UPDACCT\":\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # Customer/Account/CA_NAME\n",
    "            account_desc = account.findtext(\"CA_NAME\", default=None, namespaces=namespace)\n",
    "            if account_desc is None:\n",
    "                account_desc = customer_accounts[customer_id][account_id][\"AccountDesc\"]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"AccountDesc\"] = account_desc\n",
    "            data[\"AccountDesc\"].append(account_desc)\n",
    "            # Customer/Account/@CA_TAX_ST\n",
    "            tax_status = account.get(\"CA_TAX_ST\", None)\n",
    "            tax_status = int(tax_status) if tax_status else None\n",
    "            if tax_status is None:\n",
    "                tax_status = customer_accounts[customer_id][account_id][\"TaxStatus\"]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"TaxStatus\"] = tax_status\n",
    "            data[\"TaxStatus\"].append(tax_status)\n",
    "            #  Customer/Account/CA_B_ID\n",
    "            broker_id = account.findtext(\"CA_B_ID\", default=None, namespaces=namespace)\n",
    "            broker_id = int(broker_id) if broker_id else None\n",
    "            if broker_id is None:\n",
    "                broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            else:\n",
    "                customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)\n",
    "            status = \"ACTIVE\"\n",
    "            data[\"Status\"].append(status)\n",
    "    elif action.get(\"ActionType\") == \"UPDCUST\":\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # set all other fields as is\n",
    "            for col in customer_accounts[customer_id][account_id]:\n",
    "                if not col.startswith(\"SK_\"):\n",
    "                    data[col].append(customer_accounts[customer_id][account_id][col])\n",
    "            broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)\n",
    "    elif action.get(\"ActionType\") in (\"INACT\", \"CLOSEACCT\"):\n",
    "        accounts = action.findall('Customer/Account', namespaces=namespace)\n",
    "        for account in accounts:\n",
    "            # set effective date for this account\n",
    "            action_ts = pd.to_datetime(action.get(\"ActionTS\"), format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "            data[\"EffectiveDate\"].append(action_ts)\n",
    "            # Customer/Account/@CA_ID\n",
    "            account_id = account.get(\"CA_ID\", None)\n",
    "            account_id = int(account_id) if account_id else None\n",
    "            data[\"AccountID\"].append(account_id)\n",
    "            # set all other fields as is\n",
    "            for col in customer_accounts[customer_id][account_id]:\n",
    "                if col.startswith(\"SK_\"):\n",
    "                    continue\n",
    "                elif col != \"Status\":\n",
    "                    data[col].append(customer_accounts[customer_id][account_id][col])\n",
    "                else:\n",
    "                    data[col].append(\"INACTIVE\")\n",
    "                    customer_accounts[customer_id][account_id][col] = \"INACTIVE\"\n",
    "            broker_id = customer_accounts[customer_id][account_id][\"SK_BrokerID\"][0]\n",
    "            customer_accounts[customer_id][account_id][\"SK_BrokerID\"] = (broker_id, action_ts)\n",
    "            sk_brokerid = (broker_id, action_ts)\n",
    "            data[\"SK_BrokerID\"].append(sk_brokerid)\n",
    "            sk_customer_id = (customer_id, action_ts)\n",
    "            customer_accounts[customer_id][account_id][\"SK_CustomerID\"] = sk_customer_id\n",
    "            data[\"SK_CustomerID\"].append(sk_customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the database to get all SK_BrokerID\n",
    "query_parts = [\n",
    "    f\"(BrokerID = {broker_id} AND EffectiveDate <= '{action_ts}' <= EndDate)\"\n",
    "    for broker_id, action_ts in data[\"SK_BrokerID\"]\n",
    "]\n",
    "# Joining all conditions with 'OR'\n",
    "conditions = \" OR \".join(query_parts)\n",
    "query = f\"\"\"SELECT BrokerID, EffectiveDate, EndDate, SK_BrokerID \n",
    "FROM dimbroker \n",
    "WHERE {conditions}\"\"\"\n",
    "result = pd.read_sql_query(query, engine)\n",
    "for index, pair in enumerate(data[\"SK_BrokerID\"]):\n",
    "    broker_id, action_ts = pair    \n",
    "    sk_brokerid = result[\n",
    "        (result[\"BrokerID\"] == broker_id)\n",
    "        & (result[\"EffectiveDate\"] <= action_ts.date())\n",
    "        & (action_ts.date() <= result[\"EndDate\"])\n",
    "    ].iloc[0, 3]\n",
    "    data[\"SK_BrokerID\"][index] = sk_brokerid\n",
    "\n",
    "# query the database to get all SK_CustomerID\n",
    "query_parts = [\n",
    "    f\"(CustomerID = {customer_id} AND EffectiveDate <= '{action_ts}' <= EndDate)\"\n",
    "    for customer_id, action_ts in data[\"SK_CustomerID\"]\n",
    "]\n",
    "# Joining all conditions with 'OR'\n",
    "conditions = \" OR \".join(query_parts)\n",
    "query = f\"\"\"SELECT CustomerID, EffectiveDate, EndDate, SK_CustomerID \n",
    "FROM dimcustomer \n",
    "WHERE {conditions}\"\"\"\n",
    "result = pd.read_sql_query(query, engine)\n",
    "for index, pair in enumerate(data[\"SK_CustomerID\"]):\n",
    "    customer_id, action_ts = pair\n",
    "    sk_brokerid = result[\n",
    "        (result[\"CustomerID\"] == customer_id)\n",
    "        & (result[\"EffectiveDate\"] <= action_ts.date())\n",
    "        & (action_ts.date() <= result[\"EndDate\"])\n",
    "    ].iloc[0, 3]\n",
    "    data[\"SK_CustomerID\"][index] = sk_brokerid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data:\n",
    "    dimAccount_df[col] = data[col]\n",
    "dimAccount_df['SK_AccountID'] = range(1, len(dimAccount_df) + 1)\n",
    "dimAccount_df['BatchID'] = 1\n",
    "\n",
    "# Sort the DataFrame by CustomerID and EffectiveDate\n",
    "dimAccount_df.sort_values(by=['AccountID', 'EffectiveDate'], inplace=True)\n",
    "# Create a shifted DataFrame\n",
    "shifted_df = dimAccount_df.shift(-1)\n",
    "# Update EndDate: If next row has same CustomerID, use its EffectiveDate; otherwise, use default date\n",
    "dimAccount_df['EndDate'] = pd.Timestamp('9999-12-31')\n",
    "mask = dimAccount_df['AccountID'] == shifted_df['AccountID']\n",
    "dimAccount_df.loc[mask, 'EndDate'] = shifted_df.loc[mask, 'EffectiveDate']\n",
    "\n",
    "# Update IsCurrent: True if next row has different CustomerID or is the last row\n",
    "dimAccount_df['IsCurrent'] = ~mask\n",
    "dimAccount_df.sort_values(by=['SK_AccountID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'AccountID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.String(10),\n",
    "    'AccountDesc': sqlalchemy.types.String(50),\n",
    "    'TaxStatus': sqlalchemy.types.SmallInteger,\n",
    "    'IsCurrent': sqlalchemy.types.Boolean,\n",
    "    'BatchID': sqlalchemy.types.SmallInteger,\n",
    "    'EffectiveDate': sqlalchemy.types.Date,\n",
    "    'EndDate': sqlalchemy.types.Date\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimAccount (\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    AccountID INT UNSIGNED NOT NULL,\n",
    "    SK_BrokerID INT UNSIGNED NOT NULL,\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    AccountDesc CHAR(50),\n",
    "    TaxStatus TINYINT UNSIGNED,\n",
    "    IsCurrent BOOLEAN NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    EffectiveDate DATE NOT NULL,\n",
    "    EndDate DATE NOT NULL,\n",
    "    PRIMARY KEY (SK_AccountID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimAccount_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimAccount_df.to_sql('dimaccount', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### dimTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'T_ID', 'T_DTS', 'T_ST_ID', 'T_TT_ID', 'T_IS_CASH', \n",
    "    'T_S_SYMB', 'T_QTY', 'T_BID_PRICE', 'T_CA_ID', 'T_EXEC_NAME', \n",
    "    'T_TRADE_PRICE', 'T_CHRG', 'T_COMM', 'T_TAX'\n",
    "]\n",
    "dtypes = {\n",
    "    'T_ID': 'uint64',\n",
    "    'T_DTS': 'str',\n",
    "    'T_ST_ID': 'str',\n",
    "    'T_TT_ID': 'str',\n",
    "    'T_IS_CASH': 'bool',\n",
    "    'T_S_SYMB': 'str',\n",
    "    'T_QTY': 'uint32',\n",
    "    'T_BID_PRICE': 'float64',\n",
    "    'T_CA_ID': 'uint32',\n",
    "    'T_EXEC_NAME': 'str',\n",
    "    'T_TRADE_PRICE': 'float64',\n",
    "    'T_CHRG': 'float64',\n",
    "    'T_COMM': 'float64',\n",
    "    'T_TAX': 'float64'\n",
    "}\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "trade_df = pd.read_csv(\n",
    "    DATA_DIR + \"Trade.txt\", \n",
    "    sep='|', \n",
    "    header=None, \n",
    "    names=columns, \n",
    "    dtype=dtypes,\n",
    "    parse_dates=['T_DTS']\n",
    ")\n",
    "trade_df['T_DTS'] = pd.to_datetime(trade_df['T_DTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"TH_T_ID\", \"TH_DTS\", \"TH_ST_ID\"]\n",
    "dtypes = {\n",
    "    \"TH_T_ID\": \"uint64\",\n",
    "    \"TH_DTS\": \"str\",\n",
    "    \"TH_ST_ID\": \"str\"\n",
    "}\n",
    "tradehistory_df = pd.read_csv(DATA_DIR + \"TradeHistory.txt\", sep=\"|\", header=None, \n",
    "                              names=columns, dtype=dtypes, parse_dates=['TH_DTS'])\n",
    "tradehistory_df['TH_DTS'] = pd.to_datetime(tradehistory_df['TH_DTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged = tradehistory_df.merge(trade_df, left_on='TH_T_ID', right_on='T_ID')\n",
    "del tradehistory_df\n",
    "del trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-fetch data from related tables\n",
    "date_mapping = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine).set_index(\"DateValue\")[\"SK_DateID\"].to_dict()\n",
    "time_mapping = pd.read_sql(\"SELECT TimeValue, SK_TimeID FROM dimtime\", engine).set_index(\"TimeValue\")[\"SK_TimeID\"].to_dict()\n",
    "status_mapping = pd.read_sql(\"SELECT ST_ID, ST_NAME FROM statustype\", engine).set_index(\"ST_ID\")[\"ST_NAME\"].to_dict()\n",
    "trade_type_mapping = pd.read_sql(\"SELECT TT_ID, TT_NAME FROM tradetype\", engine).set_index(\"TT_ID\")[\"TT_NAME\"].to_dict()\n",
    "\n",
    "# Fetching security and account info in one go\n",
    "security_info = pd.read_sql(\"SELECT Symbol, SK_SecurityID, SK_CompanyID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "account_info = pd.read_sql(\"SELECT AccountID, SK_AccountID, SK_CustomerID, SK_BrokerID, EffectiveDate, EndDate FROM dimaccount\", engine)\n",
    "account_info['EffectiveDate'] = pd.to_datetime(account_info['EffectiveDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct copy\n",
    "trade_merged[\"TradeID\"] = trade_merged[\"T_ID\"]\n",
    "trade_merged[\"CashFlag\"] = trade_merged[\"T_IS_CASH\"]\n",
    "trade_merged[\"Quantity\"] = trade_merged[\"T_QTY\"]\n",
    "trade_merged[\"BidPrice\"] = trade_merged[\"T_BID_PRICE\"]\n",
    "trade_merged[\"ExecutedBy\"] = trade_merged[\"T_EXEC_NAME\"]\n",
    "trade_merged[\"TradePrice\"] = trade_merged[\"T_TRADE_PRICE\"]\n",
    "trade_merged[\"Fee\"] = trade_merged[\"T_CHRG\"]\n",
    "trade_merged[\"Commission\"] = trade_merged[\"T_COMM\"]\n",
    "trade_merged[\"Tax\"] = trade_merged[\"T_TAX\"]\n",
    "trade_merged[\"Status\"] = trade_merged[\"TH_ST_ID\"].map(status_mapping)\n",
    "trade_merged[\"Type\"] = trade_merged[\"T_TT_ID\"].map(trade_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially set null\n",
    "trade_merged[\"SK_CreateDateID\"] = None\n",
    "trade_merged[\"SK_CreateTimeID\"] = None\n",
    "trade_merged[\"SK_CloseDateID\"] = None\n",
    "trade_merged[\"SK_CloseTimeID\"] = None\n",
    "\n",
    "# now populate\n",
    "create_mask = (trade_merged[\"TH_ST_ID\"] == \"PNDG\") | (trade_merged[\"TH_ST_ID\"] == \"SBMT\")\n",
    "trade_merged.loc[create_mask, \"SK_CreateDateID\"] = trade_merged.loc[create_mask, \"TH_DTS\"].dt.date.map(date_mapping)\n",
    "trade_merged.loc[create_mask, \"SK_CreateTimeID\"] = pd.to_timedelta(trade_merged.loc[create_mask, \"TH_DTS\"].dt.time.astype(str)).map(time_mapping)\n",
    "close_mask = (trade_merged[\"TH_ST_ID\"] == \"CMPT\") | (trade_merged[\"TH_ST_ID\"] == \"CNCL\")\n",
    "trade_merged.loc[close_mask, \"SK_CloseDateID\"] = trade_merged.loc[close_mask, \"TH_DTS\"].dt.date.map(date_mapping)\n",
    "trade_merged.loc[close_mask, \"SK_CloseTimeID\"] = pd.to_timedelta(trade_merged.loc[close_mask, \"TH_DTS\"].dt.time.astype(str)).map(time_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged.rename({\"T_S_SYMB\": \"Symbol\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged = pd.merge(\n",
    "    trade_merged,\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    on=\"Symbol\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows where TH_DTS < EffectiveDate  or TH_DTS > EndDate\n",
    "trade_merged = trade_merged[\n",
    "    (trade_merged[\"TH_DTS\"] >= trade_merged[\"EffectiveDate\"])\n",
    "    & (trade_merged[\"TH_DTS\"].dt.date < trade_merged[\"EndDate\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged = pd.merge(\n",
    "    trade_merged,\n",
    "    account_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"T_CA_ID\",\n",
    "    right_on=\"AccountID\",\n",
    ")\n",
    "trade_merged = trade_merged[\n",
    "    (trade_merged[\"TH_DTS\"] >= trade_merged[\"EffectiveDate_y\"])\n",
    "    & (trade_merged[\"TH_DTS\"].dt.date < trade_merged[\"EndDate_y\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    \"TradeID\",\n",
    "    \"SK_BrokerID\",\n",
    "    \"SK_CreateDateID\",\n",
    "    \"SK_CreateTimeID\",\n",
    "    \"SK_CloseDateID\",\n",
    "    \"SK_CloseTimeID\",\n",
    "    \"Status\",\n",
    "    \"Type\",\n",
    "    \"CashFlag\",\n",
    "    \"SK_SecurityID\",\n",
    "    \"SK_CompanyID\",\n",
    "    \"Quantity\",\n",
    "    \"BidPrice\",\n",
    "    \"SK_CustomerID\",\n",
    "    \"SK_AccountID\",\n",
    "    \"ExecutedBy\",\n",
    "    \"TradePrice\",\n",
    "    \"Fee\",\n",
    "    \"Commission\",\n",
    "    \"Tax\",\n",
    "]\n",
    "trade_merged = trade_merged[use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged = trade_merged.groupby(\"TradeID\").last().reset_index()\n",
    "trade_merged['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'TradeID': 'uint32',\n",
    "    'SK_BrokerID': 'UInt32',\n",
    "    'SK_CreateDateID': 'uint32',\n",
    "    'SK_CreateTimeID': 'uint32',\n",
    "    'SK_CloseDateID': 'UInt32',\n",
    "    'SK_CloseTimeID': 'UInt32',\n",
    "    'Status': 'str',\n",
    "    'Type': 'str',\n",
    "    'CashFlag': 'bool',\n",
    "    'SK_SecurityID': 'uint32',\n",
    "    'SK_CompanyID': 'uint32',\n",
    "    'Quantity': 'uint32',\n",
    "    'BidPrice': 'float64',\n",
    "    'SK_CustomerID': 'uint32',\n",
    "    'SK_AccountID': 'uint32',\n",
    "    'ExecutedBy': 'str',\n",
    "    'TradePrice': 'float64',\n",
    "    'Fee': 'float64',\n",
    "    'Commission': 'float64',\n",
    "    'Tax': 'float64',\n",
    "    'BatchID': 'uint8'\n",
    "}\n",
    "trade_merged = trade_merged.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    'TradeID': sqlalchemy.types.Integer,\n",
    "    'SK_BrokerID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CreateTimeID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseDateID': sqlalchemy.types.Integer,\n",
    "    'SK_CloseTimeID': sqlalchemy.types.Integer,\n",
    "    'Status': sqlalchemy.types.CHAR(10),\n",
    "    'Type': sqlalchemy.types.CHAR(12),\n",
    "    'CashFlag': sqlalchemy.types.Boolean,\n",
    "    'SK_SecurityID': sqlalchemy.types.Integer,\n",
    "    'SK_CompanyID': sqlalchemy.types.Integer,\n",
    "    'Quantity': sqlalchemy.types.Integer,\n",
    "    'BidPrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'SK_CustomerID': sqlalchemy.types.Integer,\n",
    "    'SK_AccountID': sqlalchemy.types.Integer,\n",
    "    'ExecutedBy': sqlalchemy.types.CHAR(64),\n",
    "    'TradePrice': sqlalchemy.types.Numeric(8, 2),\n",
    "    'Fee': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Commission': sqlalchemy.types.Numeric(10, 2),\n",
    "    'Tax': sqlalchemy.types.Numeric(10, 2),\n",
    "    'BatchID': sqlalchemy.types.SmallInteger\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE DimTrade (\n",
    "    TradeID INT UNSIGNED NOT NULL,\n",
    "    SK_BrokerID INT UNSIGNED,\n",
    "    SK_CreateDateID INT UNSIGNED NOT NULL,\n",
    "    SK_CreateTimeID INT UNSIGNED NOT NULL,\n",
    "    SK_CloseDateID INT UNSIGNED,\n",
    "    SK_CloseTimeID INT UNSIGNED,\n",
    "    Status CHAR(10) NOT NULL,\n",
    "    Type CHAR(12) NOT NULL,\n",
    "    CashFlag BOOLEAN NOT NULL,\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "    Quantity MEDIUMINT UNSIGNED NOT NULL,\n",
    "    BidPrice DECIMAL(8, 2) NOT NULL,\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    ExecutedBy CHAR(64) NOT NULL,\n",
    "    TradePrice DECIMAL(8, 2),\n",
    "    Fee DECIMAL(10, 2),\n",
    "    Commission DECIMAL(10, 2),\n",
    "    Tax DECIMAL(10, 2),\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL,\n",
    "    PRIMARY KEY (TradeID)\n",
    ");\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try:\n",
    "    for i in range(0, trade_merged.shape[0], 100000):\n",
    "        trade_merged.iloc[i:i+100000].to_sql('dimtrade', engine, if_exists='append', index=False, dtype=sql_dtypes)\n",
    "    session.commit()\n",
    "except:\n",
    "    session.rollback()\n",
    "    raise\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "invalid_trades = trade_merged[\n",
    "    (trade_merged[\"Commission\"].notnull())\n",
    "    & (trade_merged[\"Commission\"] > (trade_merged[\"TradePrice\"] * trade_merged[\"Quantity\"]))\n",
    "]\n",
    "print(invalid_trades.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists without using iterrows\n",
    "MessageSource = [\"DimTrade\"] * len(invalid_trades)\n",
    "MessageType = [\"Alert\"] * len(invalid_trades)\n",
    "MessageText = [\"Invalid trade commission\"] * len(invalid_trades)\n",
    "MessageData = [\n",
    "    \"T_ID = \"\n",
    "    + invalid_trades[\"TradeID\"].astype(str)\n",
    "    + \", T_COMM = \"\n",
    "    + invalid_trades[\"Commission\"].astype(str)\n",
    "]\n",
    "# Convert MessageData from a list of Series to a list of strings\n",
    "MessageData = MessageData[0].tolist()\n",
    "\n",
    "print(len(MessageSource))\n",
    "print(len(MessageData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData)\n",
    "VALUES \"\"\"\n",
    "for i in range(len(MessageSource)):\n",
    "    query += f\"\"\"('{pd.Timestamp(\"now\")}', 1, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query[:-1]))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for invalid trade fees\n",
    "invalid_fee_trades = trade_merged[\n",
    "    (trade_merged[\"Fee\"].notnull())\n",
    "    & (trade_merged[\"Fee\"] > (trade_merged[\"TradePrice\"] * trade_merged[\"Quantity\"]))\n",
    "]\n",
    "\n",
    "# Create the required lists\n",
    "MessageSource = [\"DimTrade\"] * len(invalid_fee_trades)\n",
    "MessageType = [\"Alert\"] * len(invalid_fee_trades)\n",
    "MessageText = [\"Invalid trade fee\"] * len(invalid_fee_trades)\n",
    "\n",
    "# Vectorized operation for MessageData\n",
    "MessageData = (\n",
    "    \"T_ID = \"\n",
    "    + invalid_fee_trades[\"TradeID\"].astype(str)\n",
    "    + \", T_CHRG = \"\n",
    "    + invalid_fee_trades[\"Fee\"].astype(str)\n",
    ")\n",
    "MessageData = MessageData.tolist()\n",
    "\n",
    "query = \"\"\"INSERT INTO Dimessages (MessageDateAndTime, BatchID, MessageSource, MessageText, MessageType, MessageData) VALUES \"\"\"\n",
    "for i in range(len(MessageSource)):\n",
    "    query += f\"\"\"('{pd.Timestamp(\"now\")}', 1, '{MessageSource[i]}', '{MessageText[i]}', '{MessageType[i]}', '{MessageData[i]}'),\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(query[:-1]))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactCashBalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 602115 entries, 0 to 602114\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   CT_CA_ID  602115 non-null  uint32        \n",
      " 1   CT_DTS    602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT    602115 non-null  float64       \n",
      " 3   CT_NAME   602115 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1), uint32(1)\n",
      "memory usage: 16.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0         2 2012-07-11 08:10:15 -37215.14   \n",
       "1        34 2012-07-07 17:11:38  -3178.67   \n",
       "2        36 2012-07-12 17:37:44  -3172.19   \n",
       "3        40 2012-09-20 03:12:34 -16621.00   \n",
       "4        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                             CT_NAME  \n",
       "0  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...  \n",
       "1  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...  \n",
       "2  uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...  \n",
       "3  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...  \n",
       "4  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = pd.read_csv(\n",
    "    DATA_DIR + \"CashTransaction.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"CT_CA_ID\",\n",
    "        \"CT_DTS\",\n",
    "        \"CT_AMT\",\n",
    "        \"CT_NAME\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"CT_CA_ID\": \"uint32\",\n",
    "        \"CT_DTS\": \"str\",\n",
    "        \"CT_AMT\": \"float64\",\n",
    "        \"CT_NAME\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"CT_DTS\"],\n",
    ")\n",
    "cash_txn_df[\"CT_DTS\"] = pd.to_datetime(cash_txn_df[\"CT_DTS\"])\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK_CustomerID and SK_AccountID are obtained from DimAccount by matching CT_CA_ID\n",
    "with AccountID, where CT_DTS is in the range given by EffectiveDate and EndDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountID  SK_AccountID  SK_CustomerID EffectiveDate     EndDate\n",
       "0          0             1              1    2007-07-07  2007-10-15\n",
       "1          1             2              2    2007-07-07  2007-07-21\n",
       "2          2             3              3    2007-07-07  2007-07-23\n",
       "3          3             4              4    2007-07-07  2007-09-16\n",
       "4          4             5              5    2007-07-07  2007-07-27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_info = pd.read_sql(\n",
    "    \"SELECT AccountID, SK_AccountID, SK_CustomerID, EffectiveDate, EndDate FROM dimaccount\",\n",
    "    engine,\n",
    ")\n",
    "account_info[\"EffectiveDate\"] = pd.to_datetime(account_info[\"EffectiveDate\"])\n",
    "account_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197606 entries, 0 to 1197605\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   CT_CA_ID       1197606 non-null  uint32        \n",
      " 1   CT_DTS         1197606 non-null  datetime64[ns]\n",
      " 2   CT_AMT         1197606 non-null  float64       \n",
      " 3   CT_NAME        1197606 non-null  object        \n",
      " 4   AccountID      1197606 non-null  int64         \n",
      " 5   SK_AccountID   1197606 non-null  int64         \n",
      " 6   SK_CustomerID  1197606 non-null  int64         \n",
      " 7   EffectiveDate  1197606 non-null  datetime64[ns]\n",
      " 8   EndDate        1197606 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(3), object(2), uint32(1)\n",
      "memory usage: 77.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>2007-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-23</td>\n",
       "      <td>2007-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-07-11</td>\n",
       "      <td>2007-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0         2 2012-07-11 08:10:15 -37215.14   \n",
       "1         2 2012-07-11 08:10:15 -37215.14   \n",
       "2         2 2012-07-11 08:10:15 -37215.14   \n",
       "3        34 2012-07-07 17:11:38  -3178.67   \n",
       "4        34 2012-07-07 17:11:38  -3178.67   \n",
       "\n",
       "                                             CT_NAME  AccountID  SK_AccountID  \\\n",
       "0  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2             3   \n",
       "1  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2           109   \n",
       "2  TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2           133   \n",
       "3  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34            35   \n",
       "4  PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34           220   \n",
       "\n",
       "   SK_CustomerID EffectiveDate     EndDate  \n",
       "0              3    2007-07-07  2007-07-23  \n",
       "1           9952    2007-07-23  2007-07-28  \n",
       "2           9952    2007-07-28  9999-12-31  \n",
       "3             35    2007-07-11  2007-08-11  \n",
       "4             35    2007-08-11  9999-12-31  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = cash_txn_df.merge(\n",
    "    account_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"CT_CA_ID\",\n",
    "    right_on=\"AccountID\",\n",
    ")\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 602115 entries, 2 to 1197605\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   CT_CA_ID       602115 non-null  uint32        \n",
      " 1   CT_DTS         602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT         602115 non-null  float64       \n",
      " 3   CT_NAME        602115 non-null  object        \n",
      " 4   AccountID      602115 non-null  int64         \n",
      " 5   SK_AccountID   602115 non-null  int64         \n",
      " 6   SK_CustomerID  602115 non-null  int64         \n",
      " 7   EffectiveDate  602115 non-null  datetime64[ns]\n",
      " 8   EndDate        602115 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(3), object(2), uint32(1)\n",
      "memory usage: 43.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "      <td>36</td>\n",
       "      <td>5062</td>\n",
       "      <td>10007</td>\n",
       "      <td>2009-11-09</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "      <td>40</td>\n",
       "      <td>1050</td>\n",
       "      <td>9957</td>\n",
       "      <td>2007-12-30</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "      <td>19</td>\n",
       "      <td>6282</td>\n",
       "      <td>9960</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "2          2 2012-07-11 08:10:15 -37215.14   \n",
       "4         34 2012-07-07 17:11:38  -3178.67   \n",
       "8         36 2012-07-12 17:37:44  -3172.19   \n",
       "10        40 2012-09-20 03:12:34 -16621.00   \n",
       "14        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                              CT_NAME  AccountID  \\\n",
       "2   TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2   \n",
       "4   PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34   \n",
       "8   uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...         36   \n",
       "10  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...         40   \n",
       "14  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...         19   \n",
       "\n",
       "    SK_AccountID  SK_CustomerID EffectiveDate     EndDate  \n",
       "2            133           9952    2007-07-28  9999-12-31  \n",
       "4            220             35    2007-08-11  9999-12-31  \n",
       "8           5062          10007    2009-11-09  9999-12-31  \n",
       "10          1050           9957    2007-12-30  9999-12-31  \n",
       "14          6282           9960    2010-06-04  9999-12-31  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df = cash_txn_df[\n",
    "    (cash_txn_df[\"CT_DTS\"] >= cash_txn_df[\"EffectiveDate\"])\n",
    "    & (cash_txn_df[\"CT_DTS\"].dt.date < cash_txn_df[\"EndDate\"])\n",
    "]\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK_DateID is obtained from DimDate by matching just the date portion of CT_DTS with\n",
    "DateValue to return the SK_DateID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25933 entries, 0 to 25932\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   DateValue  25933 non-null  datetime64[ns]\n",
      " 1   SK_DateID  25933 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 405.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateValue</th>\n",
       "      <th>SK_DateID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>19500101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-01-02</td>\n",
       "      <td>19500102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-01-03</td>\n",
       "      <td>19500103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-01-04</td>\n",
       "      <td>19500104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-01-05</td>\n",
       "      <td>19500105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DateValue  SK_DateID\n",
       "0 1950-01-01   19500101\n",
       "1 1950-01-02   19500102\n",
       "2 1950-01-03   19500103\n",
       "3 1950-01-04   19500104\n",
       "4 1950-01-05   19500105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info[\"DateValue\"] = pd.to_datetime(date_info[\"DateValue\"])\n",
    "date_info.info()\n",
    "date_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 602115 entries, 2 to 1197605\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   CT_CA_ID       602115 non-null  uint32        \n",
      " 1   CT_DTS         602115 non-null  datetime64[ns]\n",
      " 2   CT_AMT         602115 non-null  float64       \n",
      " 3   CT_NAME        602115 non-null  object        \n",
      " 4   AccountID      602115 non-null  int64         \n",
      " 5   SK_AccountID   602115 non-null  int64         \n",
      " 6   SK_CustomerID  602115 non-null  int64         \n",
      " 7   EffectiveDate  602115 non-null  datetime64[ns]\n",
      " 8   EndDate        602115 non-null  object        \n",
      " 9   SK_DateID      602115 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(4), object(2), uint32(1)\n",
      "memory usage: 48.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>SK_DateID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-07-11 08:10:15</td>\n",
       "      <td>-37215.14</td>\n",
       "      <td>TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>9952</td>\n",
       "      <td>2007-07-28</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>2012-07-07 17:11:38</td>\n",
       "      <td>-3178.67</td>\n",
       "      <td>PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...</td>\n",
       "      <td>34</td>\n",
       "      <td>220</td>\n",
       "      <td>35</td>\n",
       "      <td>2007-08-11</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>2012-07-12 17:37:44</td>\n",
       "      <td>-3172.19</td>\n",
       "      <td>uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...</td>\n",
       "      <td>36</td>\n",
       "      <td>5062</td>\n",
       "      <td>10007</td>\n",
       "      <td>2009-11-09</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>2012-09-20 03:12:34</td>\n",
       "      <td>-16621.00</td>\n",
       "      <td>VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...</td>\n",
       "      <td>40</td>\n",
       "      <td>1050</td>\n",
       "      <td>9957</td>\n",
       "      <td>2007-12-30</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2012-07-09 07:32:41</td>\n",
       "      <td>-1315.70</td>\n",
       "      <td>gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...</td>\n",
       "      <td>19</td>\n",
       "      <td>6282</td>\n",
       "      <td>9960</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>20120709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "2          2 2012-07-11 08:10:15 -37215.14   \n",
       "4         34 2012-07-07 17:11:38  -3178.67   \n",
       "8         36 2012-07-12 17:37:44  -3172.19   \n",
       "10        40 2012-09-20 03:12:34 -16621.00   \n",
       "14        19 2012-07-09 07:32:41  -1315.70   \n",
       "\n",
       "                                              CT_NAME  AccountID  \\\n",
       "2   TGDRsaHPherhApDuHfXUPdexIUoEzKdgRAGECsgXJIRZui...          2   \n",
       "4   PGwhaPC igAVOmHLJppGbXaDEgHSurSvrCvKtSyJRfHyRV...         34   \n",
       "8   uQOUlrpDGHQpeeBGxaLTrxUwMwNMFowWAjqENSawehdTQd...         36   \n",
       "10  VRIGhrJYHmbmNyXtIutswBfyfSLRjEJdGhuHOGWHscOlcC...         40   \n",
       "14  gySbOpZLevgVdfrrwPiqBrFJFQGWehUzTSmkIhCJUBLLmV...         19   \n",
       "\n",
       "    SK_AccountID  SK_CustomerID EffectiveDate     EndDate  SK_DateID  \n",
       "2            133           9952    2007-07-28  9999-12-31   20120711  \n",
       "4            220             35    2007-08-11  9999-12-31   20120707  \n",
       "8           5062          10007    2009-11-09  9999-12-31   20120712  \n",
       "10          1050           9957    2007-12-30  9999-12-31   20120920  \n",
       "14          6282           9960    2010-06-04  9999-12-31   20120709  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df['SK_DateID'] = cash_txn_df['CT_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cash is calculated as the sum of the prior Cash amount for this account plus the sum of all\n",
    "CT_AMT values from all transactions in this account on this day. If there is no previous\n",
    "FactCashBalances record for the associated account, zero is used. Remember that the net effect of all cash transactions for a given account on a given day is totaled, and only a single record is generated per account that had changes per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549361 entries, 0 to 549360\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   AccountID      549361 non-null  int64         \n",
      " 1   SK_DateID      549361 non-null  int64         \n",
      " 2   CT_CA_ID       549361 non-null  uint32        \n",
      " 3   CT_DTS         549361 non-null  datetime64[ns]\n",
      " 4   CT_AMT         549361 non-null  float64       \n",
      " 5   CT_NAME        549361 non-null  object        \n",
      " 6   SK_AccountID   549361 non-null  int64         \n",
      " 7   SK_CustomerID  549361 non-null  int64         \n",
      " 8   EffectiveDate  549361 non-null  datetime64[ns]\n",
      " 9   EndDate        549361 non-null  object        \n",
      " 10  PriorCash      549361 non-null  float64       \n",
      " 11  Cash           549361 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(3), int64(4), object(2), uint32(1)\n",
      "memory usage: 48.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>CT_CA_ID</th>\n",
       "      <th>CT_DTS</th>\n",
       "      <th>CT_AMT</th>\n",
       "      <th>CT_NAME</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>PriorCash</th>\n",
       "      <th>Cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20120708</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-08 17:58:21</td>\n",
       "      <td>-71563.60</td>\n",
       "      <td>hyaGSBCOXigNPHVAQxiPjJFgKBcBBQGDBQDpBxISwKkJ</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-71563.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120710</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-10 22:12:48</td>\n",
       "      <td>-89884.06</td>\n",
       "      <td>gSTsTBZrTEm PMYdHvhKxaJTrNxtosRUsJDwGBqwTbbjDO...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>3249.91</td>\n",
       "      <td>-86634.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20120711</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-11 04:19:10</td>\n",
       "      <td>8110.34</td>\n",
       "      <td>JGEQbvMIqUzPAbNiKtveoxbSUHRxlHkxdGZKeTdXWqhWGN...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-95309.80</td>\n",
       "      <td>-87199.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20120712</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-12 21:36:34</td>\n",
       "      <td>1641.86</td>\n",
       "      <td>YAROnGbtCACCSuAbFQJxIZxwibmZPuvKjoENySzzhmajQe...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-113718.54</td>\n",
       "      <td>-112076.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120713</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-13 16:23:08</td>\n",
       "      <td>-52115.15</td>\n",
       "      <td>xFePvUHkWgBKpuTjsCBcnRCYTUjEtIKYNtgeBVLTsQZfHj...</td>\n",
       "      <td>866</td>\n",
       "      <td>7802</td>\n",
       "      <td>2007-11-29</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>-604254.35</td>\n",
       "      <td>-656369.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountID  SK_DateID  CT_CA_ID              CT_DTS    CT_AMT  \\\n",
       "0          0   20120708         0 2012-07-08 17:58:21 -71563.60   \n",
       "1          0   20120710         0 2012-07-10 22:12:48 -89884.06   \n",
       "2          0   20120711         0 2012-07-11 04:19:10   8110.34   \n",
       "3          0   20120712         0 2012-07-12 21:36:34   1641.86   \n",
       "4          0   20120713         0 2012-07-13 16:23:08 -52115.15   \n",
       "\n",
       "                                             CT_NAME  SK_AccountID  \\\n",
       "0       hyaGSBCOXigNPHVAQxiPjJFgKBcBBQGDBQDpBxISwKkJ           866   \n",
       "1  gSTsTBZrTEm PMYdHvhKxaJTrNxtosRUsJDwGBqwTbbjDO...           866   \n",
       "2  JGEQbvMIqUzPAbNiKtveoxbSUHRxlHkxdGZKeTdXWqhWGN...           866   \n",
       "3  YAROnGbtCACCSuAbFQJxIZxwibmZPuvKjoENySzzhmajQe...           866   \n",
       "4  xFePvUHkWgBKpuTjsCBcnRCYTUjEtIKYNtgeBVLTsQZfHj...           866   \n",
       "\n",
       "   SK_CustomerID EffectiveDate     EndDate  PriorCash       Cash  \n",
       "0           7802    2007-11-29  9999-12-31       0.00  -71563.60  \n",
       "1           7802    2007-11-29  9999-12-31    3249.91  -86634.15  \n",
       "2           7802    2007-11-29  9999-12-31  -95309.80  -87199.46  \n",
       "3           7802    2007-11-29  9999-12-31 -113718.54 -112076.68  \n",
       "4           7802    2007-11-29  9999-12-31 -604254.35 -656369.50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame by account ID and transaction date\n",
    "cash_txn_df.sort_values(by=['SK_AccountID', 'CT_DTS'], inplace=True)\n",
    "\n",
    "# Create a new column to store the prior cash amount\n",
    "cash_txn_df['PriorCash'] = cash_txn_df.groupby('SK_AccountID')['CT_AMT'].cumsum() - cash_txn_df['CT_AMT']\n",
    "cash_txn_df['PriorCash'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the cash balance\n",
    "cash_txn_df['Cash'] = cash_txn_df['PriorCash'] + cash_txn_df['CT_AMT']\n",
    "\n",
    "# Keep only the last record for each account on each day\n",
    "cash_txn_df = cash_txn_df.groupby(['AccountID', 'SK_DateID']).last().reset_index()\n",
    "\n",
    "cash_txn_df.info()\n",
    "cash_txn_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\n",
    "    \"SK_CustomerID\",\n",
    "    \"SK_AccountID\",\n",
    "    \"SK_DateID\",\n",
    "    \"Cash\",\n",
    "]\n",
    "cash_txn_df = cash_txn_df[keep_cols]\n",
    "cash_txn_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549361 entries, 0 to 549360\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   SK_CustomerID  549361 non-null  int64  \n",
      " 1   SK_AccountID   549361 non-null  int64  \n",
      " 2   SK_DateID      549361 non-null  int64  \n",
      " 3   Cash           549361 non-null  float64\n",
      " 4   BatchID        549361 non-null  int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 21.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>SK_AccountID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>Cash</th>\n",
       "      <th>BatchID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120708</td>\n",
       "      <td>-71563.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120710</td>\n",
       "      <td>-86634.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120711</td>\n",
       "      <td>-87199.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120712</td>\n",
       "      <td>-112076.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7802</td>\n",
       "      <td>866</td>\n",
       "      <td>20120713</td>\n",
       "      <td>-656369.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_CustomerID  SK_AccountID  SK_DateID       Cash  BatchID\n",
       "0           7802           866   20120708  -71563.60        1\n",
       "1           7802           866   20120710  -86634.15        1\n",
       "2           7802           866   20120711  -87199.46        1\n",
       "3           7802           866   20120712 -112076.68        1\n",
       "4           7802           866   20120713 -656369.50        1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_txn_df.info()\n",
    "cash_txn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE FactCashBalances (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_AccountID INT UNSIGNED NOT NULL,\n",
    "    SK_DateID INT UNSIGNED NOT NULL,\n",
    "    Cash DECIMAL(15, 2) NOT NULL,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL\n",
    ");\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_AccountID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    \"Cash\": sqlalchemy.types.DECIMAL(precision=15, scale=2),\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6f48d529ac4e52b6f7451eab970ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in trange(0, cash_txn_df.shape[0], 100000):\n",
    "    cash_txn_df.iloc[i:i+100000].to_sql('factcashbalances', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactHoldings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL queries\n",
    "sql_commands = [\n",
    "    \"DROP TABLE IF EXISTS TempHoldingHistory\",\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE TempHoldingHistory (\n",
    "        HH_H_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_T_ID INT UNSIGNED NOT NULL,\n",
    "        HH_BEFORE_QTY INT NOT NULL,\n",
    "        HH_AFTER_QTY INT NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'E:\\\\\\\\Documents\\\\\\\\BDMA\\\\\\\\ULB\\\\\\\\Data Warehouses\\\\\\\\tpc-di\\\\\\\\TPC-DI\\\\\\\\data\\\\\\\\sf5\\\\\\\\Batch1\\\\\\\\HoldingHistory.txt'\n",
    "    INTO TABLE TempHoldingHistory\n",
    "    FIELDS TERMINATED BY '|'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    (HH_H_T_ID, HH_T_ID, HH_BEFORE_QTY, HH_AFTER_QTY)\n",
    "    \"\"\",\n",
    "    \"DROP TABLE IF EXISTS FactHoldings\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE FactHoldings (\n",
    "        TradeID INT UNSIGNED NOT NULL,\n",
    "        CurrentTradeID INT UNSIGNED NOT NULL,\n",
    "        SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "        SK_AccountID INT UNSIGNED NOT NULL,\n",
    "        SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "        SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "        SK_DateID INT UNSIGNED NOT NULL,\n",
    "        SK_TimeID INT UNSIGNED NOT NULL,\n",
    "        CurrentPrice DECIMAL(8, 2) NOT NULL CHECK (CurrentPrice > 0),\n",
    "        CurrentHolding INT NOT NULL,\n",
    "        BatchID SMALLINT UNSIGNED NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    INSERT INTO FactHoldings (TradeID, CurrentTradeID, SK_CustomerID, SK_AccountID, SK_SecurityID, SK_CompanyID, SK_DateID, SK_TimeID, CurrentPrice, CurrentHolding, BatchID)\n",
    "    SELECT \n",
    "        thh.HH_H_T_ID AS TradeID,\n",
    "        thh.HH_T_ID AS CurrentTradeID,\n",
    "        dt.SK_CustomerID,\n",
    "        dt.SK_AccountID,\n",
    "        dt.SK_SecurityID,\n",
    "        dt.SK_CompanyID,\n",
    "        dt.SK_CloseDateID AS SK_DateID,\n",
    "        dt.SK_CloseTimeID AS SK_TimeID,\n",
    "        dt.TradePrice AS CurrentPrice,\n",
    "        thh.HH_AFTER_QTY AS CurrentHolding,\n",
    "        1 AS BatchID\n",
    "    FROM \n",
    "        TempHoldingHistory thh\n",
    "    JOIN \n",
    "        DimTrade dt ON thh.HH_T_ID = dt.TradeID\n",
    "    \"\"\",\n",
    "    \"DROP TABLE IF EXISTS TempHoldingHistory\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "with engine.connect() as connection:\n",
    "    # connection.execute(text(\"SET GLOBAL local_infile = 1;\"))\n",
    "    for sql in sql_commands:\n",
    "        connection.execute(text(sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FactMarketHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2422064 entries, 0 to 2422063\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   DM_DATE    datetime64[ns]\n",
      " 1   DM_S_SYMB  object        \n",
      " 2   DM_CLOSE   float32       \n",
      " 3   DM_HIGH    float32       \n",
      " 4   DM_LOW     float32       \n",
      " 5   DM_VOL     int64         \n",
      "dtypes: datetime64[ns](1), float32(3), int64(1), object(1)\n",
      "memory usage: 83.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_CLOSE</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>DM_VOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYJ</td>\n",
       "      <td>445.459991</td>\n",
       "      <td>522.299988</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>78849320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEVC</td>\n",
       "      <td>910.590027</td>\n",
       "      <td>1148.890015</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>807515829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAACEZ</td>\n",
       "      <td>647.070007</td>\n",
       "      <td>756.679993</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>693226268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADOY</td>\n",
       "      <td>385.010010</td>\n",
       "      <td>564.669983</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>34628570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB    DM_CLOSE      DM_HIGH      DM_LOW     DM_VOL\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  242.929993   284.420013  185.080002  111904727\n",
       "1 2015-07-06  AAAAAAAAAAAAEYJ  445.459991   522.299988  386.480011   78849320\n",
       "2 2015-07-06  AAAAAAAAAAAAEVC  910.590027  1148.890015  723.369995  807515829\n",
       "3 2015-07-06  AAAAAAAAAAAACEZ  647.070007   756.679993  473.299988  693226268\n",
       "4 2015-07-06  AAAAAAAAAAAADOY  385.010010   564.669983  295.630005   34628570"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df = pd.read_csv(\n",
    "    DATA_DIR + \"DailyMarket.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"DM_DATE\",\n",
    "        \"DM_S_SYMB\",\n",
    "        \"DM_CLOSE\",\n",
    "        \"DM_HIGH\",\n",
    "        \"DM_LOW\",\n",
    "        \"DM_VOL\",\n",
    "    ],\n",
    "    dtype={\n",
    "        \"DM_DATE\": \"str\",\n",
    "        \"DM_S_SYMB\": \"str\",\n",
    "        \"DM_CLOSE\": \"float32\",\n",
    "        \"DM_HIGH\": \"float32\",\n",
    "        \"DM_LOW\": \"float32\",\n",
    "        \"DM_VOL\": \"int64\",\n",
    "    },\n",
    "    parse_dates=[\"DM_DATE\"],\n",
    ")\n",
    "dailymarket_df[\"DM_DATE\"] = pd.to_datetime(dailymarket_df[\"DM_DATE\"])\n",
    "dailymarket_df.info()\n",
    "dailymarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClosePrice, DayHigh, DayLow, and Volume are copied from DM_CLOSE, DM_HIGH,\n",
    "# DM_LOW, and DM_VOL respectively.\n",
    "dailymarket_df[\"ClosePrice\"] = dailymarket_df[\"DM_CLOSE\"]\n",
    "dailymarket_df[\"DayHigh\"] = dailymarket_df[\"DM_HIGH\"]\n",
    "dailymarket_df[\"DayLow\"] = dailymarket_df[\"DM_LOW\"]\n",
    "dailymarket_df[\"Volume\"] = dailymarket_df[\"DM_VOL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   DM_S_SYMB      4000 non-null   object        \n",
      " 1   SK_SecurityID  4000 non-null   int64         \n",
      " 2   SK_CompanyID   4000 non-null   int64         \n",
      " 3   EffectiveDate  4000 non-null   datetime64[ns]\n",
      " 4   EndDate        4000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_CompanyID</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1967-04-25</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAB</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1967-04-26</td>\n",
       "      <td>1968-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAC</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1967-04-26</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAD</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1967-04-27</td>\n",
       "      <td>1979-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAE</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1967-04-27</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DM_S_SYMB  SK_SecurityID  SK_CompanyID EffectiveDate     EndDate\n",
       "0  AAAAAAAAAAAAAAA              1             5    1967-04-25  9999-12-31\n",
       "1  AAAAAAAAAAAAAAB              2            52    1967-04-26  1968-03-30\n",
       "2  AAAAAAAAAAAAAAC              3            13    1967-04-26  9999-12-31\n",
       "3  AAAAAAAAAAAAAAD              4            70    1967-04-27  1979-06-27\n",
       "4  AAAAAAAAAAAAAAE              5            46    1967-04-27  9999-12-31"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "security_info = pd.read_sql(\"SELECT Symbol AS DM_S_SYMB, SK_SecurityID, SK_CompanyID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "security_info.info()\n",
    "security_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2422064 entries, 0 to 2567327\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   DM_DATE        datetime64[ns]\n",
      " 1   DM_S_SYMB      object        \n",
      " 2   DM_CLOSE       float32       \n",
      " 3   DM_HIGH        float32       \n",
      " 4   DM_LOW         float32       \n",
      " 5   DM_VOL         int64         \n",
      " 6   ClosePrice     float32       \n",
      " 7   DayHigh        float32       \n",
      " 8   DayLow         float32       \n",
      " 9   Volume         int64         \n",
      " 10  SK_SecurityID  int64         \n",
      " 11  SK_CompanyID   int64         \n",
      "dtypes: datetime64[ns](1), float32(6), int64(4), object(1)\n",
      "memory usage: 184.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df = pd.merge(\n",
    "    dailymarket_df,\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    on=\"DM_S_SYMB\",\n",
    ")\n",
    "dailymarket_df = dailymarket_df[\n",
    "    (dailymarket_df[\"DM_DATE\"] >= dailymarket_df[\"EffectiveDate\"])\n",
    "    & (dailymarket_df[\"DM_DATE\"].dt.date < dailymarket_df[\"EndDate\"])\n",
    "]\n",
    "# drop temp columns\n",
    "dailymarket_df.drop(columns=[\"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SK_DateID is obtained from DimDate by matching DM_DATE with DateValue to return the\n",
    "SK_DateID. The match is guaranteed to succeed because DimDate has been populated\n",
    "with date information for all dates relevant to the benchmark.\"\"\"\n",
    "date_info = pd.read_sql(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info[\"DateValue\"] = pd.to_datetime(date_info[\"DateValue\"])\n",
    "date_info = date_info.set_index(\"DateValue\")[\"SK_DateID\"].to_dict()\n",
    "dailymarket_df[\"SK_DateID\"] = dailymarket_df[\"DM_DATE\"].dt.date.map(date_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>FiftyTwoWeekHigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>284.420013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYD</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>841.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABJB</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>1055.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADSX</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>747.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABYA</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>708.140015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB      DM_HIGH  FiftyTwoWeekHigh\n",
       "0 2015-07-06  AAAAAAAAAAAAERN   284.420013        284.420013\n",
       "1 2015-07-06  AAAAAAAAAAAAEYD   841.200012        841.200012\n",
       "2 2015-07-06  AAAAAAAAAAAABJB  1055.699951       1055.699951\n",
       "3 2015-07-06  AAAAAAAAAAAADSX   747.770020        747.770020\n",
       "4 2015-07-06  AAAAAAAAAAAABYA   708.140015        708.140015"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Sort the DataFrame\n",
    "dailymarket_df.sort_values(by='DM_DATE', inplace=True)\n",
    "\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling max\n",
    "rolling_max = dailymarket_df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_HIGH'].max()\n",
    "\n",
    "# Reset index to make merging easier\n",
    "rolling_max = rolling_max.reset_index()\n",
    "\n",
    "# Step 5: Merge with the original DataFrame\n",
    "dailymarket_df = dailymarket_df.merge(rolling_max, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekHigh'))\n",
    "\n",
    "# Rename the column for clarity\n",
    "dailymarket_df.rename(columns={'DM_HIGH_52WeekHigh': 'FiftyTwoWeekHigh'}, inplace=True)\n",
    "dailymarket_df[['DM_DATE', 'DM_S_SYMB', 'DM_HIGH', 'FiftyTwoWeekHigh']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>Rank</th>\n",
       "      <th>SK_FiftyTwoWeekHighDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>1</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>1</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>4</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DM_S_SYMB    DM_DATE  Rank  SK_FiftyTwoWeekHighDate\n",
       "0  AAAAAAAAAAAAAAA 2015-07-06     1                 20150706\n",
       "1  AAAAAAAAAAAAAAA 2015-07-07     1                 20150707\n",
       "2  AAAAAAAAAAAAAAA 2015-07-08     2                 20150707\n",
       "3  AAAAAAAAAAAAAAA 2015-07-09     2                 20150707\n",
       "4  AAAAAAAAAAAAAAA 2015-07-10     4                 20150707"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostly wrote this myself but dont ask me to explain...........\n",
    "rolling_rank = (\n",
    "    dailymarket_df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_HIGH\"]\n",
    "    .rank(method=\"average\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_HIGH\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekHighDate'] = rolling_rank['SK_FiftyTwoWeekHighDate'].dt.date.map(date_info)\n",
    "rolling_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_CLOSE</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>DM_VOL</th>\n",
       "      <th>ClosePrice</th>\n",
       "      <th>DayHigh</th>\n",
       "      <th>DayLow</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_CompanyID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>FiftyTwoWeekHigh</th>\n",
       "      <th>SK_FiftyTwoWeekHighDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>3523</td>\n",
       "      <td>1275</td>\n",
       "      <td>20150706</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYD</td>\n",
       "      <td>624.479980</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>505.109985</td>\n",
       "      <td>448826960</td>\n",
       "      <td>624.479980</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>505.109985</td>\n",
       "      <td>448826960</td>\n",
       "      <td>3709</td>\n",
       "      <td>1825</td>\n",
       "      <td>20150706</td>\n",
       "      <td>841.200012</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABJB</td>\n",
       "      <td>918.270020</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>808.450012</td>\n",
       "      <td>187580057</td>\n",
       "      <td>918.270020</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>808.450012</td>\n",
       "      <td>187580057</td>\n",
       "      <td>986</td>\n",
       "      <td>461</td>\n",
       "      <td>20150706</td>\n",
       "      <td>1055.699951</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADSX</td>\n",
       "      <td>593.820007</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>593.119995</td>\n",
       "      <td>625016548</td>\n",
       "      <td>593.820007</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>593.119995</td>\n",
       "      <td>625016548</td>\n",
       "      <td>2794</td>\n",
       "      <td>811</td>\n",
       "      <td>20150706</td>\n",
       "      <td>747.770020</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAABYA</td>\n",
       "      <td>517.380005</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>394.940002</td>\n",
       "      <td>278873866</td>\n",
       "      <td>517.380005</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>394.940002</td>\n",
       "      <td>278873866</td>\n",
       "      <td>1420</td>\n",
       "      <td>229</td>\n",
       "      <td>20150706</td>\n",
       "      <td>708.140015</td>\n",
       "      <td>20150707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB    DM_CLOSE      DM_HIGH      DM_LOW     DM_VOL  \\\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  242.929993   284.420013  185.080002  111904727   \n",
       "1 2015-07-06  AAAAAAAAAAAAEYD  624.479980   841.200012  505.109985  448826960   \n",
       "2 2015-07-06  AAAAAAAAAAAABJB  918.270020  1055.699951  808.450012  187580057   \n",
       "3 2015-07-06  AAAAAAAAAAAADSX  593.820007   747.770020  593.119995  625016548   \n",
       "4 2015-07-06  AAAAAAAAAAAABYA  517.380005   708.140015  394.940002  278873866   \n",
       "\n",
       "   ClosePrice      DayHigh      DayLow     Volume  SK_SecurityID  \\\n",
       "0  242.929993   284.420013  185.080002  111904727           3523   \n",
       "1  624.479980   841.200012  505.109985  448826960           3709   \n",
       "2  918.270020  1055.699951  808.450012  187580057            986   \n",
       "3  593.820007   747.770020  593.119995  625016548           2794   \n",
       "4  517.380005   708.140015  394.940002  278873866           1420   \n",
       "\n",
       "   SK_CompanyID  SK_DateID  FiftyTwoWeekHigh  SK_FiftyTwoWeekHighDate  \n",
       "0          1275   20150706        284.420013                 20150706  \n",
       "1          1825   20150706        841.200012                 20150707  \n",
       "2           461   20150706       1055.699951                 20150707  \n",
       "3           811   20150706        747.770020                 20150707  \n",
       "4           229   20150706        708.140015                 20150707  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df = pd.concat([dailymarket_df, rolling_rank['SK_FiftyTwoWeekHighDate']], axis=1)\n",
    "dailymarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>FiftyTwoWeekLow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>185.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYJ</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>386.480011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEVC</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>723.369995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAACEZ</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>473.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADOY</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>295.630005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB      DM_LOW  FiftyTwoWeekLow\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  185.080002       185.080002\n",
       "1 2015-07-06  AAAAAAAAAAAAEYJ  386.480011       386.480011\n",
       "2 2015-07-06  AAAAAAAAAAAAEVC  723.369995       723.369995\n",
       "3 2015-07-06  AAAAAAAAAAAACEZ  473.299988       473.299988\n",
       "4 2015-07-06  AAAAAAAAAAAADOY  295.630005       295.630005"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df.sort_values(by='DM_DATE', inplace=True)\n",
    "# Step 3 & 4: Group by 'DM_S_SYMB' and apply rolling min\n",
    "rolling_min = dailymarket_df.groupby('DM_S_SYMB').rolling('365D', on='DM_DATE')['DM_LOW'].min()\n",
    "# Reset index to make merging easier\n",
    "rolling_min = rolling_min.reset_index()\n",
    "# Step 5: Merge with the original DataFrame\n",
    "dailymarket_df = dailymarket_df.merge(rolling_min, on=['DM_S_SYMB', 'DM_DATE'], suffixes=('', '_52WeekLow'))\n",
    "# Rename the column for clarity\n",
    "dailymarket_df.rename(columns={'DM_LOW_52WeekLow': 'FiftyTwoWeekLow'}, inplace=True)\n",
    "dailymarket_df[['DM_DATE', 'DM_S_SYMB', 'DM_LOW', 'FiftyTwoWeekLow']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>Rank</th>\n",
       "      <th>SK_FiftyTwoWeekLowDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>1</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-07</td>\n",
       "      <td>2</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>4</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>2015-07-10</td>\n",
       "      <td>3</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DM_S_SYMB    DM_DATE  Rank  SK_FiftyTwoWeekLowDate\n",
       "0  AAAAAAAAAAAAAAA 2015-07-06     1                20150706\n",
       "1  AAAAAAAAAAAAAAA 2015-07-07     2                20150706\n",
       "2  AAAAAAAAAAAAAAA 2015-07-08     2                20150706\n",
       "3  AAAAAAAAAAAAAAA 2015-07-09     4                20150706\n",
       "4  AAAAAAAAAAAAAAA 2015-07-10     3                20150706"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same...\n",
    "rolling_rank = (\n",
    "    dailymarket_df.groupby(\"DM_S_SYMB\")\n",
    "    .rolling(\"365D\", on=\"DM_DATE\")[\"DM_LOW\"]\n",
    "    .rank(method=\"average\", ascending=True)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"DM_LOW\": \"Rank\"})\n",
    ")\n",
    "rolling_rank[\"Rank\"] = rolling_rank[\"Rank\"].astype(\"uint32\")\n",
    "# Apply the mask to select DM_DATE only for those rows, then forward fill\n",
    "mask = rolling_rank['Rank'] == 1\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['DM_DATE'].where(mask).ffill()\n",
    "rolling_rank['SK_FiftyTwoWeekLowDate'] = rolling_rank['SK_FiftyTwoWeekLowDate'].dt.date.map(date_info)\n",
    "rolling_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2422064 entries, 0 to 2422063\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                object        \n",
      " 2   DM_CLOSE                 float32       \n",
      " 3   DM_HIGH                  float32       \n",
      " 4   DM_LOW                   float32       \n",
      " 5   DM_VOL                   int64         \n",
      " 6   ClosePrice               float32       \n",
      " 7   DayHigh                  float32       \n",
      " 8   DayLow                   float32       \n",
      " 9   Volume                   int64         \n",
      " 10  SK_SecurityID            int64         \n",
      " 11  SK_CompanyID             int64         \n",
      " 12  SK_DateID                int64         \n",
      " 13  FiftyTwoWeekHigh         float64       \n",
      " 14  SK_FiftyTwoWeekHighDate  int64         \n",
      " 15  FiftyTwoWeekLow          float64       \n",
      " 16  SK_FiftyTwoWeekLowDate   int64         \n",
      "dtypes: datetime64[ns](1), float32(6), float64(2), int64(7), object(1)\n",
      "memory usage: 258.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DM_DATE</th>\n",
       "      <th>DM_S_SYMB</th>\n",
       "      <th>DM_CLOSE</th>\n",
       "      <th>DM_HIGH</th>\n",
       "      <th>DM_LOW</th>\n",
       "      <th>DM_VOL</th>\n",
       "      <th>ClosePrice</th>\n",
       "      <th>DayHigh</th>\n",
       "      <th>DayLow</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_CompanyID</th>\n",
       "      <th>SK_DateID</th>\n",
       "      <th>FiftyTwoWeekHigh</th>\n",
       "      <th>SK_FiftyTwoWeekHighDate</th>\n",
       "      <th>FiftyTwoWeekLow</th>\n",
       "      <th>SK_FiftyTwoWeekLowDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAERN</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>242.929993</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>111904727</td>\n",
       "      <td>3523</td>\n",
       "      <td>1275</td>\n",
       "      <td>20150706</td>\n",
       "      <td>284.420013</td>\n",
       "      <td>20150706</td>\n",
       "      <td>185.080002</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEYJ</td>\n",
       "      <td>445.459991</td>\n",
       "      <td>522.299988</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>78849320</td>\n",
       "      <td>445.459991</td>\n",
       "      <td>522.299988</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>78849320</td>\n",
       "      <td>3703</td>\n",
       "      <td>2251</td>\n",
       "      <td>20150706</td>\n",
       "      <td>522.299988</td>\n",
       "      <td>20170212</td>\n",
       "      <td>386.480011</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAAEVC</td>\n",
       "      <td>910.590027</td>\n",
       "      <td>1148.890015</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>807515829</td>\n",
       "      <td>910.590027</td>\n",
       "      <td>1148.890015</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>807515829</td>\n",
       "      <td>3607</td>\n",
       "      <td>429</td>\n",
       "      <td>20150706</td>\n",
       "      <td>1148.890015</td>\n",
       "      <td>20170212</td>\n",
       "      <td>723.369995</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAACEZ</td>\n",
       "      <td>647.070007</td>\n",
       "      <td>756.679993</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>693226268</td>\n",
       "      <td>647.070007</td>\n",
       "      <td>756.679993</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>693226268</td>\n",
       "      <td>1626</td>\n",
       "      <td>112</td>\n",
       "      <td>20150706</td>\n",
       "      <td>756.679993</td>\n",
       "      <td>20170212</td>\n",
       "      <td>473.299988</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-06</td>\n",
       "      <td>AAAAAAAAAAAADOY</td>\n",
       "      <td>385.010010</td>\n",
       "      <td>564.669983</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>34628570</td>\n",
       "      <td>385.010010</td>\n",
       "      <td>564.669983</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>34628570</td>\n",
       "      <td>2673</td>\n",
       "      <td>552</td>\n",
       "      <td>20150706</td>\n",
       "      <td>564.669983</td>\n",
       "      <td>20170212</td>\n",
       "      <td>295.630005</td>\n",
       "      <td>20150706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DM_DATE        DM_S_SYMB    DM_CLOSE      DM_HIGH      DM_LOW     DM_VOL  \\\n",
       "0 2015-07-06  AAAAAAAAAAAAERN  242.929993   284.420013  185.080002  111904727   \n",
       "1 2015-07-06  AAAAAAAAAAAAEYJ  445.459991   522.299988  386.480011   78849320   \n",
       "2 2015-07-06  AAAAAAAAAAAAEVC  910.590027  1148.890015  723.369995  807515829   \n",
       "3 2015-07-06  AAAAAAAAAAAACEZ  647.070007   756.679993  473.299988  693226268   \n",
       "4 2015-07-06  AAAAAAAAAAAADOY  385.010010   564.669983  295.630005   34628570   \n",
       "\n",
       "   ClosePrice      DayHigh      DayLow     Volume  SK_SecurityID  \\\n",
       "0  242.929993   284.420013  185.080002  111904727           3523   \n",
       "1  445.459991   522.299988  386.480011   78849320           3703   \n",
       "2  910.590027  1148.890015  723.369995  807515829           3607   \n",
       "3  647.070007   756.679993  473.299988  693226268           1626   \n",
       "4  385.010010   564.669983  295.630005   34628570           2673   \n",
       "\n",
       "   SK_CompanyID  SK_DateID  FiftyTwoWeekHigh  SK_FiftyTwoWeekHighDate  \\\n",
       "0          1275   20150706        284.420013                 20150706   \n",
       "1          2251   20150706        522.299988                 20170212   \n",
       "2           429   20150706       1148.890015                 20170212   \n",
       "3           112   20150706        756.679993                 20170212   \n",
       "4           552   20150706        564.669983                 20170212   \n",
       "\n",
       "   FiftyTwoWeekLow  SK_FiftyTwoWeekLowDate  \n",
       "0       185.080002                20150706  \n",
       "1       386.480011                20150706  \n",
       "2       723.369995                20150706  \n",
       "3       473.299988                20150706  \n",
       "4       295.630005                20150706  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymarket_df = pd.concat([dailymarket_df, rolling_rank['SK_FiftyTwoWeekLowDate']], axis=1)\n",
    "dailymarket_df.info()\n",
    "dailymarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2422064 entries, 0 to 2422063\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                object        \n",
      " 2   DM_CLOSE                 float32       \n",
      " 3   DM_HIGH                  float32       \n",
      " 4   DM_LOW                   float32       \n",
      " 5   DM_VOL                   int64         \n",
      " 6   ClosePrice               float32       \n",
      " 7   DayHigh                  float32       \n",
      " 8   DayLow                   float32       \n",
      " 9   Volume                   int64         \n",
      " 10  SK_SecurityID            int64         \n",
      " 11  SK_CompanyID             int64         \n",
      " 12  SK_DateID                int64         \n",
      " 13  FiftyTwoWeekHigh         float64       \n",
      " 14  SK_FiftyTwoWeekHighDate  int64         \n",
      " 15  FiftyTwoWeekLow          float64       \n",
      " 16  SK_FiftyTwoWeekLowDate   int64         \n",
      "dtypes: datetime64[ns](1), float32(6), float64(2), int64(7), object(1)\n",
      "memory usage: 258.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2422064 entries, 0 to 2422063\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                category      \n",
      " 2   ClosePrice               float32       \n",
      " 3   DayHigh                  float32       \n",
      " 4   DayLow                   float32       \n",
      " 5   Volume                   int64         \n",
      " 6   SK_SecurityID            uint32        \n",
      " 7   SK_CompanyID             uint32        \n",
      " 8   SK_DateID                uint32        \n",
      " 9   FiftyTwoWeekHigh         float32       \n",
      " 10  SK_FiftyTwoWeekHighDate  uint32        \n",
      " 11  FiftyTwoWeekLow          float32       \n",
      " 12  SK_FiftyTwoWeekLowDate   uint32        \n",
      "dtypes: category(1), datetime64[ns](1), float32(5), int64(1), uint32(5)\n",
      "memory usage: 134.1 MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df['SK_SecurityID'] = dailymarket_df['SK_SecurityID'].astype('uint32')\n",
    "dailymarket_df['SK_CompanyID'] = dailymarket_df['SK_CompanyID'].astype('uint32')\n",
    "dailymarket_df['SK_DateID'] = dailymarket_df['SK_DateID'].astype('uint32')\n",
    "dailymarket_df['FiftyTwoWeekHigh'] = dailymarket_df['FiftyTwoWeekHigh'].astype('float32')\n",
    "dailymarket_df['SK_FiftyTwoWeekHighDate'] = dailymarket_df['SK_FiftyTwoWeekHighDate'].astype('uint32')\n",
    "dailymarket_df['FiftyTwoWeekLow'] = dailymarket_df['FiftyTwoWeekLow'].astype('float32')\n",
    "dailymarket_df['SK_FiftyTwoWeekLowDate'] = dailymarket_df['SK_FiftyTwoWeekLowDate'].astype('uint32')\n",
    "dailymarket_df['DM_S_SYMB'] = dailymarket_df['DM_S_SYMB'].astype('category')\n",
    "\n",
    "dailymarket_df.drop(columns=['DM_HIGH', 'DM_LOW', 'DM_VOL', 'DM_CLOSE'], inplace=True)\n",
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_info = pd.read_sql(\"SELECT Symbol, Dividend, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2422064 entries, 0 to 2567327\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                object        \n",
      " 2   ClosePrice               float32       \n",
      " 3   DayHigh                  float32       \n",
      " 4   DayLow                   float32       \n",
      " 5   Volume                   int64         \n",
      " 6   SK_SecurityID            uint32        \n",
      " 7   SK_CompanyID             uint32        \n",
      " 8   SK_DateID                uint32        \n",
      " 9   FiftyTwoWeekHigh         float32       \n",
      " 10  SK_FiftyTwoWeekHighDate  uint32        \n",
      " 11  FiftyTwoWeekLow          float32       \n",
      " 12  SK_FiftyTwoWeekLowDate   uint32        \n",
      " 13  Dividend                 float64       \n",
      "dtypes: datetime64[ns](1), float32(5), float64(1), int64(1), object(1), uint32(5)\n",
      "memory usage: 184.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df = dailymarket_df.merge(\n",
    "    security_info,\n",
    "    how=\"left\",\n",
    "    left_on=\"DM_S_SYMB\",\n",
    "    right_on=\"Symbol\",\n",
    ")\n",
    "dailymarket_df = dailymarket_df[\n",
    "    (dailymarket_df[\"DM_DATE\"] >= dailymarket_df[\"EffectiveDate\"])\n",
    "    & (dailymarket_df[\"DM_DATE\"].dt.date < dailymarket_df[\"EndDate\"])\n",
    "]\n",
    "dailymarket_df.drop(columns=[\"Symbol\", \"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailymarket_df['Yield'] = dailymarket_df['Dividend'] / dailymarket_df['ClosePrice'] * 100\n",
    "dailymarket_df.drop(columns=[\"Dividend\"], inplace=True)\n",
    "dailymarket_df['BatchID'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_CompanyID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID\": sqlalchemy.types.Integer,\n",
    "    # PERatio to be done in MySQL\n",
    "    # \"PERatio\": sqlalchemy.types.DECIMAL(precision=10, scale=2),\n",
    "    \"Yield\": sqlalchemy.types.DECIMAL(precision=5, scale=2),\n",
    "    \"FiftyTwoWeekHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekHighDate\": sqlalchemy.types.Integer,\n",
    "    \"FiftyTwoWeekLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"SK_FiftyTwoWeekLowDate\": sqlalchemy.types.Integer,\n",
    "    \"ClosePrice\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayHigh\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"DayLow\": sqlalchemy.types.DECIMAL(precision=8, scale=2),\n",
    "    \"Volume\": sqlalchemy.types.BigInteger,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger,\n",
    "    \"DM_DATE\": sqlalchemy.types.Date,\n",
    "    \"DM_S_SYMB\": sqlalchemy.types.CHAR(16),\n",
    "}\n",
    "len(sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2422064 entries, 0 to 2567327\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   DM_DATE                  datetime64[ns]\n",
      " 1   DM_S_SYMB                object        \n",
      " 2   ClosePrice               float32       \n",
      " 3   DayHigh                  float32       \n",
      " 4   DayLow                   float32       \n",
      " 5   Volume                   int64         \n",
      " 6   SK_SecurityID            uint32        \n",
      " 7   SK_CompanyID             uint32        \n",
      " 8   SK_DateID                uint32        \n",
      " 9   FiftyTwoWeekHigh         float32       \n",
      " 10  SK_FiftyTwoWeekHighDate  uint32        \n",
      " 11  FiftyTwoWeekLow          float32       \n",
      " 12  SK_FiftyTwoWeekLowDate   uint32        \n",
      " 13  Yield                    float64       \n",
      " 14  BatchID                  int64         \n",
      "dtypes: datetime64[ns](1), float32(5), float64(1), int64(2), object(1), uint32(5)\n",
      "memory usage: 203.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dailymarket_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b64744cdd14f97b4d3e60518c810d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in trange(0, dailymarket_df.shape[0], 100000):\n",
    "    dailymarket_df.iloc[i:i+100000].to_sql('tempfactmarketprice', engine, if_exists='append', index=False,\n",
    "                                           dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_commands = [\n",
    "    \"CREATE INDEX idx_sk_companyid ON tempfactmarketprice(SK_CompanyID);\",\n",
    "    \"\"\"CREATE TABLE FactMarketHistory (\n",
    "        SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "        SK_CompanyID INT UNSIGNED NOT NULL,\n",
    "        SK_DateID INT UNSIGNED NOT NULL,\n",
    "        PERatio DECIMAL(10, 2),\n",
    "        Yield DECIMAL(5, 2) NOT NULL,\n",
    "        FiftyTwoWeekHigh DECIMAL(8, 2) NOT NULL,\n",
    "        SK_FiftyTwoWeekHighDate INT UNSIGNED NOT NULL,\n",
    "        FiftyTwoWeekLow DECIMAL(8, 2) NOT NULL,\n",
    "        SK_FiftyTwoWeekLowDate INT UNSIGNED NOT NULL,\n",
    "        ClosePrice DECIMAL(8, 2) NOT NULL,\n",
    "        DayHigh DECIMAL(8, 2) NOT NULL,\n",
    "        DayLow DECIMAL(8, 2) NOT NULL,\n",
    "        Volume BIGINT UNSIGNED NOT NULL,\n",
    "        BatchID SMALLINT UNSIGNED NOT NULL\n",
    "    );\"\"\",\n",
    "    \"ALTER TABLE factmarkethistory ADD COLUMN DM_S_SYMB TEXT;\",\n",
    "    \"\"\"INSERT INTO factmarkethistory\n",
    "        SELECT SK_SecurityID, fmp.SK_CompanyID, SK_DateID, fmp.ClosePrice / T.Sum_EPS AS PERatio, Yield, FiftyTwoWeekHigh,\n",
    "        SK_FiftyTwoWeekHighDate, FiftyTwoWeekLow, SK_FiftyTwoWeekLowDate, ClosePrice, DayHigh, DayLow, Volume, BatchID, DM_S_SYMB\n",
    "        FROM tempfactmarketprice fmp\n",
    "        JOIN (SELECT \n",
    "            c.CompanyID, \n",
    "            c.SK_CompanyID AS SKCID, \n",
    "            f.FI_QTR_START_DATE,\n",
    "            SUM(f.FI_BASIC_EPS) OVER (\n",
    "                PARTITION BY c.CompanyID \n",
    "                ORDER BY f.FI_QTR_START_DATE \n",
    "                ROWS BETWEEN 3 PRECEDING AND CURRENT ROW\n",
    "            ) AS Sum_EPS\n",
    "        FROM financial f RIGHT JOIN dimCompany c ON f.SK_CompanyID = c.SK_CompanyID\n",
    "        ORDER BY c.CompanyID, f.FI_QTR_START_DATE) T\n",
    "        ON T.SKCID = fmp.SK_CompanyID\n",
    "        AND T.FI_QTR_START_DATE < fmp.DM_DATE \n",
    "        AND T.FI_QTR_START_DATE >= DATE_SUB(fmp.DM_DATE, INTERVAL 4 MONTH);\"\"\",\n",
    "    \"\"\"INSERT INTO dimessages\n",
    "        SELECT NOW() AS MessageDateAndTime, 1 AS BATCHID, 'FactMarketHistory' AS MessageSource, 'No earnings for company' AS MessageText,\n",
    "        'Alert' AS MessageType, CONCAT('DM_S_SYMB = ', DM_S_SYMB)\n",
    "        FROM factmarkethistory \n",
    "        WHERE PERatio IS NULL;\"\"\",\n",
    "    \"ALTER TABLE factmarkethistory DROP COLUMN DM_S_SYMB;\",\n",
    "    \"DROP TABLE tempfactmarketprice;\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the queries\n",
    "with engine.connect() as connection:\n",
    "    for sql in sql_commands:\n",
    "        connection.execute(text(sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactWatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500311 entries, 0 to 1500310\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count    Dtype         \n",
      "---  ------    --------------    -----         \n",
      " 0   W_C_ID    1500311 non-null  uint32        \n",
      " 1   W_S_SYMB  1500311 non-null  object        \n",
      " 2   W_DTS     1500311 non-null  datetime64[ns]\n",
      " 3   W_ACTION  1500311 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(2), uint32(1)\n",
      "memory usage: 40.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_C_ID</th>\n",
       "      <th>W_S_SYMB</th>\n",
       "      <th>W_DTS</th>\n",
       "      <th>W_ACTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>AAAAAAAAAAAAEGI</td>\n",
       "      <td>2012-07-07 00:02:15</td>\n",
       "      <td>ACTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>AAAAAAAAAAAADXJ</td>\n",
       "      <td>2012-07-07 00:02:39</td>\n",
       "      <td>ACTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>AAAAAAAAAAAADOK</td>\n",
       "      <td>2012-07-07 00:05:30</td>\n",
       "      <td>ACTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>AAAAAAAAAAAADFL</td>\n",
       "      <td>2012-07-07 00:06:37</td>\n",
       "      <td>ACTV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>AAAAAAAAAAAACWM</td>\n",
       "      <td>2012-07-07 00:06:57</td>\n",
       "      <td>ACTV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_C_ID         W_S_SYMB               W_DTS W_ACTION\n",
       "0      19  AAAAAAAAAAAAEGI 2012-07-07 00:02:15     ACTV\n",
       "1      58  AAAAAAAAAAAADXJ 2012-07-07 00:02:39     ACTV\n",
       "2      37  AAAAAAAAAAAADOK 2012-07-07 00:05:30     ACTV\n",
       "3      16  AAAAAAAAAAAADFL 2012-07-07 00:06:37     ACTV\n",
       "4      55  AAAAAAAAAAAACWM 2012-07-07 00:06:57     ACTV"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_DIR + \"WatchHistory.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"W_C_ID\",\n",
    "        \"W_S_SYMB\",\n",
    "        \"W_DTS\",\n",
    "        \"W_ACTION\"\n",
    "    ],\n",
    "    dtype={\n",
    "        \"W_C_ID\": \"uint32\",\n",
    "        \"W_S_SYMB\": \"str\",\n",
    "        \"W_DTS\": \"str\",\n",
    "        \"W_ACTION\": \"str\"\n",
    "    },\n",
    "    parse_dates=[\"W_DTS\"]\n",
    ")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_info = pd.read_sql_query(\"SELECT CustomerID, SK_CustomerID, EffectiveDate, EndDate FROM dimcustomer\", engine)\n",
    "customer_info['EffectiveDate'] = pd.to_datetime(customer_info['EffectiveDate'])\n",
    "security_info = pd.read_sql_query(\"SELECT Symbol, SK_SecurityID, EffectiveDate, EndDate FROM dimsecurity\", engine)\n",
    "security_info['EffectiveDate'] = pd.to_datetime(security_info['EffectiveDate'])\n",
    "date_info = pd.read_sql_query(\"SELECT DateValue, SK_DateID FROM dimdate\", engine)\n",
    "date_info['DateValue'] = pd.to_datetime(date_info['DateValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1500311 entries, 0 to 1694090\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   W_C_ID                1500311 non-null  uint32        \n",
      " 1   W_S_SYMB              1500311 non-null  object        \n",
      " 2   W_DTS                 1500311 non-null  datetime64[ns]\n",
      " 3   W_ACTION              1500311 non-null  object        \n",
      " 4   SK_CustomerID         1500311 non-null  int64         \n",
      " 5   SK_SecurityID         1500311 non-null  int64         \n",
      " 6   SK_DateID_DatePlaced  1500311 non-null  int64         \n",
      " 7   BatchID               1500311 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(2), uint32(1)\n",
      "memory usage: 97.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_C_ID</th>\n",
       "      <th>W_S_SYMB</th>\n",
       "      <th>W_DTS</th>\n",
       "      <th>W_ACTION</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_DateID_DatePlaced</th>\n",
       "      <th>BatchID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>AAAAAAAAAAAAEGI</td>\n",
       "      <td>2012-07-07 00:02:15</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>9960</td>\n",
       "      <td>3191</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>AAAAAAAAAAAADXJ</td>\n",
       "      <td>2012-07-07 00:02:39</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>8737</td>\n",
       "      <td>2923</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>AAAAAAAAAAAADOK</td>\n",
       "      <td>2012-07-07 00:05:30</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>38</td>\n",
       "      <td>2668</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>AAAAAAAAAAAADFL</td>\n",
       "      <td>2012-07-07 00:06:37</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>10179</td>\n",
       "      <td>2393</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>AAAAAAAAAAAACWM</td>\n",
       "      <td>2012-07-07 00:06:57</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>9971</td>\n",
       "      <td>2152</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_C_ID         W_S_SYMB               W_DTS W_ACTION  SK_CustomerID  \\\n",
       "0      19  AAAAAAAAAAAAEGI 2012-07-07 00:02:15     ACTV           9960   \n",
       "1      58  AAAAAAAAAAAADXJ 2012-07-07 00:02:39     ACTV           8737   \n",
       "2      37  AAAAAAAAAAAADOK 2012-07-07 00:05:30     ACTV             38   \n",
       "3      16  AAAAAAAAAAAADFL 2012-07-07 00:06:37     ACTV          10179   \n",
       "4      55  AAAAAAAAAAAACWM 2012-07-07 00:06:57     ACTV           9971   \n",
       "\n",
       "   SK_SecurityID  SK_DateID_DatePlaced  BatchID  \n",
       "0           3191              20120707        1  \n",
       "1           2923              20120707        1  \n",
       "2           2668              20120707        1  \n",
       "3           2393              20120707        1  \n",
       "4           2152              20120707        1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get SK_CustomerID\n",
    "df = df.merge(customer_info, how=\"left\", left_on=\"W_C_ID\", right_on=\"CustomerID\")\n",
    "# filter based on date\n",
    "df = df[\n",
    "    (df[\"W_DTS\"] >= df[\"EffectiveDate\"])\n",
    "    & (df[\"W_DTS\"].dt.date < df[\"EndDate\"])\n",
    "]\n",
    "# drop cols\n",
    "df.drop(columns=[\"CustomerID\", \"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "# get SK_SecurityID\n",
    "df = df.merge(security_info, how=\"left\", left_on=\"W_S_SYMB\", right_on=\"Symbol\")\n",
    "# filter based on date\n",
    "df = df[\n",
    "    (df[\"W_DTS\"] >= df[\"EffectiveDate\"])\n",
    "    & (df[\"W_DTS\"].dt.date < df[\"EndDate\"])\n",
    "]\n",
    "# drop cols\n",
    "df.drop(columns=[\"Symbol\", \"EffectiveDate\", \"EndDate\"], inplace=True)\n",
    "# SK_DateID_DatePlaced - set based on W_DTS.\n",
    "df['SK_DateID_DatePlaced'] = df['W_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "# BatchID - set to 1.\n",
    "df['BatchID'] = 1\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1500311 entries, 0 to 1694090\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   W_C_ID                 1500311 non-null  uint32        \n",
      " 1   W_S_SYMB               1500311 non-null  object        \n",
      " 2   W_DTS                  1500311 non-null  datetime64[ns]\n",
      " 3   W_ACTION               1500311 non-null  object        \n",
      " 4   SK_CustomerID          1500311 non-null  int64         \n",
      " 5   SK_SecurityID          1500311 non-null  int64         \n",
      " 6   SK_DateID_DatePlaced   1500311 non-null  int64         \n",
      " 7   BatchID                1500311 non-null  int64         \n",
      " 8   SK_DateID_DateRemoved  299280 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(2), uint32(1)\n",
      "memory usage: 108.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_C_ID</th>\n",
       "      <th>W_S_SYMB</th>\n",
       "      <th>W_DTS</th>\n",
       "      <th>W_ACTION</th>\n",
       "      <th>SK_CustomerID</th>\n",
       "      <th>SK_SecurityID</th>\n",
       "      <th>SK_DateID_DatePlaced</th>\n",
       "      <th>BatchID</th>\n",
       "      <th>SK_DateID_DateRemoved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>AAAAAAAAAAAAEGI</td>\n",
       "      <td>2012-07-07 00:02:15</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>9960</td>\n",
       "      <td>3191</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>AAAAAAAAAAAADXJ</td>\n",
       "      <td>2012-07-07 00:02:39</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>8737</td>\n",
       "      <td>2923</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>AAAAAAAAAAAADOK</td>\n",
       "      <td>2012-07-07 00:05:30</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>38</td>\n",
       "      <td>2668</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>AAAAAAAAAAAADFL</td>\n",
       "      <td>2012-07-07 00:06:37</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>10179</td>\n",
       "      <td>2393</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>AAAAAAAAAAAACWM</td>\n",
       "      <td>2012-07-07 00:06:57</td>\n",
       "      <td>ACTV</td>\n",
       "      <td>9971</td>\n",
       "      <td>2152</td>\n",
       "      <td>20120707</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W_C_ID         W_S_SYMB               W_DTS W_ACTION  SK_CustomerID  \\\n",
       "0      19  AAAAAAAAAAAAEGI 2012-07-07 00:02:15     ACTV           9960   \n",
       "1      58  AAAAAAAAAAAADXJ 2012-07-07 00:02:39     ACTV           8737   \n",
       "2      37  AAAAAAAAAAAADOK 2012-07-07 00:05:30     ACTV             38   \n",
       "3      16  AAAAAAAAAAAADFL 2012-07-07 00:06:37     ACTV          10179   \n",
       "4      55  AAAAAAAAAAAACWM 2012-07-07 00:06:57     ACTV           9971   \n",
       "\n",
       "   SK_SecurityID  SK_DateID_DatePlaced  BatchID  SK_DateID_DateRemoved  \n",
       "0           3191              20120707        1                    NaN  \n",
       "1           2923              20120707        1                    NaN  \n",
       "2           2668              20120707        1                    NaN  \n",
       "3           2393              20120707        1                    NaN  \n",
       "4           2152              20120707        1                    NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask for rows where W_ACTION is 'CNCL'\n",
    "mask_cncl = df['W_ACTION'] == 'CNCL'\n",
    "df.loc[mask_cncl, 'SK_DateID_DateRemoved'] = df.loc[mask_cncl, 'W_DTS'].dt.date.map(date_info.set_index('DateValue')['SK_DateID'])\n",
    "df.loc[~mask_cncl, 'SK_DateID_DateRemoved'] = None\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1500311 entries, 0 to 1694090\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   SK_CustomerID          1500311 non-null  int64  \n",
      " 1   SK_SecurityID          1500311 non-null  int64  \n",
      " 2   SK_DateID_DatePlaced   1500311 non-null  int64  \n",
      " 3   SK_DateID_DateRemoved  299280 non-null   float64\n",
      " 4   BatchID                1500311 non-null  int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 68.7 MB\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [\"SK_CustomerID\", \"SK_SecurityID\", \"SK_DateID_DatePlaced\", \"SK_DateID_DateRemoved\", \"BatchID\"]\n",
    "df = df[keep_cols]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dtypes = {\n",
    "    \"SK_CustomerID\": sqlalchemy.types.Integer,\n",
    "    \"SK_SecurityID\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DatePlaced\": sqlalchemy.types.Integer,\n",
    "    \"SK_DateID_DateRemoved\": sqlalchemy.types.Integer,\n",
    "    \"BatchID\": sqlalchemy.types.SmallInteger\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"CREATE TABLE FactWatches (\n",
    "    SK_CustomerID INT UNSIGNED NOT NULL,\n",
    "    SK_SecurityID INT UNSIGNED NOT NULL,\n",
    "    SK_DateID_DatePlaced INT UNSIGNED NOT NULL,\n",
    "    SK_DateID_DateRemoved INT UNSIGNED,\n",
    "    BatchID SMALLINT UNSIGNED NOT NULL\n",
    ");\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(create_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d981c471fcea4344a709f2769da33044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in trange(0, df.shape[0], 100000):\n",
    "    df.iloc[i:i+100000].to_sql('factwatches', engine, if_exists='append', index=False, dtype=sql_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Batch Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"E:\\Documents\\BDMA\\ULB\\Data Warehouses\\tpc-di\\TPC-DI\\validation\\tpcdi_validation.sql\"\n",
    "# Read the SQL file\n",
    "with open(filepath, 'r') as file:\n",
    "    sql_file = file.read()\n",
    "\n",
    "# Execute the SQL commands\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(sql_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
